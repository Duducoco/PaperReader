[
  {
    "date": "2025-12-08",
    "title": "PRO-V-R1: Reasoning Enhanced Programming Agent for RTL Verification",
    "authors": "Yujie Zhao, Zhijing Wu, Boqin Yuan, Zhongming Yu, Hejia Zhang, Wentao Ni, Chia-Tung Ho, Haoxing Ren, Jishen Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2506.12200v4",
    "source": "arXiv",
    "abstract": "Register-Transfer Level (RTL) verification is a primary bottleneck, consuming 60-70% of development time. While Large Language Models (LLMs) show promise for RTL automation, their performance and research focus have overwhelmingly centered on RTL generation rather than verification. Current methods for RTL verification rely on large scale proprietary models (e.g., GPT-4o) to generate Python-based functional references, incurring a high cost and raising data-privacy risks. To date, an end-to-end open-source solution for autonomous verification remains absent. We introduce PRO-V-R1, the first trainable open-source agentic framework for autonomous RTL verification. Our contributions are threefold: (1) we design PRO-V sys, a modular agentic system that couples LLM-based reasoning with programmatic tool use for RTL verification; (2) we establish a data construction pipeline that leverages existing RTL datasets to build simulation-validated, expert-level trajectories tailored for supervised fine-tuning (SFT) RTL verification agents; and (3) we implement an efficient reinforcement learning (RL) algorithm that uses verification-specific rewards derived from program-tool feedback to optimize the end-to-end verification workflow. Our empirical evaluation demonstrates PRO-V-R1 achieves a 57.7% functional correctness rate and 34.0% in robust fault detection, significantly outperforming the base model's 25.7% and 21.8% (respectively) from the state-of-the-art (SOTA) automatic verification system. This configuration also outperforms large-scale proprietary LLMs in functional correctness and shows comparable robustness for fault detection.",
    "title_zh": "PRO-V-R1：面向RTL验证的推理增强型编程智能体",
    "abstract_zh": "寄存器传输级（RTL）验证是开发中的主要瓶颈，耗费60–70%的开发时间。尽管大语言模型（LLM）在RTL自动化方面展现潜力，其性能与研究重点却几乎都集中在RTL生成而非验证上。现有的RTL验证方法依赖大型闭源模型（如GPT-4o）生成基于Python的功能参考，导致成本高且存在数据隐私风险。迄今为止，端到端的开源自主验证解决方案仍然缺失。我们提出PRO-V-R1，这是首个可训练的开源智能体式框架，用于自主RTL验证。我们的贡献包括：（1）设计PRO-V sys，一个模块化的智能体系统，将基于LLM的推理与程序化工具使用相结合以执行RTL验证；（2）建立数据构建流水线，利用现有RTL数据集，构造经仿真验证的专家级轨迹，用于监督微调（SFT）RTL验证智能体；（3）实现一种高效的强化学习（RL）算法，基于程序—工具反馈提取面向验证的奖励，以优化端到端验证工作流。实证评估表明，PRO-V-R1在功能正确率上达到57.7%，在稳健故障检测方面为34.0%，显著优于当前最先进（SOTA）自动验证系统的基模型（分别为25.7%和21.8%）。该配置在功能正确性上也优于大型闭源LLM，并在故障检测的稳健性方面表现相当。"
  },
  {
    "date": "2024-09-03",
    "title": "AIvril: AI-Driven RTL Generation With Verification In-The-Loop",
    "authors": "Mubashir ul Islam, Humza Sami, Pierre-Emmanuel Gaillardon, Valerio Tenace",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2409.11411v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are computational models capable of performing complex natural language processing tasks. Leveraging these capabilities, LLMs hold the potential to transform the entire hardware design stack, with predictions suggesting that front-end and back-end tasks could be fully automated in the near future. Currently, LLMs show great promise in streamlining Register Transfer Level (RTL) generation, enhancing efficiency, and accelerating innovation. However, their probabilistic nature makes them prone to inaccuracies - a significant drawback in RTL design, where reliability and precision are essential. To address these challenges, this paper introduces AIvril, an advanced framework designed to enhance the accuracy and reliability of RTL-aware LLMs. AIvril employs a multi-agent, LLM-agnostic system for automatic syntax correction and functional verification, significantly reducing - and in many cases, completely eliminating - instances of erroneous code generation. Experimental results conducted on the VerilogEval-Human dataset show that our framework improves code quality by nearly 2x when compared to previous works, while achieving an 88.46% success rate in meeting verification objectives. This represents a critical step toward automating and optimizing hardware design workflows, offering a more dependable methodology for AI-driven RTL design.",
    "title_zh": "AIvril：AI驱动的RTL生成与在环验证",
    "abstract_zh": "大型语言模型（LLM）是能够执行复杂自然语言处理任务的计算模型。借助这些能力，LLM 有望重塑整个硬件设计全栈，预测显示前端和后端任务在不久的将来都可能实现完全自动化。目前，LLM 在简化寄存器传输级（RTL）生成方面展现出巨大潜力，能够提升效率并加速创新。然而，其概率特性使其容易出现不准确性——这在强调可靠性与精确性的 RTL 设计中是一个重大缺陷。为应对这些挑战，本文提出 AIvril，这是一种用于提升面向 RTL 的 LLM 准确性与可靠性的先进框架。AIvril 采用多智能体、与具体 LLM 无关的系统，实现自动语法纠错与功能验证，显著减少——并在许多情况下完全消除——错误代码生成。基于 VerilogEval-Human 数据集的实验结果表明，相较于以往工作，我们的框架将代码质量提升近两倍，并在达成验证目标方面实现了 88.46% 的成功率。这标志着在自动化与优化硬件设计流程方面迈出了关键一步，为 AI 驱动的 RTL 设计提供了更为可靠的方法论。"
  },
  {
    "date": "2023-09-28",
    "title": "Using LLMs to Facilitate Formal Verification of RTL",
    "authors": "Marcelo Orenes-Vera, Margaret Martonosi, David Wentzlaff",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2309.09437v2",
    "source": "arXiv",
    "abstract": "Formal property verification (FPV) has existed for decades and has been shown to be effective at finding intricate RTL bugs. However, formal properties, such as those written as SystemVerilog Assertions (SVA), are time-consuming and error-prone to write, even for experienced users. Prior work has attempted to lighten this burden by raising the abstraction level so that SVA is generated from high-level specifications. However, this does not eliminate the manual effort of reasoning and writing about the detailed hardware behavior. Motivated by the increased need for FPV in the era of heterogeneous hardware and the advances in large language models (LLMs), we set out to explore whether LLMs can capture RTL behavior and generate correct SVA properties. First, we design an FPV-based evaluation framework that measures the correctness and completeness of SVA. Then, we evaluate GPT4 iteratively to craft the set of syntax and semantic rules needed to prompt it toward creating better SVA. We extend the open-source AutoSVA framework by integrating our improved GPT4-based flow to generate safety properties, in addition to facilitating their existing flow for liveness properties. Lastly, our use cases evaluate (1) the FPV coverage of GPT4-generated SVA on complex open-source RTL and (2) using generated SVA to prompt GPT4 to create RTL from scratch. Through these experiments, we find that GPT4 can generate correct SVA even for flawed RTL, without mirroring design errors. Particularly, it generated SVA that exposed a bug in the RISC-V CVA6 core that eluded the prior work's evaluation.",
    "title_zh": "利用大型语言模型辅助RTL的形式化验证",
    "abstract_zh": "形式化属性验证（FPV）已有数十年的历史，并被证明在发现复杂的寄存器传输级（RTL）漏洞方面行之有效。然而，诸如以 SystemVerilog 断言（SVA）编写的形式化属性，即便对经验丰富的用户而言，撰写过程仍耗时且易出错。既有工作试图通过提升抽象层次，从高层次规范自动生成 SVA，以减轻这一负担。但这并未消除围绕硬件细节行为进行推理与撰写的人工工作。\n\n受异构硬件时代对 FPV 的日益增长需求以及大型语言模型（LLM）的进展所驱动，我们着手探索 LLM 是否能够捕捉 RTL 行为并生成正确的 SVA 属性。首先，我们设计了一个基于 FPV 的评估框架，用以衡量 SVA 的正确性与完备性。随后，我们对 GPT-4 进行迭代评估，打磨一套用于提示其生成更优 SVA 的语法与语义规则。我们通过集成改进的基于 GPT-4 的流程来扩展开源 AutoSVA 框架，使其在支持既有生成活性性质的流程之外，还能生成安全性性质。最后，我们的用例评估：(1) GPT-4 生成的 SVA 在复杂开源 RTL 上的 FPV 覆盖率；(2) 利用生成的 SVA 来提示 GPT-4 从零创建 RTL。\n\n通过这些实验，我们发现：即使面对存在缺陷的 RTL，GPT-4 也能生成正确的 SVA，而不会复刻设计错误。尤其是，它生成的 SVA 揭示了 RISC-V CVA6 内核中的一个缺陷，而该缺陷在先前工作的评估中未被发现。"
  },
  {
    "date": "2025-05-14",
    "title": "AssertionForge: Enhancing Formal Verification Assertion Generation with Structured Representation of Specifications and RTL",
    "authors": "Yunsheng Bai, Ghaith Bany Hamad, Syed Suhaib, Haoxing Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2503.19174v2",
    "source": "arXiv",
    "abstract": "Generating SystemVerilog Assertions (SVAs) from natural language specifications remains a major challenge in formal verification (FV) due to the inherent ambiguity and incompleteness of specifications. Existing LLM-based approaches, such as AssertLLM, focus on extracting information solely from specification documents, often failing to capture essential internal signal interactions and design details present in the RTL code, leading to incomplete or incorrect assertions. We propose a novel approach that constructs a Knowledge Graph (KG) from both specifications and RTL, using a hardware-specific schema with domain-specific entity and relation types. We create an initial KG from the specification and then systematically fuse it with information extracted from the RTL code, resulting in a unified, comprehensive KG. This combined representation enables a more thorough understanding of the design and allows for a multi-resolution context synthesis process which is designed to extract diverse verification contexts from the KG. Experiments on four designs demonstrate that our method significantly enhances SVA quality over prior methods. This structured representation not only improves FV but also paves the way for future research in tasks like code generation and design understanding.",
    "title_zh": "AssertionForge：通过对规范与RTL进行结构化表示增强形式验证断言生成",
    "abstract_zh": "从自然语言规格生成 SystemVerilog 断言（SVA）在形式化验证（FV）中仍是重大挑战，原因在于规格本身存在固有的歧义与不完整性。现有基于大语言模型（LLM）的方法（如 AssertLLM）仅从规格文档中抽取信息，往往无法捕获存在于 RTL 代码中的关键内部信号交互与设计细节，从而导致断言不完整或错误。为此，我们提出一种新方法：结合规格与 RTL 构建知识图谱（KG），并采用面向硬件的模式（schema），定义领域特定的实体与关系类型。我们先从规格构建初始 KG，再将从 RTL 代码中抽取的信息进行系统性融合，得到统一而全面的 KG。该融合表示不仅促使对设计的更深入理解，还支持一种多分辨率的上下文合成过程，以从 KG 中提取多样的验证上下文。对四个设计的实验表明，相较既有方法，我们的方案显著提升了 SVA 的质量。此类结构化表示不仅改进了形式化验证，也为代码生成与设计理解等任务的后续研究铺平了道路。"
  },
  {
    "date": "2024-05-31",
    "title": "Towards LLM-Powered Verilog RTL Assistant: Self-Verification and Self-Correction",
    "authors": "Hanxian Huang, Zhenghan Lin, Zixuan Wang, Xin Chen, Ke Ding, Jishen Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2406.00115v1",
    "source": "arXiv",
    "abstract": "We explore the use of Large Language Models (LLMs) to generate high-quality Register-Transfer Level (RTL) code with minimal human interference. The traditional RTL design workflow requires human experts to manually write high-quality RTL code, which is time-consuming and error-prone. With the help of emerging LLMs, developers can describe their requirements to LLMs which then generate corresponding code in Python, C, Java, and more. Adopting LLMs to generate RTL design in hardware description languages is not trivial, given the complex nature of hardware design and the generated design has to meet the timing and physical constraints. We propose VeriAssist, an LLM-powered programming assistant for Verilog RTL design workflow. VeriAssist takes RTL design descriptions as input and generates high-quality RTL code with corresponding test benches. VeriAssist enables the LLM to self-correct and self-verify the generated code by adopting an automatic prompting system and integrating RTL simulator in the code generation loop. To generate an RTL design, VeriAssist first generates the initial RTL code and corresponding test benches, followed by a self-verification step that walks through the code with test cases to reason the code behavior at different time steps, and finally it self-corrects the code by reading the compilation and simulation results and generating final RTL code that fixes errors in compilation and simulation. This design fully leverages the LLMs' capabilities on multi-turn interaction and chain-of-thought reasoning to improve the quality of the generated code. We evaluate VeriAssist with various benchmark suites and find it significantly improves both syntax and functionality correctness over existing LLM implementations, thus minimizing human intervention and making RTL design more accessible to novice designers.",
    "title_zh": "迈向LLM驱动的Verilog RTL助手：自我验证与自我纠正",
    "abstract_zh": "我们探索使用大型语言模型（LLM）在尽量减少人工干预的情况下生成高质量的寄存器传输级（RTL）代码。传统的 RTL 设计流程需要专家手工编写高质量的 RTL 代码，既耗时又容易出错。借助新兴的 LLM，开发者可以向模型描述需求，模型随后生成 Python、C、Java 等语言的相应代码。然而，考虑到硬件设计的复杂性以及生成的设计必须满足时序和物理约束，将 LLM 用于在硬件描述语言（HDL）中生成 RTL 设计并非易事。\n\n我们提出 VeriAssist，这是一种由 LLM 驱动的用于 Verilog RTL 设计流程的编程助手。VeriAssist 以 RTL 设计说明为输入，生成高质量的 RTL 代码及其相应的测试平台（testbench）。通过采用自动提示系统并将 RTL 仿真器集成到代码生成循环中，VeriAssist 使 LLM 能够对生成的代码进行自我纠错和自我验证。为生成 RTL 设计，VeriAssist 首先生成初始 RTL 代码及相应的测试平台；随后进行自我验证步骤，结合测试用例在不同时间步推理代码行为；最后通过读取编译与仿真结果，对代码进行自我纠错，生成修复编译与仿真错误的最终 RTL 代码。该设计充分利用 LLM 在多轮交互与链式思维推理方面的能力，以提升生成代码的质量。\n\n我们使用多种基准测试套件对 VeriAssist 进行评估，发现其在语法正确性与功能正确性方面均显著优于现有的 LLM 实现，从而将人工干预降至最低，并使新手设计者更容易开展 RTL 设计。"
  },
  {
    "date": "2025-06-17",
    "title": "Comprehensive Verilog Design Problems: A Next-Generation Benchmark Dataset for Evaluating Large Language Models and Agents on RTL Design and Verification",
    "authors": "Nathaniel Pinckney, Chenhui Deng, Chia-Tung Ho, Yun-Da Tsai, Mingjie Liu, Wenfei Zhou, Brucek Khailany, Haoxing Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2506.14074v1",
    "source": "arXiv",
    "abstract": "We present the Comprehensive Verilog Design Problems (CVDP) benchmark, a new dataset and infrastructure to advance LLM and agent research in hardware design and verification. CVDP includes 783 problems across 13 task categories, covering RTL generation, verification, debugging, specification alignment, and technical Q&A authored by experienced hardware engineers. Problems are offered in both non-agentic and agentic formats. The benchmark introduces more realistic and challenging contexts than prior work, with state-of-the-art models achieving no more than 34% pass@1 on code generation. Agentic tasks$\\unicode{x2013}$especially those involving RTL reuse and verification$\\unicode{x2013}$are particularly difficult. Evaluation uses open-source tools and model scoring infrastructure, with comprehension tasks assessed via BLEU and LLM-based judging. CVDP reveals substantial gaps in current model capabilities, underscoring the need for continued research toward robust, real-world hardware design automation.",
    "title_zh": "综合性 Verilog 设计问题：用于评估大型语言模型与智能体在 RTL 设计与验证方面表现的下一代基准数据集",
    "abstract_zh": "我们提出了综合 Verilog 设计问题（CVDP）基准，这是一个用于推进大型语言模型（LLM）与智能体在硬件设计与验证领域研究的新数据集与基础设施。CVDP 覆盖 13 个任务类别，共包含 783 个问题，涵盖由资深硬件工程师编写的 RTL 生成、验证、调试、规格对齐以及技术问答。问题同时以非智能体与智能体两种形式提供。与先前工作相比，该基准提供了更贴近现实且更具挑战的上下文；在代码生成上，最先进模型的一次通过率（pass@1）不超过 34%。智能体任务——尤其是涉及 RTL 复用与验证的任务——尤为困难。评测使用开源工具和模型评分基础设施，其中理解类任务通过 BLEU 与基于 LLM 的评审进行评价。CVDP 揭示了当前模型能力的显著不足，强调需要继续研究以实现稳健的、面向真实世界的硬件设计自动化。"
  },
  {
    "date": "2024-11-25",
    "title": "UVLLM: An Automated Universal RTL Verification Framework using LLMs",
    "authors": "Yuchen Hu, Junhao Ye, Ke Xu, Jialin Sun, Shiyue Zhang, Xinyao Jiao, Dingrong Pan, Jie Zhou, Ning Wang, Weiwei Shan, Xinwei Fang, Xi Wang, Nan Guan, Zhe Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2411.16238v1",
    "source": "arXiv",
    "abstract": "Verifying hardware designs in embedded systems is crucial but often labor-intensive and time-consuming. While existing solutions have improved automation, they frequently rely on unrealistic assumptions. To address these challenges, we introduce a novel framework, UVLLM, which combines Large Language Models (LLMs) with the Universal Verification Methodology (UVM) to relax these assumptions. UVLLM significantly enhances the automation of testing and repairing error-prone Register Transfer Level (RTL) codes, a critical aspect of verification development. Unlike existing methods, UVLLM ensures that all errors are triggered during verification, achieving a syntax error fix rate of 86.99% and a functional error fix rate of 71.92% on our proposed benchmark. These results demonstrate a substantial improvement in verification efficiency. Additionally, our study highlights the current limitations of LLM applications, particularly their reliance on extensive training data. We emphasize the transformative potential of LLMs in hardware design verification and suggest promising directions for future research in AI-driven hardware design methodologies. The Repo. of dataset and code: https://anonymous.4open.science/r/UVLLM/.",
    "title_zh": "UVLLM：一种基于大语言模型的自动化通用寄存器传输级（RTL）验证框架",
    "abstract_zh": "在嵌入式系统中验证硬件设计至关重要，但往往劳动密集且耗时。尽管现有方案提高了自动化水平，它们常常依赖不切实际的假设。为应对这些挑战，我们提出了一种新框架 UVLLM，将大语言模型（LLM）与通用验证方法学（UVM）相结合，以弱化这些假设。UVLLM 显著提升了对易出错的寄存器传输级（RTL）代码进行测试与修复的自动化，这是验证开发中的关键环节。与现有方法不同，UVLLM 确保在验证过程中所有错误都能被触发，并在我们提出的基准上实现了86.99%的语法错误修复率和71.92%的功能错误修复率。这些结果表明验证效率获得了显著提升。此外，我们的研究也凸显了当前 LLM 应用的局限性，尤其是其对大量训练数据的依赖。我们强调 LLM 在硬件设计验证中的变革性潜力，并为 AI 驱动的硬件设计方法学的未来研究提出了有前景的方向。数据集和代码的仓库：https://anonymous.4open.science/r/UVLLM/"
  },
  {
    "date": "2025-08-20",
    "title": "From Concept to Practice: an Automated LLM-aided UVM Machine for RTL Verification",
    "authors": "Junhao Ye, Yuchen Hu, Ke Xu, Dingrong Pan, Qichun Chen, Jie Zhou, Shuai Zhao, Xinwei Fang, Xi Wang, Nan Guan, Zhe Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2504.19959v3",
    "source": "arXiv",
    "abstract": "Verification presents a major bottleneck in Integrated Circuit (IC) development, consuming nearly 70% of the total development effort. While the Universal Verification Methodology (UVM) is widely used in industry to improve verification efficiency through structured and reusable testbenches, constructing these testbenches and generating sufficient stimuli remain challenging. These challenges arise from the considerable manual coding effort required, repetitive manual execution of multiple EDA tools, and the need for in-depth domain expertise to navigate complex designs.Here, we present UVM^2, an automated verification framework that leverages Large Language Models (LLMs) to generate UVM testbenches and iteratively refine them using coverage feedback, significantly reducing manual effort while maintaining rigorous verification standards.To evaluate UVM^2, we introduce a benchmark suite comprising Register Transfer Level (RTL) designs of up to 1.6K lines of code.The results show that UVM^2 reduces testbench setup time by up to UVM^2 compared to experienced engineers, and achieve average code and function coverage of 87.44% and 89.58%, outperforming state-of-the-art solutions by 20.96% and 23.51%, respectively.",
    "title_zh": "从概念到实践：面向RTL验证的自动化、LLM辅助的UVM系统",
    "abstract_zh": "验证是集成电路（IC）开发中的主要瓶颈，几乎占据总开发投入的 70%。尽管业界广泛采用通用验证方法学（UVM），通过结构化、可复用的测试平台提升验证效率，但构建这些测试平台并生成足够的激励仍然充满挑战。这些挑战源于大量的手工编码、反复手动执行多种 EDA 工具，以及为应对复杂设计所需的深入领域专业知识。为此，我们提出 UVM^2，这是一套自动化验证框架，利用大语言模型（LLM）生成 UVM 测试平台，并在覆盖率反馈的驱动下迭代改进，在保持严格验证标准的同时显著降低人工工作量。为评估 UVM^2，我们引入了一个基准套件，包含代码规模最高达 1.6K 行的寄存器传输级（RTL）设计。结果显示，与经验丰富的工程师相比，UVM^2 能将测试平台的搭建时间最多减少至 UVM^2，并实现平均代码覆盖率 87.44% 和功能覆盖率 89.58%，分别优于当前最先进的解决方案 20.96% 和 23.51%。"
  },
  {
    "date": "2025-05-11",
    "title": "RTL++: Graph-enhanced LLM for RTL Code Generation",
    "authors": "Mohammad Akyash, Kimia Azar, Hadi Kamali",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2505.13479v1",
    "source": "arXiv",
    "abstract": "As hardware design complexity escalates, there is an urgent need for advanced automation in electronic design automation (EDA). Traditional register transfer level (RTL) design methods are manual, time-consuming, and prone to errors. While commercial (instruction-tuned) large language models (LLMs) shows promising performance for automation, they pose security and privacy concerns. Open-source models offer alternatives; however, they frequently fall short in quality/correctness, largely due to limited, high-quality RTL code data essential for effective training and generalization. This paper proposes RTL++, a first-of-its-kind LLM-assisted method for RTL code generation that utilizes graph representations of code structures to enhance the quality of generated code. By encoding RTL code into a textualized control flowgraphs (CFG) and data flow graphs (DFG), RTL++ captures the inherent hierarchy, dependencies, and relationships within the code. This structured graph-based approach enhances the context available to LLMs, enabling them to better understand and generate instructions. By focusing on data generation through graph representations, RTL++ addresses the limitations of previous approaches that rely solely on code and suffer from lack of diversity. Experimental results demonstrate that RTL++ outperforms state-of-the-art models fine-tuned for RTL generation, as evaluated using the VerilogEval benchmark's Pass@1/5/10 metric, as well as the RTLLM1.1 model, which highlight the effectiveness of graph-enhanced context in advancing the capabilities of LLM-assisted RTL code generation.",
    "title_zh": "RTL++：用于RTL代码生成的图增强型大语言模型",
    "abstract_zh": "随着硬件设计复杂性不断攀升，电子设计自动化（EDA）亟需更先进的自动化能力。传统的寄存器传输级（RTL）设计方法以人工为主，耗时且易出错。尽管商业（指令微调的）大语言模型（LLM）在自动化方面展现出有前景的性能，但也带来了安全与隐私方面的担忧。开源模型提供了替代方案；然而，它们在质量与正确性上常常不足，主要原因在于缺乏用于有效训练与泛化的高质量RTL代码数据。本文提出RTL++，一种首创的LLM辅助RTL代码生成方法，通过利用代码结构的图表示来提升生成代码质量。RTL++将RTL代码编码为文本化的控制流图（CFG）和数据流图（DFG），以捕捉代码内部的层次结构、依赖关系与关联性。这种结构化的图方法增强了LLM可用的上下文，使其更好地理解并生成指令。通过聚焦于基于图表示的数据生成，RTL++克服了以往仅依赖代码且缺乏多样性的方案的局限。实验结果表明，RTL++在VerilogEval基准的Pass@1/5/10指标上优于为RTL生成微调的最新模型，同时也超过了RTLLM1.1模型，凸显了图增强上下文在提升LLM辅助RTL代码生成能力方面的有效性。"
  },
  {
    "date": "2024-05-27",
    "title": "RTL-Repo: A Benchmark for Evaluating LLMs on Large-Scale RTL Design Projects",
    "authors": "Ahmed Allam, Mohamed Shalan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2405.17378v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated potential in assisting with Register Transfer Level (RTL) design tasks. Nevertheless, there remains to be a significant gap in benchmarks that accurately reflect the complexity of real-world RTL projects. To address this, this paper presents RTL-Repo, a benchmark specifically designed to evaluate LLMs on large-scale RTL design projects. RTL-Repo includes a comprehensive dataset of more than 4000 Verilog code samples extracted from public GitHub repositories, with each sample providing the full context of the corresponding repository. We evaluate several state-of-the-art models on the RTL-Repo benchmark, including GPT-4, GPT-3.5, Starcoder2, alongside Verilog-specific models like VeriGen and RTLCoder, and compare their performance in generating Verilog code for complex projects. The RTL-Repo benchmark provides a valuable resource for the hardware design community to assess and compare LLMs' performance in real-world RTL design scenarios and train LLMs specifically for Verilog code generation in complex, multi-file RTL projects. RTL-Repo is open-source and publicly available on Github.",
    "title_zh": "RTL-Repo：用于评估大型语言模型在大规模 RTL 设计项目上的评测基准",
    "abstract_zh": "大型语言模型（LLM）已在辅助寄存器传输级（RTL）设计任务方面展现出潜力。然而，能够准确反映真实世界RTL项目复杂性的基准仍存在显著缺口。为此，本文提出RTL-Repo，这一专门用于评估LLM在大规模RTL设计项目上表现的基准。RTL-Repo包含一个全面的数据集，收录了来自公开GitHub仓库的4000余个Verilog代码样本，每个样本都提供其对应仓库的完整上下文。我们在RTL-Repo基准上评测了多种最先进的模型，包括GPT-4、GPT-3.5、StarCoder2，以及面向Verilog的模型VeriGen与RTLCoder，并比较了它们在复杂项目的Verilog代码生成中的表现。RTL-Repo为硬件设计社区提供了一个有价值的资源，用于在真实世界的RTL设计场景中评估与比较LLM的性能，并用于专门训练LLM以在复杂的多文件RTL项目中进行Verilog代码生成。RTL-Repo已开源并在GitHub上公开提供。"
  },
  {
    "date": "2025-11-17",
    "title": "Think with Self-Decoupling and Self-Verification: Automated RTL Design with Backtrack-ToT",
    "authors": "Zhiteng Chao, Yonghao Wang, Xinyu Zhang, Jiaxin Zhou, Tenghui Hua, Husheng Han, Tianmeng Yang, Jianan Mu, Bei Yu, Rui Zhang, Jing Ye, Huawei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.13139v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) hold promise for automating integrated circuit (IC) engineering using register transfer level (RTL) hardware description languages (HDLs) like Verilog. However, challenges remain in ensuring the quality of Verilog generation. Complex designs often fail in a single generation due to the lack of targeted decoupling strategies, and evaluating the correctness of decoupled sub-tasks remains difficult. While the chain-of-thought (CoT) method is commonly used to improve LLM reasoning, it has been largely ineffective in automating IC design workflows, requiring manual intervention. The key issue is controlling CoT reasoning direction and step granularity, which do not align with expert RTL design knowledge. This paper introduces VeriBToT, a specialized LLM reasoning paradigm for automated Verilog generation. By integrating Top-down and design-for-verification (DFV) approaches, VeriBToT achieves self-decoupling and self-verification of intermediate steps, constructing a Backtrack Tree of Thought with formal operators. Compared to traditional CoT paradigms, our approach enhances Verilog generation while optimizing token costs through flexible modularity, hierarchy, and reusability.",
    "title_zh": "自解耦与自验证的思维：基于 Backtrack-ToT 的自动化 RTL 设计",
    "abstract_zh": "大型语言模型（LLMs）在利用 Verilog 等寄存器传输级（RTL）硬件描述语言（HDLs）实现集成电路（IC）工程自动化方面前景可期。然而，确保 Verilog 生成质量仍面临挑战。由于缺乏有针对性的解耦策略，复杂设计往往难以一次性生成；而对解耦后的子任务进行正确性评估也同样困难。尽管链式思维（CoT）方法常用于提升 LLM 的推理能力，但在自动化 IC 设计流程中效果欠佳，仍需人工干预。核心问题在于，CoT 的推理方向与步骤粒度难以受控，且与专家级 RTL 设计知识不匹配。本文提出 VeriBToT，这是一种面向自动化 Verilog 生成的专用 LLM 推理范式。通过融合自顶向下与面向验证（DFV）的设计思想，VeriBToT 实现中间步骤的自我解耦与自我验证，并以形式化操作符构建带回溯的思维树（Backtrack Tree of Thought）。与传统 CoT 范式相比，我们的方法在提升 Verilog 生成效果的同时，凭借灵活的模块化、层次化与可复用性优化了令牌成本。"
  },
  {
    "date": "2025-01-06",
    "title": "RTLSquad: Multi-Agent Based Interpretable RTL Design",
    "authors": "Bowei Wang, Qi Xiong, Zeqing Xiang, Lei Wang, Renzhi Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2501.05470v1",
    "source": "arXiv",
    "abstract": "Optimizing Register-Transfer Level (RTL) code is crucial for improving hardware PPA performance. Large Language Models (LLMs) offer new approaches for automatic RTL code generation and optimization. However, existing methods often lack decision interpretability (sufficient, understandable justification for decisions), making it difficult for hardware engineers to trust the generated results, thus preventing these methods from being integrated into the design process. To address this, we propose RTLSquad, a novel LLM-Based Multi-Agent system for interpretable RTL code generation. RTLSquad divides the design process into exploration, implementation, and verification & evaluation stages managed by specialized agent squads, generating optimized RTL code through inter-agent collaboration, and providing decision interpretability through the communication process. Experiments show that RTLSquad excels in generating functionally correct RTL code and optimizing PPA performance, while also having the capability to provide decision paths, demonstrating the practical value of our system.",
    "title_zh": "RTLSquad：基于多智能体的可解释寄存器传输级（RTL）设计",
    "abstract_zh": "优化寄存器传输级（RTL）代码对于提升硬件的 PPA（功耗、性能、面积）指标至关重要。大型语言模型（LLMs）为自动化的 RTL 代码生成与优化提供了新思路。然而，现有方法通常缺乏决策可解释性（为决策提供充分且易懂的理由），使硬件工程师难以信任生成结果，从而阻碍其融入设计流程。为此，我们提出 RTLSquad，这是一种用于可解释 RTL 代码生成的新型基于 LLM 的多智能体系统。RTLSquad 将设计流程划分为探索、实现以及验证与评估三个阶段，由专门的智能体小队负责管理，通过智能体之间的协作生成优化的 RTL 代码，并通过沟通过程提供决策可解释性。实验表明，RTLSquad 在生成功能正确的 RTL 代码和优化 PPA 指标方面表现出色，同时具备提供决策路径的能力，体现了该系统的实用价值。"
  },
  {
    "date": "2025-10-09",
    "title": "Faver: Boosting LLM-based RTL Generation with Function Abstracted Verifiable Middleware",
    "authors": "Jianan Mu, Mingyu Shi, Yining Wang, Tianmeng Yang, Bin Sun, Xing Hu, Jing Ye, Huawei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2510.08664v1",
    "source": "arXiv",
    "abstract": "LLM-based RTL generation is an interesting research direction, as it holds the potential to liberate the least automated stage in the current chip design. However, due to the substantial semantic gap between high-level specifications and RTL, coupled with limited training data, existing models struggle with generation accuracy. Drawing on human experience, design with verification helps improving accuracy. However, as the RTL testbench data are even more scarce, it is not friendly for LLMs. Although LLMs excel at higher-level languages like Python/C, they have a huge semantic gap from RTL. When implementing the same functionality, Python/C code and hardware code differ significantly in the spatiotemporal granularity, requiring the LLM not only to consider high-level functional semantics but also to ensure the low-level details align with the circuit code. It is not an easy task. In this paper, we propose a function abstracted verifiable middleware (Faver) that streamlines RTL verification in LLM-based workflows. By mixing LLM-friendly code structures with a rule-based template, Faver decouples the details of circuit verification, allowing the LLM to focus on the functionality itself. In our experiments on the SFT model and open-source models, Faver improved the model's generation accuracy by up to 14%.",
    "title_zh": "Faver：借助函数抽象的可验证中间件提升基于大语言模型的寄存器传输级（RTL）生成",
    "abstract_zh": "基于LLM的RTL生成是一个颇具潜力的研究方向，因为它有望解放当前芯片设计流程中自动化程度最低的阶段。然而，由于高层规格与RTL之间存在显著的语义鸿沟，加之训练数据有限，现有模型在生成准确性方面存在困难。借鉴人类经验，设计与验证相结合有助于提升准确性。但由于RTL测试平台（testbench）数据更为稀缺，这对LLM并不友好。尽管LLM在Python/C等高级语言上表现出色，但它们与RTL之间存在巨大的语义差距。在实现相同功能时，Python/C代码与硬件代码在时空粒度上存在显著差异，这要求LLM不仅要考虑高层功能语义，还要确保低层细节与电路代码保持一致，这并非易事。本文提出了一种函数抽象的可验证中间件（Faver），用于在基于LLM的工作流程中简化RTL验证。通过将对LLM友好的代码结构与基于规则的模板相结合，Faver对电路验证的细节进行解耦，使LLM能够专注于功能本身。在针对SFT模型和开源模型的实验中，Faver将模型的生成准确性最多提升了14%。"
  },
  {
    "date": "2024-12-10",
    "title": "MAGE: A Multi-Agent Engine for Automated RTL Code Generation",
    "authors": "Yujie Zhao, Hejia Zhang, Hanxian Huang, Zhongming Yu, Jishen Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2412.07822v1",
    "source": "arXiv",
    "abstract": "The automatic generation of RTL code (e.g., Verilog) through natural language instructions has emerged as a promising direction with the advancement of large language models (LLMs). However, producing RTL code that is both syntactically and functionally correct remains a significant challenge. Existing single-LLM-agent approaches face substantial limitations because they must navigate between various programming languages and handle intricate generation, verification, and modification tasks. To address these challenges, this paper introduces MAGE, the first open-source multi-agent AI system designed for robust and accurate Verilog RTL code generation. We propose a novel high-temperature RTL candidate sampling and debugging system that effectively explores the space of code candidates and significantly improves the quality of the candidates. Furthermore, we design a novel Verilog-state checkpoint checking mechanism that enables early detection of functional errors and delivers precise feedback for targeted fixes, significantly enhancing the functional correctness of the generated RTL code. MAGE achieves a 95.7% rate of syntactic and functional correctness code generation on VerilogEval-Human 2 benchmark, surpassing the state-of-the-art Claude-3.5-sonnet by 23.3 %, demonstrating a robust and reliable approach for AI-driven RTL design workflows.",
    "title_zh": "MAGE：用于自动化 RTL 代码生成的多智能体引擎",
    "abstract_zh": "随着大语言模型（LLM）的发展，通过自然语言指令自动生成 RTL 代码（如 Verilog）已成为一个前景可期的方向。然而，生成在语法和功能上都正确的 RTL 代码仍然充满挑战。现有的单一 LLM 代理方法存在显著局限，因为它们需要在多种编程语言之间切换，并处理复杂的生成、验证与修改任务。为应对这些挑战，本文提出了 MAGE，这是首个面向稳健且精确的 Verilog RTL 代码生成的开源多智能体 AI 系统。我们提出了一种新颖的高温 RTL 候选采样与调试系统，能够有效探索候选代码空间，并显著提升候选质量。此外，我们设计了全新的 Verilog 状态检查点核查机制，可早期发现功能错误并提供精确反馈以进行定向修复，大幅提升生成代码的功能正确性。在 VerilogEval-Human 2 基准上，MAGE 实现了 95.7% 的语法与功能双正确生成率，较当前最先进的 Claude-3.5-sonnet 提升 23.3%，展示了在 AI 驱动的 RTL 设计流程中的稳健且可靠的方法。"
  },
  {
    "date": "2024-11-21",
    "title": "EDA-Aware RTL Generation with Large Language Models",
    "authors": "Mubashir ul Islam, Humza Sami, Pierre-Emmanuel Gaillardon, Valerio Tenace",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2412.04485v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have become increasingly popular for generating RTL code. However, producing error-free RTL code in a zero-shot setting remains highly challenging for even state-of-the-art LLMs, often leading to issues that require manual, iterative refinement. This additional debugging process can dramatically increase the verification workload, underscoring the need for robust, automated correction mechanisms to ensure code correctness from the start. In this work, we introduce AIvril2, a self-verifying, LLM-agnostic agentic framework aimed at enhancing RTL code generation through iterative corrections of both syntax and functional errors. Our approach leverages a collaborative multi-agent system that incorporates feedback from error logs generated by EDA tools to automatically identify and resolve design flaws. Experimental results, conducted on the VerilogEval-Human benchmark suite, demonstrate that our framework significantly improves code quality, achieving nearly a 3.4$\\times$ enhancement over prior methods. In the best-case scenario, functional pass rates of 77% for Verilog and 66% for VHDL were obtained, thus substantially improving the reliability of LLM-driven RTL code generation.",
    "title_zh": "基于大型语言模型的EDA感知型RTL生成",
    "abstract_zh": "大型语言模型（LLM）在生成 RTL 代码方面日益流行。然而，即使是最先进的 LLM，在零样本设置下生成无错误的 RTL 代码仍然极具挑战性，往往会导致需要人工迭代改进的问题。这一额外的调试过程会显著增加验证工作量，凸显出从一开始就确保代码正确性的健壮自动化纠错机制的必要性。为此，我们提出了 AIvril2，这是一种自验证、与具体 LLM 无关的代理型框架，旨在通过对语法和功能错误进行迭代纠正来提升 RTL 代码生成质量。我们的方法采用协作式多代理系统，结合由 EDA（电子设计自动化）工具生成的错误日志反馈，自动识别并解决设计缺陷。基于 VerilogEval-Human 基准套件的实验结果表明，该框架能够显著提升代码质量，相对于既有方法实现了近 3.4 倍的改进。在最佳情况下，Verilog 的功能通过率达到 77%，VHDL 为 66%，从而大幅提升了基于 LLM 的 RTL 代码生成的可靠性。"
  },
  {
    "date": "2025-07-22",
    "title": "Rethinking LLM-Based RTL Code Optimization Via Timing Logic Metamorphosis",
    "authors": "Zhihao Xu, Bixin Li, Lulu Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2507.16808v1",
    "source": "arXiv",
    "abstract": "Register Transfer Level(RTL) code optimization is crucial for achieving high performance and low power consumption in digital circuit design. However, traditional optimization methods often rely on manual tuning and heuristics, which can be time-consuming and error-prone. Recent studies proposed to leverage Large Language Models(LLMs) to assist in RTL code optimization. LLMs can generate optimized code snippets based on natural language descriptions, potentially speeding up the optimization process. However, existing approaches have not thoroughly evaluated the effectiveness of LLM-Based code optimization methods for RTL code with complex timing logic. To address this gap, we conducted a comprehensive empirical investigation to assess the capability of LLM-Based RTL code optimization methods in handling RTL code with complex timing logic. In this study, we first propose a new benchmark for RTL optimization evaluation. It comprises four subsets, each corresponding to a specific area of RTL code optimization. Then we introduce a method based on metamorphosis to systematically evaluate the effectiveness of LLM-Based RTL code optimization methods.Our key insight is that the optimization effectiveness should remain consistent for semantically equivalent but more complex code. After intensive experiments, we revealed several key findings. (1) LLM-Based RTL optimization methods can effectively optimize logic operations and outperform existing compiler-based methods. (2) LLM-Based RTL optimization methods do not perform better than existing compiler-based methods on RTL code with complex timing logic, particularly in timing control flow optimization and clock domain optimization. This is primarily attributed to the challenges LLMs face in understanding timing logic in RTL code. Based on these findings, we provide insights for further research in leveraging LLMs for RTL code optimization.",
    "title_zh": "通过时序逻辑变换重新思考基于大语言模型的RTL代码优化",
    "abstract_zh": "寄存器传输级（RTL）代码优化对于实现数字电路设计中的高性能和低功耗至关重要。然而，传统优化方法通常依赖手工调参和启发式规则，既耗时又易出错。近期研究提出利用大语言模型（LLM）来辅助 RTL 代码优化。LLM 能根据自然语言描述生成优化的代码片段，有望加速优化过程。然而，现有方法尚未对基于 LLM 的代码优化在处理具有复杂时序逻辑的 RTL 代码时的有效性进行充分评估。为弥补这一缺口，我们开展了一项全面的实证研究，以评估基于 LLM 的 RTL 代码优化方法在应对复杂时序逻辑 RTL 代码方面的能力。\n\n在本研究中，我们首先提出了一个用于评估 RTL 优化的新基准。该基准由四个子集组成，每个子集对应一个特定的 RTL 代码优化领域。随后，我们引入一种基于蜕变关系的系统化方法，来评估基于 LLM 的 RTL 代码优化方法的有效性。我们的关键洞见是：对于语义等价但更复杂的代码，其优化效果应当保持一致。\n\n经过大量实验，我们揭示了几个关键发现。（1）基于 LLM 的 RTL 优化方法能够有效优化逻辑运算，并且优于现有的基于编译器的方法。（2）在具有复杂时序逻辑的 RTL 代码上，尤其是在时序控制流优化和时钟域优化方面，基于 LLM 的方法并不优于现有的基于编译器的方法，其主要原因在于 LLM 在理解 RTL 代码时序逻辑方面面临挑战。基于这些发现，我们为进一步利用 LLM 进行 RTL 代码优化提供了若干研究启示。"
  },
  {
    "date": "2024-08-13",
    "title": "LAAG-RV: LLM Assisted Assertion Generation for RTL Design Verification",
    "authors": "Karthik Maddala, Bhabesh Mali, Chandan Karfa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2409.15281v1",
    "source": "arXiv",
    "abstract": "Writing SystemVerilog Assertions (SVA) is an important but complex step in verifying Register Transfer Level (RTL) designs. Conventionally, experts need to understand the design specifications and write the SVA assertions, which is time-consuming and error-prone. However, with the recent advancement of transformer models, the Large Language Models (LLMs) assisted assertion generation for design verification is gaining interest in recent times. Motivated by this, we proposed a novel LLM-based framework, LAAG-RV, to generate SVA from the natural language specifications of the design. Our framework provides a one-time Verilog loop for signal synchronization in the generated SVA to improve the generated assertion quality. For our experiments, we created a custom LLM based on OpenAI GPT-4. Furthermore, we developed test cases to validate the LLM-generated assertions. Initial observations show that some generated assertions contain issues and did not pass all the test cases. However, by iteratively prompting the LLMs using carefully crafted manual prompts derived from test case failures in a simulator, the framework can generate correct SVAs. Our results on OpenTitan designs demonstrate that LLMs significantly simplify the process of generating assertions, making it efficient and less error-prone.",
    "title_zh": "LAAG-RV：用于RTL设计验证的LLM辅助断言生成",
    "abstract_zh": "编写 SystemVerilog 断言（SVA）是验证寄存器传输级（RTL）设计中重要但复杂的一步。传统上，专家需要理解设计规格说明并编写 SVA 断言，这既耗时又容易出错。随着 Transformer 模型的最新进展，利用大型语言模型（LLM）辅助进行设计验证中的断言生成近来备受关注。受此启发，我们提出了一个新颖的基于 LLM 的框架 LAAG-RV，用于从设计的自然语言规格生成 SVA。我们的框架在生成的 SVA 中提供一次性 Verilog 循环实现信号同步，以提升生成断言的质量。在实验中，我们基于 OpenAI GPT-4 构建了定制的 LLM，并开发测试用例来验证 LLM 生成的断言。初步观察显示，部分生成的断言存在问题，未能通过全部测试用例。然而，通过在仿真器中根据测试失败现象精心设计的人工提示对 LLM 进行迭代提示，框架能够生成正确的 SVA。我们在 OpenTitan 设计上的结果表明，LLM 显著简化了断言生成流程，使其更高效且更不易出错。"
  },
  {
    "date": "2025-11-29",
    "title": "TrojanLoC: LLM-based Framework for RTL Trojan Localization",
    "authors": "Weihua Xiao, Zeng Wang, Minghao Shao, Raghu Vamshi Hemadri, Ozgur Sinanoglu, Muhammad Shafique, Johann Knechtel, Siddharth Garg, Ramesh Karri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.00591v1",
    "source": "arXiv",
    "abstract": "Hardware Trojans (HT s) are a persistent threat to integrated circuits, especially when inserted at the register-transfer level (RTL). Existing methods typically first convert the design into a graph, such as a gate-level netlist or an RTL-derived dataflow graph (DFG), and then use a graph neural network (GNN ) to obtain an embedding of that graph, which (i) loses compact RTL semantics, (ii) relies on shallow GNNs with limited receptive field, and (iii) is largely restricted to coarse, module-level binary HT detection. We propose TrojanLoC, an LLM-based framework for RTL-level HT localization. We use an RTL-finetuned LLM to derive module-level and line-level embeddings directly from RTL code, capturing both global design context and local semantics. Next, we train task-specific classifiers on these embeddings to perform module-level Trojan detection, type prediction, and fine-grained line-level localization. We also introduce TrojanInS, a large synthetic dataset of RTL designs with systematically injected Trojans from four effect-based categories, each accompanied by precise line-level annotations. Our experiments show that TrojanLoC achieves strong module-level performance, reaching 0.99 F1-score for Trojan detection, up to 0.68 higher than baseline, and 0.84 macro-F1 for Trojan-type classification. At the line level, TrojanLoc further achieves up to 0.93 macro-F1, enabling fine-grained localization of Trojan-relevant RTL lines",
    "title_zh": "TrojanLoC：基于大型语言模型的 RTL 级硬件木马定位框架",
    "abstract_zh": "硬件木马（HTs）对集成电路构成持久威胁，尤其是在寄存器传输级（RTL）被植入时。现有方法通常先将设计转换为图，例如门级网表或由RTL派生的数据流图（DFG），再使用图神经网络（GNN）获取该图的嵌入表示，这会(i) 丢失RTL语义的紧凑表达，(ii) 依赖感受野受限的浅层GNN，(iii) 在很大程度上局限于粗粒度的、模块级的二元HT检测。我们提出TrojanLoC，一个基于大语言模型（LLM）的RTL级HT定位框架。我们使用针对RTL微调的LLM，直接从RTL代码提取模块级和行级嵌入，既捕获全局设计上下文，也刻画局部语义。随后，我们在这些嵌入上训练面向任务的分类器，以执行模块级的木马检测、类型预测以及细粒度的行级定位。我们还引入TrojanInS，这是一个大型合成数据集，包含系统性注入的、按效应划分的四类RTL设计木马，并配有精确的行级标注。实验表明，TrojanLoC在模块级上表现出色：木马检测的F1分数达到0.99，较基线最高提升0.68；木马类型分类的宏平均F1为0.84。在线级，TrojanLoc进一步达到最高0.93的宏平均F1，能够对与木马相关的RTL代码行进行细粒度定位。"
  },
  {
    "date": "2024-09-04",
    "title": "RTLRewriter: Methodologies for Large Models aided RTL Code Optimization",
    "authors": "Xufeng Yao, Yiwen Wang, Xing Li, Yingzhao Lian, Ran Chen, Lei Chen, Mingxuan Yuan, Hong Xu, Bei Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2409.11414v1",
    "source": "arXiv",
    "abstract": "Register Transfer Level (RTL) code optimization is crucial for enhancing the efficiency and performance of digital circuits during early synthesis stages. Currently, optimization relies heavily on manual efforts by skilled engineers, often requiring multiple iterations based on synthesis feedback. In contrast, existing compiler-based methods fall short in addressing complex designs. This paper introduces RTLRewriter, an innovative framework that leverages large models to optimize RTL code. A circuit partition pipeline is utilized for fast synthesis and efficient rewriting. A multi-modal program analysis is proposed to incorporate vital visual diagram information as optimization cues. A specialized search engine is designed to identify useful optimization guides, algorithms, and code snippets that enhance the model ability to generate optimized RTL. Additionally, we introduce a Cost-aware Monte Carlo Tree Search (C-MCTS) algorithm for efficient rewriting, managing diverse retrieved contents and steering the rewriting results. Furthermore, a fast verification pipeline is proposed to reduce verification cost. To cater to the needs of both industry and academia, we propose two benchmarking suites: the Large Rewriter Benchmark, targeting complex scenarios with extensive circuit partitioning, optimization trade-offs, and verification challenges, and the Small Rewriter Benchmark, designed for a wider range of scenarios and patterns. Our comparative analysis with established compilers such as Yosys and E-graph demonstrates significant improvements, highlighting the benefits of integrating large models into the early stages of circuit design. We provide our benchmarks at https://github.com/yaoxufeng/RTLRewriter-Bench.",
    "title_zh": "RTLRewriter：大模型辅助的RTL代码优化方法论",
    "abstract_zh": "寄存器传输级（RTL）代码优化在综合的早期阶段对于提升数字电路的效率与性能至关重要。当前的优化工作高度依赖经验丰富的工程师的人工投入，通常需要基于综合反馈进行多次迭代。相比之下，现有的基于编译器的方法难以有效应对复杂设计。本文提出了RTLRewriter，这一利用大模型优化RTL代码的创新框架。我们采用电路划分流水线，以实现快速综合和高效重写；提出多模态程序分析，将关键的视觉图信息作为优化线索纳入；设计专用搜索引擎，识别有用的优化指南、算法与代码片段，以增强模型生成优化RTL的能力。此外，我们引入成本感知蒙特卡洛树搜索（C-MCTS）算法，用于高效重写，能够管理多样的检索内容并引导重写结果。我们还提出快速验证流水线，以降低验证成本。为满足工业界与学术界的需求，我们构建了两套基准测试：大型重写基准，面向包含大规模电路划分、优化取舍与验证挑战的复杂场景；以及小型重写基准，适用于更广泛的场景与模式。与Yosys和E-graph等成熟编译器的对比分析显示出显著提升，彰显了在电路设计早期引入大模型的价值。我们的基准数据集发布于：https://github.com/yaoxufeng/RTLRewriter-Bench。"
  },
  {
    "date": "2025-11-17",
    "title": "Assessing Large Language Models in Generating RTL Design Specifications",
    "authors": "Hung-Ming Huang, Yu-Hsin Yang, Fu-Chieh Chang, Yun-Chia Hsu, Yin-Yu Lin, Ming-Fang Tsai, Chun-Chih Yang, Pei-Yuan Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.00045v1",
    "source": "arXiv",
    "abstract": "As IC design grows more complex, automating comprehension and documentation of RTL code has become increasingly important. Engineers currently should manually interpret existing RTL code and write specifications, a slow and error-prone process. Although LLMs have been studied for generating RTL from specifications, automated specification generation remains underexplored, largely due to the lack of reliable evaluation methods. To address this gap, we investigate how prompting strategies affect RTL-to-specification quality and introduce metrics for faithfully evaluating generated specs. We also benchmark open-source and commercial LLMs, providing a foundation for more automated and efficient specification workflows in IC design.",
    "title_zh": "评估大型语言模型在生成 RTL 设计规范方面的能力",
    "abstract_zh": "随着IC设计日益复杂，自动化地理解并编写RTL代码的文档变得愈发重要。当前工程师通常需要手动解读现有RTL代码并撰写规格说明，这一过程既缓慢又容易出错。尽管已有研究利用大型语言模型（LLM）根据规格生成RTL，自动化生成规格这一方向仍缺乏深入探索，主要是因为缺少可靠的评估方法。为填补这一空白，我们研究提示策略如何影响从RTL到规格的生成质量，并提出用于忠实评估生成规格的度量指标。同时，我们对开源与商业LLM进行基准评测，为在IC设计中实现更自动化、更高效的规格制定工作流程奠定基础。"
  },
  {
    "date": "2023-11-09",
    "title": "Verilog-to-PyG -- A Framework for Graph Learning and Augmentation on RTL Designs",
    "authors": "Yingjie Li, Mingju Liu, Alan Mishchenko, Cunxi Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2311.05722v1",
    "source": "arXiv",
    "abstract": "The complexity of modern hardware designs necessitates advanced methodologies for optimizing and analyzing modern digital systems. In recent times, machine learning (ML) methodologies have emerged as potent instruments for assessing design quality-of-results at the Register-Transfer Level (RTL) or Boolean level, aiming to expedite design exploration of advanced RTL configurations. In this presentation, we introduce an innovative open-source framework that translates RTL designs into graph representation foundations, which can be seamlessly integrated with the PyTorch Geometric graph learning platform. Furthermore, the Verilog-to-PyG (V2PYG) framework is compatible with the open-source Electronic Design Automation (EDA) toolchain OpenROAD, facilitating the collection of labeled datasets in an utterly open-source manner. Additionally, we will present novel RTL data augmentation methods (incorporated in our framework) that enable functional equivalent design augmentation for the construction of an extensive graph-based RTL design database. Lastly, we will showcase several using cases of V2PYG with detailed scripting examples. V2PYG can be found at \\url{https://yu-maryland.github.io/Verilog-to-PyG/}.",
    "title_zh": "Verilog-to-PyG——一个面向RTL设计的图学习与数据增强框架",
    "abstract_zh": "现代硬件设计的复杂性要求采用先进的方法来优化和分析数字系统。近年来，机器学习（ML）方法已成为在寄存器传输级（RTL）或布尔级评估设计结果质量（QoR）的有力工具，旨在加速对先进 RTL 配置的设计空间探索。在本次报告中，我们介绍一个创新的开源框架，它将 RTL 设计转换为图表示形式，并可与 PyTorch Geometric 图学习平台无缝集成。此外，Verilog‑to‑PyG（V2PYG）框架与开源电子设计自动化（EDA）工具链 OpenROAD 兼容，从而能够以完全开源的方式收集标注数据集。我们还将介绍新的 RTL 数据增强方法（已集成到我们的框架中），通过功能等价的设计增强，构建大规模的基于图的 RTL 设计数据库。最后，我们将给出多个 V2PYG 的应用案例，并提供详细的脚本示例。V2PYG 项目地址：https://yu-maryland.github.io/Verilog-to-PyG/"
  },
  {
    "date": "2025-07-21",
    "title": "VeriRAG: A Retrieval-Augmented Framework for Automated RTL Testability Repair",
    "authors": "Haomin Qi, Yuyang Du, Lihao Zhang, Soung Chang Liew, Kexin Chen, Yining Du",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2507.15664v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have demonstrated immense potential in computer-aided design (CAD), particularly for automated debugging and verification within electronic design automation (EDA) tools. However, Design for Testability (DFT) remains a relatively underexplored area. This paper presents VeriRAG, the first LLM-assisted DFT-EDA framework. VeriRAG leverages a Retrieval-Augmented Generation (RAG) approach to enable LLM to revise code to ensure DFT compliance. VeriRAG integrates (1) an autoencoder-based similarity measurement model for precise retrieval of reference RTL designs for the LLM, and (2) an iterative code revision pipeline that allows the LLM to ensure DFT compliance while maintaining synthesizability. To support VeriRAG, we introduce VeriDFT, a Verilog-based DFT dataset curated for DFT-aware RTL repairs. VeriRAG retrieves structurally similar RTL designs from VeriDFT, each paired with a rigorously validated correction, as references for code repair. With VeriRAG and VeriDFT, we achieve fully automated DFT correction -- resulting in a 7.72-fold improvement in successful repair rate compared to the zero-shot baseline (Fig. 5 in Section V). Ablation studies further confirm the contribution of each component of the VeriRAG framework. We open-source our data, models, and scripts at https://github.com/yuyangdu01/LLM4DFT.",
    "title_zh": "VeriRAG：一种用于自动化RTL可测试性修复的检索增强框架",
    "abstract_zh": "大型语言模型（LLMs）在计算机辅助设计（CAD）领域展现出巨大潜力，尤其是在电子设计自动化（EDA）工具中的自动调试与验证方面。然而，可测试性设计（DFT）仍相对缺乏系统性探索。本文提出了VeriRAG，这是首个由LLM辅助的DFT-EDA框架。VeriRAG采用检索增强生成（RAG）方法，使LLM能够通过修改代码来确保满足DFT要求。VeriRAG集成了：(1) 基于自编码器的相似度度量模型，为LLM精确检索参考RTL设计；以及(2) 迭代式代码修订流程，使LLM在保持可综合性的同时确保DFT合规。为支撑VeriRAG，我们构建了VeriDFT——一个面向DFT感知型RTL修复而整理的、基于Verilog的DFT数据集。VeriRAG从VeriDFT中检索结构相似的RTL设计，这些设计均配有经严格验证的修正，作为代码修复的参考。借助VeriRAG与VeriDFT，我们实现了全自动的DFT修复——相较零样本基线，成功修复率提升了7.72倍（见第V节图5）。消融实验进一步验证了VeriRAG框架各组件的贡献。我们已在 https://github.com/yuyangdu01/LLM4DFT 开源数据、模型与脚本。"
  },
  {
    "date": "2024-09-02",
    "title": "OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection",
    "authors": "Fan Cui, Chenyang Yin, Kexing Zhou, Youwei Xiao, Guangyu Sun, Qiang Xu, Qipeng Guo, Demin Song, Dahua Lin, Xingcheng Zhang, Yun, Liang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2407.16237v2",
    "source": "arXiv",
    "abstract": "Recent studies have demonstrated the significant potential of Large Language Models (LLMs) in generating Register Transfer Level (RTL) code, with notable advancements showcased by commercial models such as GPT-4 and Claude3-Opus. However, these proprietary LLMs often raise concerns regarding privacy and security. While open-source LLMs offer solutions to these concerns, they typically underperform commercial models in RTL code generation tasks, primarily due to the scarcity of high-quality open-source RTL datasets. To address this challenge, we introduce OriGen , a fully open-source framework that incorporates self-reflection capabilities and a novel dataset augmentation methodology for generating high-quality, large-scale RTL code. Our approach employs a code-tocode augmentation technique to enhance the quality of open-source RTL code datasets. Furthermore, OriGen can rectify syntactic errors through a self-reflection process that leverages compiler feedback. Experimental results demonstrate that OriGen significantly outperforms other open-source alternatives in RTL code generation. It surpasses the previous best-performing open-source LLM by 12.8% and even exceeds GPT-4 Turbo in the pass@1 metric on the VerilogEval-Human benchmark. Moreover, OriGen exhibits superior capabilities in self-reflection and error correction, outperforming GPT-4 by 19.9% on a benchmark designed to evaluate self-reflection capabilities.",
    "title_zh": "OriGen：通过代码到代码增强与自我反思提升 RTL 代码生成",
    "abstract_zh": "最新研究表明，大语言模型（LLMs）在生成寄存器传输级（RTL）代码方面具有显著潜力，商业模型如 GPT-4 和 Claude 3 Opus 已展示出明显进展。然而，这些专有 LLM 往往引发隐私与安全方面的担忧。尽管开源 LLM 能在一定程度上缓解这些问题，但由于高质量开源 RTL 数据集的稀缺，它们在 RTL 代码生成任务上通常不及商业模型。为解决这一挑战，我们提出了 OriGen——一个完全开源的框架，融合自我反思能力，并采用新颖的数据集增强方法，用于生成高质量、大规模的 RTL 代码。我们的方法通过“代码到代码”的数据增强技术提升开源 RTL 代码数据集的质量。此外，OriGen 还能通过利用编译器反馈的自我反思过程来纠正语法错误。实验结果表明，OriGen 在 RTL 代码生成方面显著优于其他开源替代方案：相较于此前表现最好的开源 LLM，提升了 12.8%；并且在 VerilogEval-Human 基准上的 pass@1 指标上超越了 GPT-4 Turbo。与此同时，OriGen 在自我反思与错误纠正能力方面也更为出色，在专门用于评估自我反思能力的基准上较 GPT-4 提升了 19.9%。"
  },
  {
    "date": "2025-11-26",
    "title": "R3A: Reliable RTL Repair Framework with Multi-Agent Fault Localization and Stochastic Tree-of-Thoughts Patch Generation",
    "authors": "Zizhang Luo, Fan Cui, Kexing Zhou, Runlin Guo, Mile Xia, Hongyuan Hou, Yun Liang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20090v2",
    "source": "arXiv",
    "abstract": "Repairing RTL bugs is crucial for hardware design and verification. Traditional automatic program repair (APR) methods define dedicated search spaces to locate and fix bugs with program synthesis. However, they heavily rely on fixed templates and can only deal with limited bugs. As an alternative, Large Language Models with the ability to understand code semantics can be explored for RTL repair. However, they suffer from unreliable outcomes due to inherent randomness and long input contexts of RTL code and waveform. To address these challenges, we propose R3A, an LLM-based automatic RTL program repair framework upon the basic model to improve reliability. R3A proposes the stochastic Tree-Of-Thoughts method to control a patch generation agent to explore a validated solution for the bug. The algorithm samples search states according to a heuristic function to balance between exploration and exploitation for a reliable outcome. Besides, R3A proposes a multi-agent fault localization method to find fault candidates as the starting points for the patch generation agent, further increasing the reliability. Experiments show R3A can fix 90.6% of bugs in the RTL-repair dataset within a given time limit, which covers 45% more bugs than traditional methods and other LLM-based approaches, while achieving an 86.7% pass@5 rate on average, showing a high reliability.",
    "title_zh": "R3A：可靠的RTL修复框架，采用多智能体故障定位与随机思维树补丁生成",
    "abstract_zh": "修复 RTL 缺陷对硬件设计与验证至关重要。传统的自动程序修复（APR）方法通过程序综合为定位并修复缺陷定义专用的搜索空间，但它们严重依赖固定模板，只能处理有限类型的缺陷。作为替代，具备代码语义理解能力的大型语言模型可用于 RTL 修复。然而，由于内在的随机性以及 RTL 代码与波形所带来的长输入上下文，这类方法的结果往往不够可靠。为应对这些挑战，我们提出了 R3A——一种基于 LLM 的自动 RTL 程序修复框架，在基础模型之上提升结果的可靠性。R3A 提出随机思维树（Tree-of-Thoughts）方法，用以控制补丁生成代理，探索针对缺陷的经验证解。该算法依据启发式函数对搜索状态进行采样，在探索与利用之间取得平衡，从而获得更可靠的结果。此外，R3A 提出多智能体故障定位方法，以发现故障候选作为补丁生成代理的起点，进一步提升可靠性。实验表明，R3A 能在给定时间限制内修复 RTL-repair 数据集中的 90.6% 的缺陷，相比传统方法与其他基于 LLM 的方法多覆盖 45% 的缺陷，并且平均实现 86.7% 的 pass@5，显示出较高的可靠性。"
  },
  {
    "date": "2023-11-14",
    "title": "MasterRTL: A Pre-Synthesis PPA Estimation Framework for Any RTL Design",
    "authors": "Wenji Fang, Yao Lu, Shang Liu, Qijun Zhang, Ceyu Xu, Lisa Wu Wills, Hongce Zhang, Zhiyao Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2311.08441v1",
    "source": "arXiv",
    "abstract": "In modern VLSI design flow, the register-transfer level (RTL) stage is a critical point, where designers define precise design behavior with hardware description languages (HDLs) like Verilog. Since the RTL design is in the format of HDL code, the standard way to evaluate its quality requires time-consuming subsequent synthesis steps with EDA tools. This time-consuming process significantly impedes design optimization at the early RTL stage. Despite the emergence of some recent ML-based solutions, they fail to maintain high accuracy for any given RTL design. In this work, we propose an innovative pre-synthesis PPA estimation framework named MasterRTL. It first converts the HDL code to a new bit-level design representation named the simple operator graph (SOG). By only adopting single-bit simple operators, this SOG proves to be a general representation that unifies different design types and styles. The SOG is also more similar to the target gate-level netlist, reducing the gap between RTL representation and netlist. In addition to the new SOG representation, MasterRTL proposes new ML methods for the RTL-stage modeling of timing, power, and area separately. Compared with state-of-the-art solutions, the experiment on a comprehensive dataset with 90 different designs shows accuracy improvement by 0.33, 0.22, and 0.15 in correlation for total negative slack (TNS), worst negative slack (WNS), and power, respectively.",
    "title_zh": "MasterRTL：一种适用于任何 RTL 设计的前综合 PPA 估计框架",
    "abstract_zh": "在现代超大规模集成电路（VLSI）设计流程中，寄存器传输级（RTL）阶段至关重要，设计人员在此阶段使用 Verilog 等硬件描述语言（HDL）来精确定义设计行为。由于 RTL 设计以 HDL 代码的形式存在，评估其质量的标准方法需要借助 EDA 工具进行耗时的后续综合步骤。这一耗时过程显著阻碍了在 RTL 早期阶段的设计优化。尽管近年来出现了一些基于机器学习（ML）的解决方案，但它们难以在任意 RTL 设计上维持高精度。\n\n为此，我们提出了一种名为 MasterRTL 的创新型预综合 PPA（性能/功耗/面积）估计框架。该框架首先将 HDL 代码转换为一种新的比特级设计表示——简单运算符图（SOG）。通过仅采用单比特的简单运算符，SOG 被证明是一种能够统一不同设计类型与风格的通用表示。SOG 也更接近目标的门级网表，从而缩小了 RTL 表示与网表之间的差距。除了新的 SOG 表示之外，MasterRTL 还分别提出了面向 RTL 阶段的时序、功耗与面积建模的全新机器学习方法。与当前最先进的方案相比，在包含 90 个不同设计的综合数据集上的实验表明，对于总负裕量（TNS）、最坏负裕量（WNS）和功耗的相关性，分别提升了 0.33、0.22 和 0.15。"
  },
  {
    "date": "2025-10-24",
    "title": "REvolution: An Evolutionary Framework for RTL Generation driven by Large Language Models",
    "authors": "Kyungjun Min, Kyumin Cho, Junhwan Jang, Seokhyeong Kang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2510.21407v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are used for Register-Transfer Level (RTL) code generation, but they face two main challenges: functional correctness and Power, Performance, and Area (PPA) optimization. Iterative, feedback-based methods partially address these, but they are limited to local search, hindering the discovery of a global optimum. This paper introduces REvolution, a framework that combines Evolutionary Computation (EC) with LLMs for automatic RTL generation and optimization. REvolution evolves a population of candidates in parallel, each defined by a design strategy, RTL implementation, and evaluation feedback. The framework includes a dual-population algorithm that divides candidates into Fail and Success groups for bug fixing and PPA optimization, respectively. An adaptive mechanism further improves search efficiency by dynamically adjusting the selection probability of each prompt strategy according to its success rate. Experiments on the VerilogEval and RTLLM benchmarks show that REvolution increased the initial pass rate of various LLMs by up to 24.0 percentage points. The DeepSeek-V3 model achieved a final pass rate of 95.5\\%, comparable to state-of-the-art results, without the need for separate training or domain-specific tools. Additionally, the generated RTL designs showed significant PPA improvements over reference designs. This work introduces a new RTL design approach by combining LLMs' generative capabilities with EC's broad search power, overcoming the local-search limitations of previous methods.",
    "title_zh": "REvolution：一种由大型语言模型驱动的用于寄存器传输级（RTL）生成的演化框架",
    "abstract_zh": "大型语言模型（LLM）已用于寄存器传输级（RTL）代码生成，但面临两大挑战：功能正确性以及功耗、性能与面积（PPA）优化。迭代的、基于反馈的方法在一定程度上缓解了这些问题，但受限于局部搜索，难以发现全局最优。本文提出 REvolution，这一将进化计算（EC）与 LLM 结合的自动 RTL 生成与优化框架。REvolution 并行进化一个候选种群，每个候选由设计策略、RTL 实现与评估反馈定义。该框架包含一种双种群算法，将候选划分为失败（Fail）与成功（Success）两组，分别用于缺陷修复和 PPA 优化。一个自适应机制进一步提升搜索效率，依据各提示策略的成功率动态调整其被选概率。在 VerilogEval 与 RTLLM 基准上的实验表明，REvolution 使多种 LLM 的初始通过率最高提升了 24.0 个百分点。DeepSeek-V3 模型的最终通过率达到 95.5%，在无需额外训练或领域专用工具的情况下，可与当前最先进结果相当。此外，生成的 RTL 设计相较参考设计在 PPA 上也显著改进。该工作通过将 LLM 的生成能力与 EC 的广域搜索能力相结合，提出了一种新的 RTL 设计范式，克服了以往方法的局部搜索局限。"
  },
  {
    "date": "2025-02-25",
    "title": "DeepCircuitX: A Comprehensive Repository-Level Dataset for RTL Code Understanding, Generation, and PPA Analysis",
    "authors": "Zeju Li, Changran Xu, Zhengyuan Shi, Zedong Peng, Yi Liu, Yunhao Zhou, Lingfeng Zhou, Chengyu Ma, Jianyuan Zhong, Xi Wang, Jieru Zhao, Zhufei Chu, Xiaoyan Yang, Qiang Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2502.18297v1",
    "source": "arXiv",
    "abstract": "This paper introduces DeepCircuitX, a comprehensive repository-level dataset designed to advance RTL (Register Transfer Level) code understanding, generation, and power-performance-area (PPA) analysis. Unlike existing datasets that are limited to either file-level RTL code or physical layout data, DeepCircuitX provides a holistic, multilevel resource that spans repository, file, module, and block-level RTL code. This structure enables more nuanced training and evaluation of large language models (LLMs) for RTL-specific tasks. DeepCircuitX is enriched with Chain of Thought (CoT) annotations, offering detailed descriptions of functionality and structure at multiple levels. These annotations enhance its utility for a wide range of tasks, including RTL code understanding, generation, and completion. Additionally, the dataset includes synthesized netlists and PPA metrics, facilitating early-stage design exploration and enabling accurate PPA prediction directly from RTL code. We demonstrate the dataset's effectiveness on various LLMs finetuned with our dataset and confirm the quality with human evaluations. Our results highlight DeepCircuitX as a critical resource for advancing RTL-focused machine learning applications in hardware design automation.Our data is available at https://zeju.gitbook.io/lcm-team.",
    "title_zh": "DeepCircuitX：一个面向寄存器传输级（RTL）代码理解、生成与PPA（功耗、性能与面积）分析的全面仓库级数据集",
    "abstract_zh": "本文介绍了 DeepCircuitX，这是一套面向推进 RTL（寄存器传输级）代码理解、生成以及功耗-性能-面积（PPA）分析的综合性仓库级数据集。与现有仅限于文件级 RTL 代码或物理版图数据的数据集不同，DeepCircuitX 提供了一个整体的、多层级的资源，覆盖仓库、文件、模块和块级别的 RTL 代码。这一结构使得针对 RTL 特定任务的大型语言模型（LLMs）的训练与评估更加细致。DeepCircuitX 还结合了思维链（CoT）标注，在多个层级提供对功能与结构的详细描述。这些标注提升了其在 RTL 代码理解、生成与补全等广泛任务中的实用性。此外，数据集包含综合生成的网表与 PPA 指标，有助于早期设计探索，并能直接从 RTL 代码进行准确的 PPA 预测。我们在使用该数据集微调的多种 LLM 上展示了其有效性，并通过人工评估验证了数据质量。我们的结果表明，DeepCircuitX 是推动面向硬件设计自动化的 RTL 方向机器学习应用的关键资源。我们的数据可在 https://zeju.gitbook.io/lcm-team 获取。"
  },
  {
    "date": "2024-05-06",
    "title": "Annotating Slack Directly on Your Verilog: Fine-Grained RTL Timing Evaluation for Early Optimization",
    "authors": "Wenji Fang, Shang Liu, Hongce Zhang, Zhiyao Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2403.18453v2",
    "source": "arXiv",
    "abstract": "In digital IC design, compared with post-synthesis netlists or layouts, the early register-transfer level (RTL) stage offers greater optimization flexibility for both designers and EDA tools. However, timing information is typically unavailable at this early stage. Some recent machine learning (ML) solutions propose to predict the total negative slack (TNS) and worst negative slack (WNS) of an entire design at the RTL stage, but the fine-grained timing information of individual registers remains unavailable. In this work, we address the unique challenges of RTL timing prediction and introduce our solution named RTL-Timer. To the best of our knowledge, this is the first fine-grained general timing estimator applicable to any given design. RTL-Timer explores multiple promising RTL representations and proposes customized loss functions to capture the maximum arrival time at register endpoints. RTL-Timer's fine-grained predictions are further applied to guide optimization in a standard synthesis flow. The average results on unknown test designs demonstrate a correlation above 0.89, contributing around 3% WNS and 10% TNS improvement after optimization.",
    "title_zh": "直接在你的 Verilog 中标注时序裕量：用于早期优化的细粒度 RTL 时序评估",
    "abstract_zh": "在数字集成电路设计中，与综合后网表或版图相比，早期的寄存器传输级（RTL）阶段为设计人员和EDA工具提供了更大的优化灵活性。然而，在这一早期阶段通常无法获得时序信息。近期一些机器学习（ML）方法提出在RTL阶段预测整个设计的总负裕量（TNS）和最差负裕量（WNS），但针对单个寄存器的细粒度时序信息仍不可用。在本工作中，我们针对RTL时序预测的独特挑战提出了名为RTL-Timer的解决方案。据我们所知，这是首个适用于任意给定设计的细粒度通用时序估计器。RTL-Timer探索了多种有前景的RTL表示方式，并提出了定制化损失函数，以捕获寄存器端点的最大到达时间。RTL-Timer的细粒度预测进一步用于指导标准综合流程中的优化。在未知测试设计上的平均结果显示相关系数超过0.89，并在优化后带来约3%的WNS改善和10%的TNS改善。"
  },
  {
    "date": "2025-05-30",
    "title": "TuRTLe: A Unified Evaluation of LLMs for RTL Generation",
    "authors": "Dario Garcia-Gasulla, Gokcen Kestor, Emanuele Parisi, Miquel Albertí-Binimelis, Cristian Gutierrez, Razine Moundir Ghorab, Orlando Montenegro, Bernat Homs, Miquel Moreto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2504.01986v2",
    "source": "arXiv",
    "abstract": "The rapid advancements in LLMs have driven the adoption of generative AI in various domains, including Electronic Design Automation (EDA). Unlike traditional software development, EDA presents unique challenges, as generated RTL code must not only be syntactically correct and functionally accurate but also synthesizable by hardware generators while meeting performance, power, and area constraints. These additional requirements introduce complexities that existing code-generation benchmarks often fail to capture, limiting their effectiveness in evaluating LLMs for RTL generation. To address this gap, we propose TuRTLe, a unified evaluation framework designed to systematically assess LLMs across key RTL generation tasks. TuRTLe integrates multiple existing benchmarks and automates the evaluation process, enabling a comprehensive assessment of LLM performance in syntax correctness, functional correctness, synthesis, PPA optimization, and exact line completion. Using this framework, we benchmark a diverse set of open LLMs and analyze their strengths and weaknesses in EDA-specific tasks. Our results show that reasoning-based models, such as DeepSeek R1, consistently outperform others across multiple evaluation criteria, but at the cost of increased computational overhead and inference latency. Additionally, base models are better suited in module completion tasks, while instruct-tuned models perform better in specification-to-RTL tasks.",
    "title_zh": "TuRTLe：面向RTL生成的大型语言模型统一评测",
    "abstract_zh": "大型语言模型（LLMs）的快速进步推动了生成式人工智能在各个领域的应用，其中也包括电子设计自动化（EDA）。与传统软件开发不同，EDA 面临独特挑战：生成的寄存器传输级（RTL）代码不仅要语法正确、功能准确，还必须能够被综合工具成功综合，并满足性能、功耗与面积（PPA）约束。这些额外要求带来了现有代码生成基准往往难以体现的复杂性，从而限制了它们在评估用于 RTL 生成的 LLM 时的有效性。\n\n为弥补这一空白，我们提出了 TuRTLe——一个统一的评测框架，用于系统地评估 LLM 在关键 RTL 生成任务中的表现。TuRTLe 集成了多个现有基准并实现评测流程自动化，能够从语法正确性、功能正确性、可综合性、PPA 优化以及精确行级补全等方面对 LLM 的性能进行全面评估。基于该框架，我们对多样化的开源大语言模型进行了基准测试，分析了它们在 EDA 特定任务中的优劣势。结果表明，推理型模型（如 DeepSeek R1）在多项评测指标上持续优于其他模型，但代价是更高的计算开销与推理延迟。此外，基础模型更适合模块补全任务，而指令微调模型在从规格说明到 RTL 的生成任务上表现更佳。"
  },
  {
    "date": "2025-02-22",
    "title": "Machine Learning Framework for Early Power, Performance, and Area Estimation of RTL",
    "authors": "Anindita Chattopadhyay, Vijay Kumar Sutrakar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2502.16203v1",
    "source": "arXiv",
    "abstract": "A critical stage in the evolving landscape of VLSI design is the design phase that is transformed into register-transfer level (RTL), which specifies system functionality through hardware description languages like Verilog. Generally, evaluating the quality of an RTL design demands full synthesis via electronic design automation (EDA) tool is time-consuming process that is not well-suited to rapid design iteration and optimization. Although recent breakthroughs in machine Learning (ML) have brought early prediction models, these methods usually do not provide robust and generalizable solutions with respect to a wide range of RTL designs. This paper proposes a pre-synthesis framework that makes early estimation of power, performance and area (PPA) metrics directly from the hardware description language (HDL) code making direct use of library files instead of toggle files. The proposed framework introduces a bit-level representation referred to as the simple operator graph (SOG), which uses single-bit operators to generate a generalized and flexible structure that closely mirrors the characteristics of post synthesis design. The proposed model bridges the RTL and post-synthesis design, which will help in precisely predicting key metrics. The proposed tree-based ML framework shows superior predictive performance PPA estimation. Validation is carried out on 147 distinct RTL designs. The proposed model with 147 different designs shows accuracy of 98%, 98%, and 90% for WNS, TNS and power, respectively, indicates significant accuracy improvements relative to state-of-the-art methods.",
    "title_zh": "用于RTL早期功耗、性能与面积估算的机器学习框架",
    "abstract_zh": "在不断演进的超大规模集成电路（VLSI）设计版图中，一个关键阶段是将设计转化为寄存器传输级（RTL），它通过 Verilog 等硬件描述语言（HDL）来规定系统功能。通常，评估 RTL 设计质量需要借助电子设计自动化（EDA）工具进行完整综合，这一过程耗时漫长，不利于快速的设计迭代与优化。尽管近期的机器学习（ML）突破带来了早期预测模型，这些方法通常难以在广泛的 RTL 设计范围内提供稳健且具备泛化能力的解决方案。\n\n本文提出一种预综合框架，直接从 HDL 代码进行功耗、性能与面积（PPA）指标的早期估计，采用库文件而非切换活动文件（toggle file）。该框架引入一种位级表示——简单运算符图（SOG），使用单比特运算符生成一种通用且灵活的结构，能够紧密贴合综合后设计的特征。所提出的模型在 RTL 与综合后设计之间搭建桥梁，有助于更精确地预测关键指标。基于树的机器学习框架在 PPA 估计方面展现出更优的预测性能。我们在 147 个不同的 RTL 设计上进行了验证，所提出的模型在最坏负裕量（WNS）、总负裕量（TNS）和功耗上的准确率分别达到 98%、98% 和 90%，相较于当前最先进的方法具有显著的准确性提升。"
  },
  {
    "date": "2025-08-24",
    "title": "VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation",
    "authors": "Anjiang Wei, Huanmi Tan, Tarun Suresh, Daniel Mendoza, Thiago S. F. X. Teixeira, Ke Wang, Caroline Trippel, Alex Aiken",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2504.15659v2",
    "source": "arXiv",
    "abstract": "Recent advances in Large Language Models (LLMs) have sparked growing interest in applying them to Electronic Design Automation (EDA) tasks, particularly Register Transfer Level (RTL) code generation. While several RTL datasets have been introduced, most focus on syntactic validity rather than functional validation with tests, leading to training examples that compile but may not implement the intended behavior. We present VERICODER, a model for RTL code generation fine-tuned on a dataset validated for functional correctness. This fine-tuning dataset is constructed using a novel methodology that combines unit test generation with feedback-directed refinement. Given a natural language specification and an initial RTL design, we prompt a teacher model (GPT-4o-mini) to generate unit tests and iteratively revise the RTL design based on its simulation results using the generated tests. If necessary, the teacher model also updates the tests to ensure they comply with the natural language specification. As a result of this process, every example in our dataset is functionally validated, consisting of a natural language description, an RTL implementation, and passing tests. Fine-tuned on this dataset of 125,777 examples, VERICODER achieves state-of-the-art metrics in functional correctness on VerilogEval and RTLLM, with relative gains of up to 71.7% and 27.4%, respectively. An ablation study further shows that models trained on our functionally validated dataset outperform those trained on functionally non-validated datasets, underscoring the importance of high-quality datasets in RTL code generation. Our code, data, and models are publicly available at https://github.com/Anjiang-Wei/VeriCoder",
    "title_zh": "VeriCoder：通过功能正确性验证提升基于大语言模型的寄存器传输级（RTL）代码生成",
    "abstract_zh": "大型语言模型（LLMs）的最新进展激发了将其应用于电子设计自动化（EDA）任务的广泛兴趣，尤其是寄存器传输级（RTL）代码生成。尽管已有若干 RTL 数据集被提出，但多数更关注语法有效性而非通过测试进行的功能验证，导致训练样本可以编译却可能无法实现预期行为。我们提出 VERICODER，这是一种在功能正确性验证数据集上微调的 RTL 代码生成模型。该微调数据集通过一种新方法构建，结合了单元测试生成与反馈驱动的迭代优化。给定自然语言规格说明和初始 RTL 设计，我们提示教师模型（GPT-4o-mini）生成单元测试，并依据使用这些测试进行仿真得到的结果迭代修订 RTL 设计。必要时，教师模型还会更新测试，以确保其符合自然语言规格说明。通过这一过程，我们的数据集中的每个样例都获得了功能验证，由自然语言描述、RTL 实现以及通过的测试组成。在包含 125,777 个样例的数据集上微调后，VERICODER 在 VerilogEval 和 RTLLM 上的功能正确性指标达到业内领先水平，分别实现最高 71.7% 和 27.4% 的相对提升。消融研究进一步表明，基于我们功能验证数据集训练的模型优于基于未进行功能验证的数据集训练的模型，强调了高质量数据集在 RTL 代码生成中的重要性。我们的代码、数据和模型已在 https://github.com/Anjiang-Wei/VeriCoder 公开。"
  },
  {
    "date": "2025-11-27",
    "title": "VeriDispatcher: Multi-Model Dispatching through Pre-Inference Difficulty Prediction for RTL Generation Optimization",
    "authors": "Zeng Wang, Weihua Xiao, Minghao Shao, Raghu Vamshi Hemadri, Ozgur Sinanoglu, Muhammad Shafique, Ramesh Karri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.22749v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) show strong performance in RTL generation, but different models excel on different tasks because of architecture and training differences. Prior work mainly prompts or finetunes a single model. What remains not well studied is how to coordinate multiple different LLMs so they jointly improve RTL quality while also reducing cost, instead of running all models and choosing the best output. We define this as the multi-LLM RTL generation problem. We propose VeriDispatcher, a multi-LLM RTL generation framework that dispatches each RTL task to suitable LLMs based on pre-inference difficulty prediction. For each model, we train a compact classifier over semantic embeddings of task descriptions, using difficulty scores derived from benchmark variants that combine syntax, structural similarity, and functional correctness. At inference, VeriDispatcher uses these predictors to route tasks to a selected subset of LLMs. Across 10 diverse LLMs on RTLLM and VerilogEval, VeriDispatcher achieves up to 18% accuracy improvement on RTLLM using only 40% of commercial calls, and on VerilogEval maintains accuracy while reducing commercial usage by 25%, enabling cost-effective, high-quality LLM deployment in hardware design automation.",
    "title_zh": "VeriDispatcher：通过推理前难度预测进行多模型调度，以优化RTL生成",
    "abstract_zh": "大型语言模型（LLM）在RTL生成方面表现出色，但由于架构与训练的差异，不同模型在不同任务上各有所长。既有工作主要通过为单一模型设计提示词或进行微调。尚未被充分研究的是：如何协调多种不同的LLM，使其在降低成本的同时共同提升RTL质量，而不是简单地运行所有模型再从中挑选最佳输出。我们将此定义为多LLM协同的RTL生成问题。\n\n我们提出VeriDispatcher，这是一种基于推理前难度预测的多LLM RTL生成框架，可将每个RTL任务分派给合适的LLM。具体而言，我们为每个模型在任务描述的语义嵌入上训练一个轻量级分类器，难度分数来自结合语法、结构相似度与功能正确性的基准测试变体。在推理阶段，VeriDispatcher利用这些预测器将任务路由到选定子集的LLM。在RTLLM与VerilogEval两个基准上，针对10个多样化LLM，VeriDispatcher在仅使用40%商用模型调用的情况下，使RTLLM上的准确率最高提升18%；在VerilogEval上保持准确率不降的同时将商用使用量降低25%，从而实现硬件设计自动化中高性价比且高质量的LLM部署。"
  }
]