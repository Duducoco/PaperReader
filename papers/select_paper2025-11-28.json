[
  {
    "date": "2025-11-28",
    "title": "Algorithm-Architecture Co-Exploration of Systolic Arrays Using High-Level Synthesis",
    "authors": "Chu-Chun Yang, Gwo Giun Lee, Tsung-Ying Tsai, Jie-Ren Zheng, Yue-Cong Kuo, Wei-Chieh Lee, Ryan Karthik Pary",
    "publish": "2025 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)",
    "url": "https://doi.org/10.1109/apsipaasc65261.2025.11248996",
    "source": "IEEE",
    "abstract": "This paper introduces an Architecture Compiler technique which jointly explores the algorithm and architecture co-design. This methodology facilitates a systematic mechanism by which design spaces are crossed or traversed from algorithmic functionality to potentially synthesizable microarchitecture designs having optimized placement and routing with low power, starting from high level synthesis. This will be demonstrated for parallel architecture designs for AI accelerators of general matrix multiplication (GEMM) with high demands in Generative AI on EDGE devices. In this paper, we explored the systolic array dataflow which includes weight, input, and output stationarity for parallel computing in CNN convolution. Different data granularities based on kernel sizes resulting in potentially different architectures will be explored at the high level. This algorithm/architecture co-design methodology will be exploring the potential design space solutions for all LeNet5, AlexNet, VGG16, and VGG19 CNN most suitable for the pre-defined specification quickly.",
    "title_zh": "基于高层次综合的阵列算法-架构协同探索",
    "abstract_zh": "本文介绍了一种架构编译器（Architecture Compiler）技术，该技术联合探索算法与架构的协同设计。该方法提供了一种系统化机制，能够从高层次综合出发，将设计空间从算法功能逐步跨越或遍历至可综合的微架构设计，最终实现低功耗、优化布局布线的高性能设计。该方法将应用于面向边缘设备上生成式人工智能对大规模矩阵乘法（GEMM）高需求场景的并行架构设计。在本研究中，我们探讨了适用于卷积神经网络（CNN）并行计算的脉动阵列数据流，包括权重、输入和输出的固定性（stationarity）。基于不同核大小所带来不同的数据粒度，将在高层次层面探索潜在的多种架构方案。该算法/架构协同设计方法将快速探索所有LeNet5、AlexNet、VGG16和VGG19等典型CNN模型在预定义规格下的最优设计方案。"
  },
  {
    "date": "2025-11-28",
    "title": "Model-Driven Development of Web Application Backend Using Node.js Framework",
    "authors": "Werayoot Kunphai, Twittie Senivongse",
    "publish": "2025 IEEE/ACIS 29th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",
    "url": "https://doi.org/10.1109/snpd65828.2025.11252540",
    "source": "IEEE",
    "abstract": "Model-Driven Development (MDD) has emerged as a promising software engineering paradigm that uses models as the primary artifacts to support software development including web application development. This paper presents a novel application of the MDD principles for Node.JS backend development, focusing on both forward and reverse engineering processes. A UML Profile for Node.js, supporting both SQL and NoSQL databases, is introduced for building design models of web applications. Transformation engines are provided for model-to-code (M2C) and code-to-model (C2M) transformation. The proposed approach was evaluated through three case studies. The forward engineering results demonstrated high model-to-code transformation rates especially for Model (86.18-94.53%) and Route (70.73-90.52%), with consistent performance across SQL (MySQL) and NoSQL (MongoDB) implementations. The reverse engineering results showed 100% correctness in code-to-model transformation for different implementations of backend code. This approach significantly reduces development time for code development while maintaining system documentation through automated model generation, providing a practical solution for Node.JS backend development and maintenance.",
    "title_zh": "使用 Node.js 框架进行 Web 应用后端的模型驱动开发",
    "abstract_zh": "模型驱动开发（Model-Driven Development, MDD）作为一种有前景的软件工程范式，通过将模型作为主要开发资产来支持软件开发，包括Web应用开发。本文提出了一种MDD原则在Node.js后端开发中的创新应用，重点涵盖正向工程与逆向工程两个过程。为此，本文引入了一个针对Node.js的UML配置文件，该配置文件同时支持SQL和NoSQL数据库，用于构建Web应用的设计模型。此外，还提供了模型到代码（M2C）以及代码到模型（C2M）转换的转换引擎。通过三个案例研究对所提出的方案进行了评估。正向工程结果表明，模型到代码的转换率较高，尤其在模型（86.18%-94.53%）和路由（70.73%-90.52%）方面表现优异，且在SQL（MySQL）和NoSQL（MongoDB）实现中均表现出一致的性能。逆向工程结果显示，不同后端代码实现的代码到模型转换均达到100%的正确性。该方法显著缩短了代码开发时间，同时通过自动化的模型生成保持了系统文档的完整性，为Node.js后端开发与维护提供了一种切实可行的解决方案。"
  },
  {
    "date": "2025-11-28",
    "title": "Research on Aerospace Quality Data Analysis and Application Based on Retrieval-Augmented Large Language Models",
    "authors": "Texian Zhang, Beina Du, Lina Dong",
    "publish": "2025 16th International Conference on Reliability, Maintainability and Safety (ICRMS)",
    "url": "https://doi.org/10.1109/icrms65480.2025.00051",
    "source": "IEEE",
    "abstract": "Generative artificial intelligence technologies, such as Large Language Model (LLM), have developed rapidly and are now applied to numerous domains. However, in the aerospace quality domain, LLM's applications and implementation paths require further exploration. In this paper, we study vector knowledge retrieval and prompt optimization methods based on retrieval-augmented LLM. We propose a hybrid retrieval method that integrates semantic retrieval, keyword retrieval, and a reranking algorithm to understand user intent accurately. Aerospace practices demonstrate that LLM can assist quality managers in conducting quality problem mining and quality situation analysis, uncovering key elements and correlations of quality and reliability problems, thereby revealing common weak points in aerospace products.",
    "title_zh": "基于检索增强型大语言模型的航空航天质量数据分析与应用研究",
    "abstract_zh": "生成式人工智能技术，如大型语言模型（LLM），发展迅速，并已广泛应用于多个领域。然而，在航空航天质量领域，LLM的应用与实施路径仍需进一步探索。本文研究了基于检索增强型LLM的向量知识检索与提示优化方法，提出了一种融合语义检索、关键词检索及重排序算法的混合检索方法，以更准确地理解用户意图。航空航天实践表明，LLM能够协助质量管理人员开展质量问题挖掘与质量态势分析，揭示质量与可靠性问题的关键要素及其关联关系，从而发现航空航天产品中的共性薄弱环节。"
  },
  {
    "date": "2025-11-28",
    "title": "Intelligent Root Cause Analysis Approach for Quality Accidents Based on Knowledge Graph and Large Language Model",
    "authors": "Rui Shi, Wei Liu, Chao Guo, Yihai He",
    "publish": "2025 16th International Conference on Reliability, Maintainability and Safety (ICRMS)",
    "url": "https://doi.org/10.1109/icrms65480.2025.00108",
    "source": "IEEE",
    "abstract": "As the speed of product updates accelerates, the mismatch between manufacturing capabilities and user needs becomes more and more obvious. Insufficient manufacturing capabilities lead to product failures or a series of quality accidents. Frequent quality accidents will bring poor product experience to users and cause huge economic and reputation losses to manufacturers. In this context, the continuous maturity of artificial intelligence technology has made it possible to efficiently and intelligently identify the root causes of product quality accidents and failures. To find the root causes of quality accidents and reduce the consequences of frequent quality accidents, a root cause identification scheme for quality accidents based on knowledge graph (KG) and large language model (LLM) is proposed. First, the connotation of quality accidents is proposed, and the formation mechanism of quality accidents in the big data context is explained with product reliability as the core. Secondly, a novel root cause analysis method of quality accidents is established based on the KG and LLM. Finally, a steam turbine is taken as the illustrated example to verify the effectiveness of the proposed method.",
    "title_zh": "基于知识图谱与大语言模型的智能根因分析方法在质量事故中的应用",
    "abstract_zh": "随着产品更新速度的加快，制造能力与用户需求之间的不匹配日益凸显。制造能力不足导致产品出现故障或一系列质量事故。频繁的质量事故会给用户带来糟糕的产品体验，并给制造商带来巨大的经济损失和声誉损害。在此背景下，人工智能技术的持续成熟为高效、智能地识别产品质量事故及故障的根本原因提供了可能。为查明质量事故的根本原因并减少频繁事故带来的后果，本文提出了一种基于知识图谱（KG）与大语言模型（LLM）的质量事故根因识别方案。首先，界定质量事故的内涵，并以产品可靠性为核心，阐释大数据环境下质量事故的形成机制；其次，构建一种基于KG与LLM的新型质量事故根因分析方法；最后，以汽轮机为例进行实证分析，验证所提方法的有效性。"
  },
  {
    "date": "2025-11-28",
    "title": "On the Use of Artificial Intelligent with Large Language Model as a Tool for Evaluating Quality of Hazard and Operability Study",
    "authors": "Darmawan Ahmad Mukharror, Henry Susilo, Zulfan Adi Putra",
    "publish": "2025 9th International Conference on Instrumentation, Control, and Automation (ICA)",
    "url": "https://doi.org/10.1109/ica65945.2025.11252369",
    "source": "IEEE",
    "abstract": "This study explores the application of Large Language Models (LLMs) in evaluating the completeness of safeguard identification in Hazard and Operability (HAZOP) studies. Safeguard completeness is considered a key result indicator in assessing HAZOP study quality. The methodology involved configuring a general-purpose LLM, followed by an initial training phase using synthesized data sets comprising Piping and Instrumentation Diagrams (P&ID) and HAZOP worksheets. The LLM's performance was evaluated across multiple iterations (shots) using prompts constructed by four respondents with varying levels of experience in process safety. Accuracy was measured by comparing LLM output to expert-generated safeguard data, and was found to positively correlate with both respondent experience and number of prompt iterations (R<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> = 0.9964 in the training phase).",
    "title_zh": "利用大型语言模型的人工智能在评估危害与可操作性研究质量中的应用",
    "abstract_zh": "本研究探讨了大型语言模型（LLMs）在评估危害与可操作性（HAZOP）分析中安全防护措施识别完整性方面的应用。安全防护措施的完整性被视为评估HAZOP分析质量的关键结果指标。该方法首先配置了一个通用型大型语言模型，随后利用由管道仪表流程图（P&ID）和HAZOP工作表组成的合成数据集进行初步训练。通过四位在过程安全领域具有不同经验水平的受访者构建的提示（prompts）对模型性能进行了多轮迭代（shots）评估。通过将模型输出与专家生成的安全防护数据进行对比，衡量其准确性，结果显示，模型的准确率与受访者的经验水平以及提示迭代次数均呈正相关，在训练阶段的相关系数R²高达0.9964。"
  },
  {
    "date": "2025-11-28",
    "title": "Analyzing the Combined Effects of Association Rules for Software Defect Prediction",
    "authors": "Catherine Francis Mangare, Hiroki Inayoshi, Akito Monden",
    "publish": "2025 IEEE/ACIS 29th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",
    "url": "https://doi.org/10.1109/snpd65828.2025.11253670",
    "source": "IEEE",
    "abstract": "Association rule mining has been widely applied to identify conditions under which software modules are likely to be buggy or not buggy. These rules include both positive rules (e.g., \"A⇒buggy\") and negative rules (e.g., \"B⇒not buggy\"). Positive rules help pinpoint modules that require thorough testing due to a higher likelihood of defects, whereas negative rules help avoid unnecessary testing by identifying likely clean modules. However, a critical question arises when both positive and negative conditions co-occur: what happens in such cases ̶ does the module end up being buggy or not (\"A&B⇒buggy or not buggy\")? This study investigates the combined effects of positive and negative conditions to determine which set of conditions dominates in predicting software defects. We conduct experiments using defect datasets from versions 2.0 and 3.0 of the Eclipse Mylyn project, which are widely used benchmarks in software defect prediction research. Our results show that dominant conditions for buggy (or not-buggy) modules are primarily associated with process metrics such as added lines, deleted lines, and pre-release defects, while product metrics showed very limited influence.",
    "title_zh": "关联规则综合效应在软件缺陷预测中的分析",
    "abstract_zh": "关联规则挖掘已被广泛应用于识别软件模块可能出错或不出错的条件。这些规则包括正向规则（如“A⇒有缺陷”）和负向规则（如“B⇒无缺陷”）。正向规则有助于定位那些缺陷概率较高的模块，从而需要进行充分测试；而负向规则则有助于避免不必要的测试，通过识别出很可能无缺陷的模块。然而，当正向与负向条件同时出现时，一个关键问题随之产生：在这种情况下，模块究竟是有缺陷还是无缺陷（即“A&B⇒有缺陷或无缺陷”）？本研究探讨了正向与负向条件共同作用的影响，以确定哪一类条件在预测软件缺陷方面具有主导作用。我们利用Eclipse Mylyn项目2.0和3.0版本的缺陷数据集进行了实验，这两个版本是软件缺陷预测研究中广泛使用的基准数据集。研究结果表明，决定模块是否为有缺陷（或无缺陷）的主导因素主要与过程度量相关，例如新增行数、删除行数以及发布前的缺陷数量，而产品度量的影响则非常有限。"
  },
  {
    "date": "2025-11-28",
    "title": "Fine-Tuned LLMs vs. Rule-Based NLP for UML Diagram Generation: An Educational Evaluation",
    "authors": "Reshma P Nair, M.G. Thushara, Vijayan Sugumaran",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2025.3638372",
    "source": "IEEE",
    "abstract": "The automatic generation of Unified Modeling Language (UML) diagrams from natural language requirements continues to be a difficult task in software engineering education and practice. Conventional rule-based Natural Language Processing (NLP) approaches often fail to handle semantic ambiguity and typically demand extensive manual adjustments. Recent developments in Large Language Models (LLMs) demonstrate stronger contextual reasoning abilities, but their capability to produce accurate and structured diagrams-particularly in instructional settings—has not been thoroughly examined. This work compares a traditional NLP pipeline with a fine-tuned Qwen2.5-Coder-7B-Instruct model using a dataset of 75 annotated specifications. The fine-tuned model attained a semantic fidelity of 94%, a G-Eval correctness score of 0.78, and reduced manual correction requirements by 78%. In contrast, the NLP pipeline achieved 67% fidelity and required a 52% correction effort. Statistical analysis using MANOVA and ANOVA confirmed that these differences across the student, NLP, and LLM groups were statistically significant (p < 0.001). Moreover, students working with LLM-generated diagrams reported a 30% decrease in effort and greater engagement during modeling tasks. The findings demonstrate that fine-tuned LLMs can substantially improve the precision and interpretability of automated UML diagram generation while supporting more interactive and effective learning in software engineering contexts.",
    "title_zh": "微调的大语言模型与基于规则的NLP在UML图生成中的比较：一项教育评估",
    "abstract_zh": "从自然语言需求自动生成统一建模语言（UML）图在软件工程教育与实践中仍是一项极具挑战性的任务。传统的基于规则的自然语言处理（NLP）方法往往难以应对语义歧义，且通常需要大量的人工调整。尽管大型语言模型（LLMs）近年来展现出更强的上下文推理能力，但其在生成准确、结构化UML图——尤其是在教学场景中——的表现尚未得到充分评估。本研究对比了传统NLP流程与经过微调的Qwen2.5-Coder-7B-Instruct模型，使用包含75个标注规范的数据集进行测试。结果显示，微调后的模型实现了94%的语义保真度，G-Eval正确性得分为0.78，并将人工修正需求降低了78%；而传统NLP流程仅达到67%的语义保真度，需进行52%的修正工作。通过多元方差分析（MANOVA）和单因素方差分析（ANOVA）进行的统计检验表明，学生组、NLP组与LLM组之间的差异具有高度统计显著性（p < 0.001）。此外，使用LLM生成的UML图的学生在建模任务中报告工作量减少了30%，并表现出更高的参与度。研究结果表明，经过微调的LLM能够显著提升自动化UML图生成的精确性与可读性，同时支持更具互动性和实效性的软件工程学习环境。"
  },
  {
    "date": "2025-11-28",
    "title": "A Robust and Portable All-Digital TRNG Circuit for Extending the Instruction Set Architecture of RISC-V Processors",
    "authors": "Luca Crocetti, Ettore Noccetti, Pietro Nannipieri, Stefano Di Matteo, Ivan Sarno, Sergio Saponara",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2025.3638434",
    "source": "IEEE",
    "abstract": "All-digital True Random Number Generators (TRNGs) play a crucial role in enhancing hardware security by providing native entropy sources directly within the processor pipeline. Their integration into open architectures such as RISC-V enables the extension of the Instruction Set Architecture (ISA) with secure, hardware-level random number generation capabilities essential for cryptographic operations. This work presents the design and validation of an all-digital True Random Number Generator (TRNG) for seamless integration with RISC-V processors via a custom interface. The proposed circuit has been developed using SystemVerilog and leverages Fibonacci Galois Ring Oscillators (FiGaROs), which use jitter and metastability as entropy sources to ensure high quality randomness. The TRNG has been integrated with the VECtor processor (VEC) core of the European Processor ACcelerator (EPAC) chip through a custom Control and Status Register (CSR) interface, enabling its use as a secure entropy source within the RISC-V instruction set architecture for cryptographic applications. The validation campaign is based on the typical main statistical suites of reference organizations in the field of security and cryptography and demonstrates that our solution offers both high-security standards and independence from both the implementation technology and the operating frequency chosen for the TRNG circuit, reporting an entropy per bit (in terms of Shannon entropy) of 0.9999 in all test cases, while always passing the pass-fail criteria for randomness. In addition, our circuit offers the highest entropy rate for both Field Programmable Gate Array (FPGA) and Application Specific Integrated Circuit (ASIC) solutions, as well as an efficiency in terms of entropy rate per resource consumption that is approximately 96 to 257 times that of the other solutions in the case of ASIC implementation.",
    "title_zh": "一种鲁棒且可移植的全数字TRNG电路，用于扩展RISC-V处理器的指令集架构",
    "abstract_zh": "全数字真随机数生成器（TRNG）在提升硬件安全方面发挥着至关重要的作用，通过在处理器流水线内部直接提供原生熵源，增强了系统的安全性。将其集成到RISC-V等开放架构中，能够扩展指令集架构（ISA），赋予其安全的硬件级随机数生成能力，这对于密码学操作至关重要。本文提出了一种全数字真随机数生成器（TRNG）的设计与验证方案，该方案可通过自定义接口无缝集成至RISC-V处理器。所设计的电路采用SystemVerilog实现，利用斐波那契伽罗瓦环形振荡器（FiGaROs），以抖动（jitter）和亚稳态（metastability）作为熵源，确保生成随机性的高质量。\n\n该TRNG已通过自定义控制与状态寄存器（CSR）接口集成至欧洲处理器加速器（EPAC）芯片中的VECtor处理器（VEC）核心，使其能够在RISC-V指令集架构中作为安全的熵源，服务于各类密码学应用。验证工作基于安全与密码学领域权威机构的标准统计测试套件，结果表明：本方案不仅满足极高的安全标准，且对实现工艺技术及TRNG电路的工作频率选择具有高度独立性。在所有测试用例中，其每比特熵值（以香农熵衡量）达到0.9999，同时始终通过各项随机性测试的通过/失败判定标准。\n\n此外，本电路在FPGA和专用集成电路（ASIC）解决方案中均实现了最高的熵率，并在资源消耗效率方面表现卓越——在ASIC实现情况下，其单位资源产生的熵率约为现有其他方案的96至257倍，显著提升了能效比。"
  },
  {
    "date": "2025-11-28",
    "title": "Enhancing Algorithm Comprehension for Visually Impaired Individuals with LLM-Based Programming Code Segmentation",
    "authors": "Naoki Takamatsu, Eiji Kamioka, Chanh Minh Tran, Phan Xuan Tan",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2025.3638804",
    "source": "IEEE",
    "abstract": "The concept of inclusive education increasingly focuses on providing appropriate support for diverse learners, including visually impaired individuals (VIs) who encounter notable difficulties in programming education. Unlike sighted learners who can visually grasp code structure at a glance, VIs depend on screen readers that present code linearly, hindering their ability to comprehend program flow and increasing cognitive load. This study proposes a method that leverages Large Language Model (LLM) to automatically segment the source code into semantically coherent sections along with their corresponding explanatory descriptions. These descriptions are embedded in a screen-reader-compatible block-based programming interface, designed to enhance non-visual code comprehension by providing structured, high-level guidance. An experimental study was conducted with 20 sighted participants blindfolded to simulate non-visual interaction. Participants completed programming tasks using two systems: one with LLM-generated segmentation and one without. The results demonstrate that the segmented system significantly improved task success rates and reduced completion times by over 50% in the most complex task. Additionally, subjective evaluations indicated enhanced usability and comprehension. These findings highlight the potential of LLM-based code segmentation to improve programming accessibility for VIs. Future work includes testing on complex codebases, adding contextual aids, enhancing segmentation flexibility, and conducting broader longitudinal evaluations.",
    "title_zh": "基于大语言模型的编程代码分割提升视障人士的算法理解能力",
    "abstract_zh": "包容性教育的理念日益关注为多样化学习者提供适当支持，其中包括在编程教育中面临显著困难的视障人士（VIs）。与能够一眼直观理解代码结构的视力正常学习者不同，视障人士依赖屏幕阅读器以线性方式呈现代码，这阻碍了他们对程序流程的理解，并增加了认知负担。本研究提出一种基于大语言模型（LLM）的方法，可自动将源代码分割为语义连贯的段落，并附上相应的解释说明。这些说明被嵌入到兼容屏幕阅读器的基于块的编程界面中，旨在通过提供结构化、高层次的引导，提升非视觉环境下的代码理解能力。一项实验研究招募了20名视力正常但蒙眼的参与者，模拟非视觉交互情境。参与者使用两种系统完成编程任务：一种是采用LLM生成的代码分段，另一种则无分段。结果表明，在最复杂的任务中，分段系统显著提高了任务成功率，并将完成时间缩短超过50%。此外，主观评价也显示该系统在可用性和理解度方面均有明显提升。这些发现凸显了基于LLM的代码分段技术在提升视障人士编程可访问性方面的巨大潜力。未来工作将包括在更复杂的代码库中进行测试、增加上下文辅助功能、提升分段灵活性，并开展更广泛的纵向评估。"
  },
  {
    "date": "2025-11-28",
    "title": "Design and Implementation of Whyline4Java to Enhance Dynamic Debugging in Java Programming",
    "authors": "Tan Jun Wen, Glaret Shirley A-P Sinnappan, See Kwee Teck",
    "publish": "2025 IEEE International Conference on Computation, Big-Data and Engineering (ICCBE)",
    "url": "https://doi.org/10.1109/iccbe65177.2025.11255783",
    "source": "IEEE",
    "abstract": "To improve Java software engineering workflows, we introduced the Whyline4Java tool, an innovative interrogative debugging (ID) tool. The Whyline4Java tool, created as a plugin for the Eclipse Integrated Development Environment, allows developers to ask \"why\" and \"why not\" questions about program behavior to solve challenges in understanding and adapting complex codebases. Building on Amy J. Ko’s original Whyline for Java idea, the tool presents technological improvements with support for JDK 5 and higher, optimized memory usage, simplified installation, and a more understandable user interface. We integrated quantitative analysis (one-way analysis of variance and linear regression) with qualitative analysis (structured interviews and expert reviews). The tool significantly reduced debugging time, from 30.29% to 82.73% for five different debugging tasks. The tool can be a solution for Java developers as well as improvements in end-user software engineering (EUSE) which is useful for educators and researchers working on dynamic debugging methodologies.",
    "title_zh": "Whyline4Java：增强Java编程动态调试的设计与实现",
    "abstract_zh": "为了改进Java软件工程的工作流程，我们引入了Whyline4Java工具——一种创新的询问式调试（Interrogative Debugging, ID）工具。该工具作为Eclipse集成开发环境的插件开发而成，使开发者能够针对程序行为提出“为什么”和“为什么不”的问题，从而解决理解与适应复杂代码库时面临的挑战。基于Amy J. Ko最初提出的Java版Whyline理念，Whyline4Java在技术上实现了多项改进，包括支持JDK 5及以上版本、优化内存使用、简化安装流程，并提供更直观易用的用户界面。我们结合定量分析（单因素方差分析与线性回归）与定性分析（结构化访谈与专家评审），对工具效果进行了全面评估。结果显示，该工具将调试时间显著缩短了30.29%至82.73%，涵盖五种不同的调试任务。Whyline4Java不仅可为Java开发者提供有效支持，也为终端用户软件工程（End-User Software Engineering, EUSE）提供了重要改进，对致力于动态调试方法研究的教育工作者和研究人员具有重要参考价值。"
  },
  {
    "date": "2025-11-28",
    "title": "LEE: An Efficient Scheme of Legal Element Extraction based on Large Language Model",
    "authors": "Huaiyong Li, Wenjiang Liu, Zhao Qu, Yongping Xia, Heling Jiang, Hongfa Ding",
    "publish": "2025 IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA)",
    "url": "https://doi.org/10.1109/ispa67752.2025.00189",
    "source": "IEEE",
    "abstract": "In recent years, element extraction based on Large Language Models (LLMs) has attracted increasing attention. However, extracting structured elements from legal documents remains extremely challenging due to the presence of technical terminology, complex sentence structures, and implicit semantic logic. To address these challenges, this paper proposes the LEE, a novel LLM-based scheme with three stages for the efficient extraction of legal elements from structured legal documents. In LEE, we employ rule-based parsing (RBP) and context-prompting learning (CPL) to improve the effectiveness of element extraction. The proposed LEE is rigorously evaluated and compared with state-of-the-art schemes over real structured legal documents and public datasets. Experimental results show that LEE significantly outperforms state-of-the-art schemes in multiple metrics.",
    "title_zh": "李：基于大语言模型的高效法律要素提取方案",
    "abstract_zh": "近年来，基于大语言模型（LLMs）的元素提取引起了越来越多的关注。然而，由于法律文件中存在专业术语、复杂句式以及隐含的语义逻辑，从法律文档中提取结构化元素仍然极具挑战性。为应对这些挑战，本文提出了一种名为LEE的新颖LLM-based方案，该方案包含三个阶段，能够高效地从结构化法律文档中提取法律元素。在LEE中，我们采用基于规则的解析（RBP）和上下文提示学习（CPL）方法，以提升元素提取的有效性。所提出的LEE在真实结构化法律文档及公开数据集上进行了严格的评估，并与当前最先进的方法进行了对比。实验结果表明，LEE在多个指标上均显著优于现有先进方法。"
  },
  {
    "date": "2025-11-28",
    "title": "DRL-RAG: A Dynamic Reinforcement Learning-Driven RAG Method for Enhancing Language Model Capabilities",
    "authors": "Nianlong Zhang, Ronghua Ye, Jianmin Han",
    "publish": "2025 IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA)",
    "url": "https://doi.org/10.1109/ispa67752.2025.00159",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) are inherently prone to hallucination, as the accuracy of generated text cannot be guaranteed solely by their internal knowledge. While Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating external knowledge, its effectiveness highly depends on the relevance of the retrieved documents. The inclusion of irrelevant content often leads to performance degradation. To address this limitation, we propose Dynamic Reinforcement Learning-Retrieval Augmented Generation (DRL-RAG), a novel framework designed to improve the robustness of text generation. DRL-RAG utilizes relevance scores from a cross-encoder as a reward signal within a reinforcement learning (RL) mechanism to optimize the quality of retrieved documents. Recognizing that retrieval from static corpora frequently produces sub-optimal results, our framework dynamically extends retrieval to large-scale web search when necessary. Additionally, a confidence assessment mechanism selectively filters model-generated content based on reliability. Extensive experiments on three benchmark datasets show that DRL-RAG significantly outperforms existing RAG-based methods.",
    "title_zh": "DRL-RAG：一种动态强化学习驱动的RAG方法，用于增强语言模型能力",
    "abstract_zh": "大型语言模型（LLMs）本质上容易产生幻觉，因为仅依靠其内部知识无法保证生成文本的准确性。尽管检索增强生成（RAG）通过引入外部知识提升了LLM的表现，但其效果高度依赖于所检索文档的相关性。若引入无关内容，往往会导致性能下降。为解决这一局限，我们提出一种新型框架——动态强化学习-检索增强生成（DRL-RAG），旨在提升文本生成的鲁棒性。DRL-RAG利用交叉编码器提供的相关性评分作为强化学习（RL）机制中的奖励信号，以优化检索文档的质量。考虑到从静态语料库中检索常导致次优结果，本框架在必要时可动态扩展至大规模网络搜索进行检索。此外，系统还引入了一种置信度评估机制，根据可靠性对模型生成的内容进行选择性过滤。在三个基准数据集上的大量实验表明，DRL-RAG显著优于现有的基于RAG的方法。"
  },
  {
    "date": "2025-11-28",
    "title": "Empowering IoT with Large Language Models: A Survey of Applications, Challenges, and Future Directions",
    "authors": "Ali Shahraeeni, Rupinder Kaur, Abbas Kochari, Farah Mohammadi, Arghavan Asad",
    "publish": "2025 IEEE/ACIS 29th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",
    "url": "https://doi.org/10.1109/snpd65828.2025.11252601",
    "source": "IEEE",
    "abstract": "The integration of Large Language Models (LLMs) with the Internet of Things (IoT) is reshaping intelligent systems, enabling advanced automation, cybersecurity, and natural user interaction in cyber-physical environments. This survey synthesizes recent advances in LLM-IoT integration, highlighting transformative applications, challenges, and emerging solutions. Key applications include intelligent automation, with AutoIoT achieving 94.1%–98.5% accuracy in zero-code orchestration; personalized healthcare, with LLM-HAS reducing false alarms by 8.147%; and cybersecurity via ChatIoT and BARTPredict, the latter with 98% intrusion detection accuracy. Challenges include computational constraints on edge devices, privacy risks in data handling, and hallucinations, with medical LLMs showing up to 15% error rates without fine-tuning. Solutions like federated learning, model compression (reducing memory usage by up to 50%), and hybrid frameworks such as LLMind improve efficiency and privacy. This survey offers a comparative analysis of these approaches, providing insights into their trade-offs. Future research should focus on multimodal LLMs, scalable edge deployments, and trustworthy systems powered by explainable AI. By addressing these issues, LLM-IoT ecosystems can evolve toward resilient, adaptive, and human-centric intelligent systems, enabling more generalizable AI in IoT-driven environments.",
    "title_zh": "利用大语言模型赋能物联网：应用、挑战与未来方向综述",
    "abstract_zh": "大型语言模型（LLMs）与物联网（IoT）的融合正在重塑智能系统，使网络物理环境中的高级自动化、网络安全以及自然人机交互成为可能。本综述总结了LLM-IoT融合领域的最新进展，重点阐述了其变革性应用、面临的挑战及新兴解决方案。关键应用包括：智能自动化方面，AutoIoT在零代码编排中实现了94.1%至98.5%的准确率；个性化医疗领域，LLM-HAS将误报率降低了8.147%；网络安全方面，ChatIoT和BARTPredict等技术表现突出，其中BARTPredict的入侵检测准确率达到98%。然而，该领域仍面临诸多挑战：边缘设备的计算资源受限、数据处理过程中的隐私风险，以及模型幻觉问题——未经微调的医疗类LLM错误率最高可达15%。针对这些问题，研究提出了多种解决方案，如联邦学习、模型压缩技术（可将内存占用降低高达50%），以及混合框架如LLMind，有效提升了系统效率与隐私保护能力。本文对这些方法进行了对比分析，深入揭示了各自的权衡关系。未来的研究应聚焦于多模态LLM的发展、可扩展的边缘部署方案，以及基于可解释人工智能的可信系统构建。通过解决上述问题，LLM-IoT生态系统有望朝着更具韧性、自适应性和以人为本的智能系统演进，推动物联网驱动环境中更通用化人工智能的实现。"
  },
  {
    "date": "2025-11-28",
    "title": "Evaluating the Source Code Review Performance of LLM-based AI Chatbots",
    "authors": "Toya Kakimoto, Hiroki Inayoshi, Hidetake Uwano, Akito Monden",
    "publish": "2025 IEEE/ACIS 29th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",
    "url": "https://doi.org/10.1109/snpd65828.2025.11253974",
    "source": "IEEE",
    "abstract": "Source code review plays a critical role in ensuring software quality by identifying bugs early in the development process. Although recent studies have explored the use of large language models (LLMs) for tasks such as vulnerability detection and automated code refinement, few studies have evaluated their performance against human reviewers during the review phase. In this study, we empirically evaluate the bug detection capabilities of several LLM-based AI chatbots using a benchmark C program containing 27 bugs, originally used in a prior human-based code review study. We tested AI chatbots including GPT-4o, Grok-3, and Claude 3.7 Sonnet, under varying conditions such as code granularity, specification document availability, and Chain-of-Thought (CoT) reasoning. Our results show that while chatbots achieve bug detection performance comparable to that of human reviewers, they do not yet surpass them. We further analyze how code granularity, specification availability, and CoT reasoning affect the performance, and discuss the challenges that need to be addressed for effective LLM-assisted code review automation.",
    "title_zh": "评估基于大语言模型的AI聊天机器人在源代码审查中的表现",
    "abstract_zh": "源代码审查在确保软件质量方面起着至关重要的作用，能够帮助在开发早期识别缺陷。尽管近期研究已探索使用大型语言模型（LLMs）进行漏洞检测和自动化代码优化等任务，但很少有研究在审查阶段将这些模型的表现与人类评审员进行对比评估。在本研究中，我们通过一个包含27个缺陷的基准C程序（该程序最初用于一项基于人类的代码审查研究），实证评估了几种基于LLM的AI聊天机器人在缺陷检测方面的表现。我们测试了包括GPT-4o、Grok-3和Claude 3.7 Sonnet在内的多种AI聊天机器人，并考察了代码粒度、规范文档可用性以及思维链（Chain-of-Thought, CoT）推理等不同条件下的表现。结果表明，虽然这些聊天机器人的缺陷检测能力与人类评审员相当，但尚未超越人类。我们进一步分析了代码粒度、规范文档可用性及CoT推理对性能的影响，并讨论了实现高效LLM辅助代码审查自动化所面临的关键挑战。"
  },
  {
    "date": "2025-11-28",
    "title": "Efficient Dynamic VLSI Design with Error Detection and 8-Way Power Amplifier for Triple-Gate Vertical Power MOSFET",
    "authors": "Anumala Alekhya, Maram Y Al-Safarini, T Sunitha, K Veeranjaneyulu, Swathi B, R Deivanayaki",
    "publish": "2025 International Conference on Recent Innovation in Science Engineering and Technology (ICRISET)",
    "url": "https://doi.org/10.1109/icriset64803.2025.11252309",
    "source": "IEEE",
    "abstract": "The Efficient Dynamic VLSI Design with Error Detection and 8-Way Power Amplifier for Triple-Gate Vertical Power MOSFET (EDVEPT) model, a new solution designed to improve power amplifier (PA) performance for radar and wireless communication applications. This model combines a highly efficient Triple Gate Vertical Power MOSFET made from SiGe materials with an 8-way balanced PA system. By using a wideband balanced PA setup with Lange couplers, the EDVEPT enhances signal stability, reduces insertion loss, and increases power output, particularly for FMCW radar in the W-band. It includes transformer-based push-pull PA stages, which improve output power and impedance matching. Simulation results show consistent performance, with insertion loss below 4 dB and output return loss above 8 dB under varying loads. It also features a probability-based error detection system and adaptive noise detection using infrared sensors. The EDVEPT's SiGe-based MOSFET provides superior performance over traditional Si-channel MOSFETs, achieving low ON-state resistance and high current drive.",
    "title_zh": "具有错误检测功能的高效动态VLSI设计及用于三栅极垂直功率MOSFET的8路功率放大器",
    "abstract_zh": "EDVEPT（高效动态VLSI设计带错误检测及八路功率放大器的三栅垂直功率MOSFET）模型是一种专为雷达和无线通信应用提升功率放大器（PA）性能而设计的新解决方案。该模型将基于SiGe材料的高效率三栅垂直功率MOSFET与八路平衡式功率放大系统相结合。通过采用宽带平衡式PA结构及Lange耦合器，EDVEPT显著提升了信号稳定性，降低了插入损耗，并提高了输出功率，尤其在W波段的调频连续波（FMCW）雷达中表现突出。其采用基于变压器的推挽式PA级，有效增强了输出功率并优化了阻抗匹配。仿真结果表明，在不同负载条件下，该系统表现出稳定的性能，插入损耗低于4 dB，输出回波损耗高于8 dB。此外，EDVEPT还集成了基于概率的错误检测系统以及利用红外传感器实现的自适应噪声检测功能。其基于SiGe材料的MOSFET相比传统硅沟道MOSFET具有更优性能，实现了低导通电阻和高电流驱动能力。"
  },
  {
    "date": "2025-11-28",
    "title": "Deep Learning-based Binary Analysis for Vulnerability Detection in x86-64 Machine Code",
    "authors": "Mitchell Petingola",
    "publish": "2025 IEEE/ACIS 29th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",
    "url": "https://doi.org/10.1109/snpd65828.2025.11252836",
    "source": "IEEE",
    "abstract": "While much of the current research in deep learning-based vulnerability detection relies on disassembled binaries, this paper explores the feasibility of extracting features directly from raw x86-64 machine code. Although assembly language is more interpretable for humans, it requires more complex models to capture token-level context. In contrast, machine code may enable more efficient, lightweight models and preserve all information that might be lost in disassembly. This paper approaches the task of vulnerability detection through an exploratory study on two specific deep learning model architectures and aims to systematically evaluate their performance across three vulnerability types. The results demonstrate that graph-based models consistently outperform sequential models, emphasizing the importance of control flow relationships, and that machine code contains sufficient information for effective vulnerability discovery.",
    "title_zh": "基于深度学习的x86-64机器码漏洞检测二进制分析",
    "abstract_zh": "尽管当前基于深度学习的漏洞检测研究大多依赖反汇编后的二进制文件，本文探索了直接从原始x86-64机器码中提取特征的可行性。虽然汇编语言对人类更具可读性，但需要更复杂的模型来捕捉标记级别的上下文信息。相比之下，机器码可能使模型更加高效、轻量，并保留反汇编过程中可能丢失的所有信息。本文通过针对两种特定深度学习模型架构的探索性研究，系统评估其在三类漏洞检测任务中的表现。结果表明，基于图的模型始终优于序列模型，凸显了控制流关系的重要性，同时证明机器码包含足够信息以实现有效的漏洞发现。"
  },
  {
    "date": "2025-11-28",
    "title": "Equipment Maintainability Design Verification Based on RAG",
    "authors": "Senlin Zhu, Qingqing Song, Xingxin Li, Qingqing Hu, Ke Li",
    "publish": "2025 16th International Conference on Reliability, Maintainability and Safety (ICRMS)",
    "url": "https://doi.org/10.1109/icrms65480.2025.00123",
    "source": "IEEE",
    "abstract": "The maintenance design verification in the early stage of equipment development relies on the professional knowledge and experience accumulation of verification personnel, and the accuracy and efficiency of verification results are difficult to guarantee. Artificial intelligence technology provides new ideas for equipment maintenance design verification, but its accuracy and reliability in specific knowledge fields still need to be improved. To address this issue, this paper proposes a maintenance design verification based on Retrieval Enhanced Generative Technology (RAG). By constructing a professional domain knowledge base and utilizing the powerful generation function of Large Language Model (LLM), RAG is extended to access specific domain knowledge bases or authoritative knowledge bases, thereby improving the accuracy of retrieval in specific knowledge domains. Equipment maintenance design verification based on RAG can not only conduct a “census” of complex equipment, but also avoid manual verification omissions caused by time and experience limitations, effectively improving the quality and efficiency of maintenance verification.",
    "title_zh": "基于RAG的设备可维护性设计验证",
    "abstract_zh": "在设备研发初期，维护设计验证主要依赖于验证人员的专业知识和经验积累，其结果的准确性和效率难以保证。人工智能技术为设备维护设计验证提供了新思路，但其在特定知识领域的准确性与可靠性仍有待提升。针对这一问题，本文提出一种基于检索增强生成技术（Retrieval-Augmented Generation, RAG）的维护设计验证方法。通过构建专业领域知识库，并利用大语言模型（Large Language Model, LLM）强大的生成能力，RAG能够扩展至访问特定领域或权威知识库，从而显著提升在特定知识领域中的检索准确性。基于RAG的设备维护设计验证不仅能够对复杂设备进行全面“普查”，还可避免因时间与经验限制导致的人工验证遗漏，有效提升维护验证的质量与效率。"
  },
  {
    "date": "2025-11-28",
    "title": "Making the Case for LLM-Generated Automated Program Repair Benchmarks",
    "authors": "Yasser Ebrahim",
    "publish": "2025 IEEE/ACIS 29th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",
    "url": "https://doi.org/10.1109/snpd65828.2025.11252591",
    "source": "IEEE",
    "abstract": "Automated Program Repair (APR) has made significant strides in recent years, particularly with the integration of large language models (LLMs) and deep learning techniques. Yet despite this progress, one fundamental issue continues to hinder advancement: how we evaluate these systems. Many of today’s APR benchmarks suffer from serious limitations—including small dataset sizes, synthetic or unrealistic bug scenarios, overfitting risks, ambiguous evaluation criteria, and a narrow focus on certain programming languages.In this paper, we take a critical look at these challenges by identifying eight core limitations in widely used benchmarks. We then explore how LLM-generated benchmarks can help overcome these obstacles. Finally, we address some potential concerns about LLM-generated benchmarks and propose a quality assurance and validation framework.By combining the strengths of LLMs with thoughtful benchmark design, this work lays the foundation for more robust, diverse, and meaningful evaluation frameworks—paving the way for future breakthroughs in APR research.",
    "title_zh": "为大语言模型生成的自动化程序修复基准设定论据",
    "abstract_zh": "近年来，自动化程序修复（APR）取得了显著进展，尤其是在引入大型语言模型（LLMs）和深度学习技术方面。然而，尽管取得了这些进步，一个根本性问题依然制约着该领域的进一步发展：我们如何评估这些系统。当前许多APR基准测试存在严重缺陷——数据集规模过小、漏洞场景为合成或不切实际、存在过拟合风险、评估标准模糊，以及对特定编程语言的过度聚焦。本文通过对广泛使用的基准测试中存在的八个核心局限进行批判性分析，探讨了利用大语言模型生成基准测试以克服这些障碍的潜力。最后，我们针对LLM生成基准测试可能引发的一些担忧提出了质量保障与验证框架。通过将LLM的优势与精心设计的基准测试相结合，本研究为构建更稳健、更丰富、更具意义的评估体系奠定了基础，也为未来APR研究的突破铺平了道路。"
  },
  {
    "date": "2025-11-28",
    "title": "Design and Commission of Solid State Switch Driver in SLAC Subbooster Modulator",
    "authors": "Xupeng Chen, Jeffrey de Lamare",
    "publish": "2025 IEEE Pulsed Power &amp;amp; Plasma Science (PPPS)",
    "url": "https://doi.org/10.1109/ppps56198.2025.11248401",
    "source": "IEEE",
    "abstract": "The LINAC sub-booster modulator is a pulsed power supply to provide a 30kV pulse to drive a klystron in SLAC LINAC. It has used vacuum tetrode as pulse switch for more than 60 years. With the vacuum tetrode availability becoming less and its cost surging, a natural choice is to use solid state switch in this pulsed power modulator. To commission solid state switch in LINAC sub-booster modulator, a driver board is designed to drive a BEHLKE HTS-LC2 series MOSFET based switches. The design concept and some concerns in design will be presented. The driver board is universal for all HTS-LC2 series switches because they share the same driver signals and connections. After the driver is commissioned, two AI systems are introduced to design one core part of the driver, the results are presented here. During the commission of the driver board in the LINAC sub-booster modulators, some problems happened and were addressed.",
    "title_zh": "SLAC次级加速器调制器中固态开关驱动器的设计与研制",
    "abstract_zh": "LINAC次级加速器调制器是一种脉冲电源，用于在SLAC直线加速器中为速调管提供30kV的脉冲电压。该设备已使用真空四极管作为脉冲开关超过60年。随着真空四极管的供应日益减少且成本急剧上升，采用固态开关替代成为自然的选择。为了在LINAC次级加速器调制器中实现固态开关的投入使用，设计了一块驱动板，用于驱动BEHLKE HTS-LC2系列基于MOSFET的开关。本文将介绍该驱动板的设计理念以及设计过程中的一些关键考虑因素。由于所有HTS-LC2系列开关共享相同的驱动信号和连接方式，该驱动板具有通用性，适用于全部型号。在驱动板投入运行后，引入了两项人工智能（AI）系统，用于优化驱动板核心部件的设计，相关成果也在此展示。在驱动板于LINAC次级加速器调制器中进行调试的过程中，出现了一些问题，并已得到妥善解决。"
  },
  {
    "date": "2025-11-28",
    "title": "Foundation Models as Guardrails: LLM-and VLM-Based Approaches to Safety and Alignment",
    "authors": "Huy H. Nguyen, Pride Kavumba, Tomoya Kurosawa, Koki Wataoka",
    "publish": "2025 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)",
    "url": "https://doi.org/10.1109/apsipaasc65261.2025.11249402",
    "source": "IEEE",
    "abstract": "The growing deployment of large language models (LLMs) and vision-language models (VLMs) raises urgent concerns about safety and alignment. While alignment techniques such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) improve model behavior, they are not sufficient to prevent harmful outputs. This paper reviews recent approaches that use foundation models themselves as guardrails systems that monitor or filter inputs and outputs for safety. We cover LLM-based moderation, neural classifiers, and multimodal safety filters, highlighting both academic advances and industry tools. We also discuss empirical evaluation methods such as red teaming and adversarial prompting. Finally, we outline open challenges in robustness, interpretability, and policy adaptation, pointing to key directions for building trustworthy guardrails for generative AI.",
    "title_zh": "基础模型作为安全护栏：基于大语言模型与视觉语言模型的安全性与对齐方法",
    "abstract_zh": "大规模语言模型（LLMs）和视觉-语言模型（VLMs）的广泛应用引发了对安全性和对齐性的迫切关注。尽管对齐技术如监督微调（SFT）和基于人类反馈的强化学习（RLHF）在改善模型行为方面取得了一定成效，但仍不足以完全防止有害输出。本文综述了近期利用基础模型自身作为防护机制的研究方法，这些方法通过监控或过滤输入与输出来保障安全性。我们涵盖了基于大语言模型的内容审核、神经分类器以及多模态安全过滤器，既介绍了学术上的最新进展，也梳理了产业界的相关工具。此外，本文还讨论了红队测试和对抗性提示等实证评估方法。最后，我们指出了在鲁棒性、可解释性及政策适应性方面仍存在的开放性挑战，并提出了构建可信生成式人工智能防护体系的关键研究方向。"
  },
  {
    "date": "2025-11-28",
    "title": "Vulnerability Smart Contract Detection Model based on CUR Matrix Decomposition",
    "authors": "Hengxin Lei, Thein Lai Wong, Tong Ming Lim, Xiangfu Zhao, Yiqi Tew, Shuang Wu",
    "publish": "2025 IEEE International Conference on Computation, Big-Data and Engineering (ICCBE)",
    "url": "https://doi.org/10.1109/iccbe65177.2025.11255968",
    "source": "IEEE",
    "abstract": "Smart contracts, an important component of blockchain technology, have received widespread attention due to their decentralized and trustworthy characteristics. However, the security vulnerabilities of smart contracts pose a serious threat to their reliability, causing huge economic losses to users. Existing analysis tools are used to detect security vulnerabilities in smart contracts. However, due to their excessive reliance on hard rules defined by experts when detecting vulnerabilities in smart contracts, the time to perform the detection significantly increases as the complexity of smart contracts increases. In this study, we developed a novel hybrid machine learning model called Bi-CUR. The Bi-CUR model extracts the feature matrix of smart contract opcodes through Bigram and detects smart contract vulnerability through CUR matrix decomposition. It approximates the original matrix by selecting rows and columns, thereby reducing computational complexity while maintaining the features of the data. Compared with traditional vulnerability detection methods, models based on CUR matrix decomposition showed higher efficiency and accuracy. In addition, the model ensured interpretability, which makes it applicable to different types of smart contract vulnerability detection.",
    "title_zh": "基于CUR矩阵分解的智能合约漏洞检测模型",
    "abstract_zh": "智能合约作为区块链技术的重要组成部分，因其去中心化和可信的特性而受到广泛关注。然而，智能合约的安全漏洞对其可靠性构成了严重威胁，给用户带来了巨大的经济损失。现有的分析工具用于检测智能合约中的安全漏洞，但由于其在检测过程中过度依赖专家定义的硬性规则，随着智能合约复杂度的增加，检测耗时显著上升。在本研究中，我们提出了一种新型的混合机器学习模型——Bi-CUR。该模型通过Bigram方法提取智能合约操作码的特征矩阵，并利用CUR矩阵分解技术来检测智能合约漏洞。通过选择部分行和列来近似原始矩阵，该方法在降低计算复杂度的同时，有效保留了数据的关键特征。与传统的漏洞检测方法相比，基于CUR矩阵分解的模型展现出更高的效率和准确性。此外，该模型还保证了良好的可解释性，使其能够适用于多种类型的智能合约漏洞检测。"
  },
  {
    "date": "2025-11-28",
    "title": "CoMaTS: A Collaborative Multi-Agent Framework for Edge Task Scheduling",
    "authors": "Zhixuan Wang, Shendong Gao, Yuqi Zhao",
    "publish": "2025 IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA)",
    "url": "https://doi.org/10.1109/ispa67752.2025.00065",
    "source": "IEEE",
    "abstract": "With the development of Internet of Things (IoT) technologies, an increasing number of intelligent devices are connected to edge environments, leading to a significant growth in the volume of service requests. To enhance service quality under resource constraints, efficient task scheduling is crucial. However, existing approaches typically consume substantial time or computational resources and struggle to achieve a good balance among multiple optimization objectives. To address these challenges, we propose a Collaborative Multi-Agent Framework for Edge Task Scheduling (CoMaTS), which guides large language models (LLMs) to design high-quality scheduling algorithms through the close collaboration of multiple agents(Generator, Praiser, Critic and Optimizer), eliminating the need for additional timeconsuming fine-tuning. The Generator, driven by multiple large language models, is responsible for generating a set of candidate algorithms. The Praiser and Critic analyze the top-scoring and lowest-scoring algorithms respectively, and deliver the reasons to the optimizer. The Optimizer accepts the reasons, conducts a comparison, and provides suggestions for the next-round operation of the generator. Extensive experiments demonstrate that compared with traditional heuristic methods and reinforcement learning approaches, CoMaTS can optimize multiple objectives more effectively. Moreover, compared with the latest LLM-based scheduling methods, it achieves higher performance at a lower cost.",
    "title_zh": "CoMaTS：一种用于边缘任务调度的协作式多智能体框架",
    "abstract_zh": "随着物联网（IoT）技术的发展，越来越多的智能设备被接入边缘环境，导致服务请求量显著增长。在资源受限的情况下，为提升服务质量，高效的任务调度至关重要。然而，现有方法通常需要大量时间或计算资源，难以在多个优化目标之间取得良好平衡。针对这一挑战，我们提出了一种面向边缘任务调度的协同多智能体框架——CoMaTS（Collaborative Multi-Agent Framework for Edge Task Scheduling），通过多个智能体（生成器、评价者、批评者和优化器）的紧密协作，引导大语言模型（LLMs）设计高质量的调度算法，无需额外耗时的微调过程。其中，由多个大语言模型驱动的生成器负责生成一组候选算法；评价者分析得分最高的算法，批评者则分析得分最低的算法，并将原因反馈给优化器；优化器接收这些原因，进行对比分析，并为生成器下一轮操作提供改进建议。大量实验表明，与传统的启发式方法和强化学习方法相比，CoMaTS能够更有效地优化多个目标；同时，相较于最新的基于大语言模型的调度方法，CoMaTS在更低的成本下实现了更高的性能表现。"
  },
  {
    "date": "2025-11-28",
    "title": "Efficient Satellite Hardware Architecture for Accelerating Satellite Computing Power Networks",
    "authors": "Junxiang Qin, Lingbin Zeng, Shan Huang, Zhixi Yang, Yonggang Wang, Jun Yang",
    "publish": "IEEE Internet of Things Journal",
    "url": "https://doi.org/10.1109/jiot.2025.3638843",
    "source": "IEEE",
    "abstract": "Low-orbit mega-constellations promote the arrival of the era of the Internet of Things (IoT) in 6G, and satellite computing power networks (SCPN) provide a resilient resource for services in IoT. Satellite resources are scarce due to volume and power constraints, forcing most tasks to be processed on the ground and hindering SCPNs practical application. To meet the elastic resource requirements of IoT, SCPN requires that each satellite node share its resources with others. However, the closedness of traditional satellite architecture cannot meet this requirement. Given that, this paper introduces a novel efficient satellite hardware architecture designed for accelerating SCPN named Efficient Satellite Hardware Architecture (ESHA), which is capable of fast and flexible satellite resource sharing. Through reorganizing the satellite system, ESHA enables the satellites to share resources among modules to aggregate resources for tasks in IoT. Besides, this paper presents a queuing network method to model and analyze ESHA and evaluate its performance. The experimental results show that, for the same type of parallel tasks, the speedup ratio of this architecture is 2.4 times higher than that of the traditional satellite architecture, the task completion time is reduced by 48%, and the utilization of satellite resources is effectively improved.",
    "title_zh": "高效卫星硬件架构以加速卫星计算能力网络",
    "abstract_zh": "低轨道巨型星座推动了6G时代物联网（IoT）的到来，而卫星计算能力网络（SCPN）为物联网服务提供了可靠的资源支持。由于体积和功耗的限制，卫星资源十分有限，导致大多数任务仍需在地面处理，这严重制约了SCPN的实际应用。为了满足物联网对弹性资源的需求，SCPN要求每个卫星节点能够与其他节点共享其资源。然而，传统卫星架构的封闭性难以实现这一目标。针对这一问题，本文提出了一种新型高效的卫星硬件架构——高效卫星硬件架构（Efficient Satellite Hardware Architecture, ESHA），旨在加速SCPN的发展，具备快速且灵活的卫星资源共享能力。通过重新组织卫星系统，ESHA实现了模块间资源的共享与聚合，从而为物联网任务提供更强大的资源支持。此外，本文还提出了一种排队网络方法，用于建模和分析ESHA，并评估其性能表现。实验结果表明，在相同类型的并行任务下，该架构的加速比是传统卫星架构的2.4倍，任务完成时间减少48%，卫星资源利用率得到显著提升。"
  },
  {
    "date": "2025-11-28",
    "title": "LLMA4OpenMP: A Large Language Model Based Agent for Automatic OpenMP Parallelization",
    "authors": "Haoran Zhu, Weidong Wang",
    "publish": "2025 IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA)",
    "url": "https://doi.org/10.1109/ispa67752.2025.00165",
    "source": "IEEE",
    "abstract": "In the field of parallel computing, efficiently leveraging multi-core processors is essential. OpenMP, despite its popularity, poses challenges due to data-sharing and synchronization issues, making manual parallelization both time-consuming and prone to errors. Traditional compiler-based automation tools could be constrained to the final development stages. Recent advancements in large language models offer new opportunities for automation, with models like HPC-Coder demonstrating potential through fine-tuning. However, fine-tuning alone does not fully address the complexities of code comprehension. We introduce a novel agent that dynamically orchestrates static analysis tools to analyze code dependency and leverages in-context learning to generate OpenMP directives. Then, we implement this approach into a user-friendly plugin, namely LLMA4OpenMP, for Neovim and VS Code, enabling one-click OpenMP parallelization. We test our approach on the sophisticated AutoParBench and obtain an accuracy of <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{9 3. 1 \\%}$</tex>, outperforming the state-of-the-art LLM-based method. The source code for testing is available on the following GitHub repository: https://github.com/LLMA4OpenMP/LLMA4OpenMP_VScode",
    "title_zh": "LLMA4OpenMP：一种基于大型语言模型的自动OpenMP并行化代理",
    "abstract_zh": "在并行计算领域，高效利用多核处理器至关重要。尽管OpenMP广受欢迎，但其数据共享和同步问题带来了挑战，导致手动并行化既耗时又容易出错。传统的基于编译器的自动化工具往往只能在开发后期才发挥作用，存在局限性。近年来，大型语言模型的发展为自动化提供了新机遇，例如通过微调实现的HPC-Coder已展现出巨大潜力。然而，仅靠微调仍无法充分解决代码理解的复杂性问题。为此，我们提出一种新型智能体，该智能体动态调度静态分析工具以分析代码依赖关系，并利用上下文学习生成OpenMP指令。随后，我们将该方法集成到一个用户友好的插件——LLMA4OpenMP中，支持Neovim和VS Code，实现一键式OpenMP并行化。我们在复杂的AutoParBench基准测试上验证了该方法，取得了93.1%的准确率，优于当前最先进的基于大模型的方法。测试所用源代码可于以下GitHub仓库获取：https://github.com/LLMA4OpenMP/LLMA4OpenMP_VScode"
  }
]