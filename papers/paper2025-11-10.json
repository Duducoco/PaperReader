[
  {
    "date": "2025-11-10",
    "title": "Chatbot Framework for Power Quality Measurement Data and Documentation Using LLM and RAG",
    "authors": "Aadharsh Aadhithya A, Surya Santoso",
    "publish": "2025 IEEE Power &amp;amp; Energy Society General Meeting (PESGM)",
    "url": "https://doi.org/10.1109/pesgm52009.2025.11225681",
    "source": "IEEE",
    "abstract": "Analyzing three-phase voltage and current waveforms to identify the root causes of power quality disturbances is a complex task. It requires expert knowledge and often involves referencing external resources. Recent advances in large language models (LLMs) and retrieval-augmented generation (RAG) offer a promising solution for enhancing this process. This paper proposes and implements a framework for developing a domain-specific chatbot enabled by LLMs and RAG models to analyze power quality disturbance waveforms. The experimental bot, demonstrated and tailored for incipient cable faults, can detect and analyze fault events while facilitating user interaction with datasets and discussions on user-specified documentation. This proof-of-concept framework can be generalized to other power quality disturbance data and documentation, paving the way for more efficient and enhanced analysis of power quality disturbances."
  },
  {
    "date": "2025-11-10",
    "title": "LLM-Based Data Augmentation Method in Reinforcement Learning With Machine-Unlearning and Fine-Tuning",
    "authors": "Yunjiao Lei, Dayong Ye, Tianqing Zhu, Wanlei Zhou, Philip S. Yu.",
    "publish": "IEEE Transactions on Big Data",
    "url": "https://doi.org/10.1109/tbdata.2025.3630807",
    "source": "IEEE",
    "abstract": "Data augmentation in reinforcement learning (RL) aims to generate diverse and extensive datasets to enhance the learning process. Most existing studies on RL augmentation employ sample-based approaches that modify existing samples. However, many of these methods directly adopt augmentation strategies from other domains, which may present limitations when applied to RL. For instance, approaches derived from computer vision techniques are often not well-suited for general RL applications that do not involve visual inputs. Moreover, such sample-based methods frequently overlook the broader characteristics of the training environment, rendering the augmented data potentially less effective in complex scenarios, such as intelligent transportation systems. In addition, these methods can introduce significant risks to critical and sensitive data. For example, introducing noise to samples as a method of augmentation can precipitate adversarial attacks. Thus, a reliable and stable method of augmentation is necessary. To address these concerns, we propose a novel large language model (LLM)-based augmentation strategy in RL with machine unlearning and fine-tuning. This method utilizes LLMs for data augmentation, ensuring the reliability of the augmented data by tailoring it to specific environmental contexts. Additionally, it enhances the quality of augmentation by mitigating the impact on critical samples through the proposed novel machine unlearning method, while simultaneously fine-tuning the model to improve overall performance. Our experimental results indicate that this innovative approach significantly surpasses traditional augmentation methods in learning performance. By mitigating the impact on critical samples, our strategy not only generates more reliable augmented data but also enhances the effectiveness of RL models."
  },
  {
    "date": "2025-11-10",
    "title": "Grid CoPilot: A Large Language Model (LLM) based framework for Transforming Long-term Planning Analyses",
    "authors": "Sarthak Chaturvedi, Sichen Jin, Shrirang Abhyankar, Travis Thurber, Kostas Oikonomou, Nathalie Voisin",
    "publish": "2025 IEEE Power &amp;amp; Energy Society General Meeting (PESGM)",
    "url": "https://doi.org/10.1109/pesgm52009.2025.11225574",
    "source": "IEEE",
    "abstract": "This paper presents a novel approach to streamline, analyze, and visualize long-term planning simulation results using a large language model (LLM). We discuss the design, implementation, and performance of GridCoPilot - a first of its kind tool developed using ChatGPT - to analyze and visualize data from PCM simulations of long term planning studies. Grid Copilot processes PCM data generating concise textual summaries and context-aware visualizations, providing users with comprehensive insights. By automating data processing and visualization tasks, Grid Copilot significantly reduces the technical barriers to data analysis for long term planning studies. This enhancement can allow analysts, and policymakers to focus on interpreting results and making informed decisions, rather than grappling with data manipulation and visualization code."
  },
  {
    "date": "2025-11-10",
    "title": "Could vs Should: Exploring Prompting Strategies and Writer Perspectives Towards LLM Assistance in Storylet Authoring",
    "authors": "Samuel Shields, Celine Lafosse, Shi Johnson-Bey, Daeun Hwang, Noah Wardrip-Fruin, Edward F. Melcer",
    "publish": "IEEE Transactions on Games",
    "url": "https://doi.org/10.1109/tg.2025.3631000",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) and procedural narrative practices have grown significantly over the past few years, but there are many questions about their newfound capabilities. In the context of video game narratives, some pre dominant questions involve whether LLMs could create content for interactive narratives, such as dialogue trees and dialogue. Alongside this idea, narrative design authors question whether we should use LLMs in practice. Extending our prior work from a 2024 IEEE CoG paper, we conducted two new studies to address both questions. The first study uses multiple content generation methods through an LLM to see if it can produce the required content for an interactive narrative. This content is put in a questionnaire for the secondary study and given to a group of experienced narrative designers to determine their opinions and concerns. We find that while LLMs hold some promise in their ability to create branching narratives, writers have concerns about utilizing them in their workflow"
  },
  {
    "date": "2025-11-10",
    "title": "LLM-OFA: On-the-Fly Adaptation of Large Language Models to Address Temporal Drift Across Two Decades of News",
    "authors": "Pouya Ghahramanian, Sepehr Bakhshi, Fazli Can",
    "publish": "Proceedings of the 34th ACM International Conference on Information and Knowledge Management",
    "url": "https://doi.org/10.1145/3746252.3760846",
    "source": "ACM",
    "abstract": "We investigate the problem of on-the-fly adaptation (OFA) with online feedback for large language models (LLMs) in the context of temporally evolving data. In this setting, each incoming instance-or a small batch- is first processed for inference, and its true label is revealed immediately after prediction, allowing the model to be updated in a sequential, single-pass manner. While pre-trained LLMs achieve state-of-the-art results across NLP tasks, they often struggle to generalize under dynamic distribution shifts-particularly in continuously evolving environments. Despite the importance of this problem, existing research on online adaptation of LLMs remains limited, and there is a lack of large-scale benchmarks for evaluating such methods. To address these gaps, we introduce 1M-News, a large-scale benchmark of one million New York Times headlines spanning two decades, and benchmark six state-of-the-art LLMs by fine-tuning them on the first 10 years and applying OFA on the following 10 years. To improve adaptation performance, we develop Adaptimizer, the first optimizer specifically designed for OFA, enabling rapid and stable model updates under temporal distribution shift. Adaptimizer maintains two sets of weights-fast and slow-balancing rapid adaptation with long-term stability and generalization across the stream. Our experiments demonstrate that OFA with Adaptimizer achieves consistent improvements over static baselines. All code and data are publicly available at https://github.com/pouyaghahramanian/LLM-OFA."
  }
]