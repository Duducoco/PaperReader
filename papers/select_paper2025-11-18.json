[
  {
    "date": "2025-11-18",
    "title": "LogPurge: Log Data Purification for Anomaly Detection via Rule-Enhanced Filtering",
    "authors": "Shenglin Zhang, Ziang Chen, Zijing Que, Yilun Liu, Yongqian Sun, Sicheng Wei, Dan Pei, Hailin Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14062v1",
    "source": "arXiv",
    "abstract": "Log anomaly detection, which is critical for identifying system failures and preempting security breaches, detects irregular patterns within large volumes of log data, and impacts domains such as service reliability, performance optimization, and database log analysis. Modern log anomaly detection methods rely on training deep learning models on clean, anomaly-free log sequences. However, obtaining such clean log data requires costly and tedious human labeling, and existing automatic cleaning methods fail to fully integrate the specific characteristics and actual semantics of logs in their purification process. In this paper, we propose a cost-aware, rule-enhanced purification framework, LogPurge, that automatically selects a sufficient subset of normal log sequences from contamination log sequences to train a anomaly detection model. Our approach involves a two-stage filtering algorithm: In the first stage, we use a large language model (LLM) to remove clustered anomalous patterns and enhance system rules to improve LLM's understanding of system logs; in the second stage, we utilize a divide-and-conquer strategy that decomposes the remaining contaminated regions into smaller subproblems, allowing each to be effectively purified through the first stage procedure. Our experiments, conducted on two public datasets and one industrial dataset, show that our method significantly removes an average of 98.74% of anomalies while retaining 82.39% of normal samples. Compared to the latest unsupervised log sample selection algorithms, our method achieves F-1 score improvements of 35.7% and 84.11% on the public datasets, and an impressive 149.72% F-1 improvement on the private dataset, demonstrating the effectiveness of our approach.",
    "title_zh": "LogPurge：通过规则增强过滤实现异常检测的日志数据净化",
    "abstract_zh": "日志异常检测对于识别系统故障和提前预防安全攻击至关重要，它能够从海量日志数据中发现异常模式，广泛影响服务可靠性、性能优化以及数据库日志分析等领域。当前的现代日志异常检测方法依赖于在干净、无异常的日志序列上训练深度学习模型。然而，获取此类干净日志数据需要耗费大量人力与时间进行标注，而现有的自动清洗方法在净化过程中未能充分融合日志本身特有的语义特征与实际含义。本文提出一种成本感知、规则增强的净化框架——LogPurge，可自动从含污染的日志序列中选取足够数量的正常日志样本，用于训练异常检测模型。我们的方法采用两阶段过滤算法：第一阶段，利用大语言模型（LLM）剔除聚集性的异常模式，并通过增强系统规则来提升LLM对系统日志的理解能力；第二阶段，采用分治策略将剩余的污染区域分解为更小的子问题，使每个子问题均可通过第一阶段的方法有效净化。我们在两个公开数据集和一个工业数据集上开展实验，结果表明，该方法平均可清除98.74%的异常，同时保留82.39%的正常样本。相较于最新的无监督日志样本选择算法，本方法在两个公开数据集上的F-1分数分别提升了35.7%和84.11%，在私有数据集上更是实现了惊人的149.72% F-1分数提升，充分验证了所提方法的有效性。"
  },
  {
    "date": "2025-11-18",
    "title": "AISAC: An Integrated multi-agent System for Transparent, Retrieval-Grounded Scientific Assistance",
    "authors": "Chandrachur Bhattacharya, Sibendu Som",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14043v1",
    "source": "arXiv",
    "abstract": "AI Scientific Assistant Core (AISAC) is an integrated multi-agent system developed at Argonne National Laboratory for scientific and engineering workflows. AISAC builds on established technologies - LangGraph for orchestration, FAISS for vector search, and SQLite for persistence - and integrates them into a unified system prototype focused on transparency, provenance tracking, and scientific adaptability. The system implements a Router-Planner-Coordinator workflow and an optional Evaluator role, using prompt-engineered agents coordinated via LangGraph's StateGraph and supported by helper agents such as a Researcher. Each role is defined through custom system prompts that enforce structured JSON outputs. A hybrid memory approach (FAISS + SQLite) enables both semantic retrieval and structured conversation history. An incremental indexing strategy based on file hashing minimizes redundant re-embedding when scientific corpora evolve. A configuration-driven project bootstrap layer allows research teams to customize tools, prompts, and data sources without modifying core code. All agent decisions, tool invocations, and retrievals are logged and visualized through a custom Gradio interface, providing step-by-step transparency for each reasoning episode. The authors have applied AISAC to multiple research areas at Argonne, including specialized deployments for waste-to-products research and energy process safety, as well as general-purpose scientific assistance, demonstrating its cross-domain applicability.",
    "title_zh": "AISAC：一种集成的多智能体系统，用于透明、基于检索的科学辅助",
    "abstract_zh": "AI科学助手核心系统（AISAC）是由阿贡国家实验室开发的集成式多智能体系统，专为科学与工程工作流设计。AISAC基于成熟技术——LangGraph用于任务编排、FAISS用于向量搜索、SQLite用于数据持久化——并将其整合为一个统一的系统原型，重点聚焦于透明性、溯源追踪和科学适应性。该系统采用“路由器-规划器-协调器”工作流，并可选地引入“评估者”角色，通过LangGraph的StateGraph协调提示工程化的智能体，辅以如“研究者”等辅助智能体。每个角色均通过自定义系统提示进行定义，强制输出结构化JSON格式。系统采用混合记忆机制（FAISS + SQLite），实现语义检索与结构化对话历史的双重支持。基于文件哈希的增量索引策略，在科学文献库演进时最大限度减少重复嵌入，提升效率。配置驱动的项目初始化层使研究团队可在不修改核心代码的前提下，灵活定制工具、提示模板和数据源。所有智能体决策、工具调用及信息检索均被完整记录，并通过定制的Gradio界面进行可视化展示，为每一次推理过程提供逐步骤的透明追溯。作者已在阿贡国家实验室多个研究领域应用AISAC，包括废物转化产品研究、能源过程安全等专项部署，以及通用型科学辅助场景，充分验证了其跨领域的适用性。"
  },
  {
    "date": "2025-11-18",
    "title": "Don't Miss the Forest for the Trees: In-Depth Confidence Estimation for LLMs via Reasoning over the Answer Space",
    "authors": "Ante Wang, Weizhi Ma, Yang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14275v1",
    "source": "arXiv",
    "abstract": "Knowing the reliability of a model's response is essential in application. With the strong generation capabilities of LLMs, research has focused on generating verbalized confidence. This is further enhanced by combining chain-of-thought reasoning, which provides logical and transparent estimation. However, how reasoning strategies affect the estimated confidence is still under-explored. In this work, we demonstrate that predicting a verbalized probability distribution can effectively encourage in-depth reasoning for confidence estimation. Intuitively, it requires an LLM to consider all candidates within the answer space instead of basing on a single guess, and to carefully assign confidence scores to meet the requirements of a distribution. This method shows an advantage across different models and various tasks, regardless of whether the answer space is known. Its advantage is maintained even after reinforcement learning, and further analysis shows its reasoning patterns are aligned with human expectations.",
    "title_zh": "不要因小失大：通过答案空间推理实现大语言模型的深度置信度估计",
    "abstract_zh": "在实际应用中，了解模型回答的可靠性至关重要。随着大语言模型（LLM）强大生成能力的发展，研究重点已转向生成可表述的置信度。这一方法进一步通过结合思维链推理（chain-of-thought reasoning）得到增强，从而实现逻辑清晰且透明的置信度估计。然而，推理策略如何影响置信度估计仍缺乏深入探索。在本研究中，我们证明了预测一个可表述的概率分布能够有效促进模型进行深层次的推理以完成置信度评估。直观上，这种方法要求LLM不仅基于单一猜测，而是需全面考虑答案空间中的所有可能选项，并仔细分配置信度分数，以满足概率分布的要求。该方法在不同模型和多种任务中均展现出优势，无论答案空间是否已知。即使经过强化学习后，其优势依然保持不变；进一步分析表明，该方法所体现的推理模式与人类预期高度一致。"
  },
  {
    "date": "2025-11-18",
    "title": "Analyzing Many Simulations of Hybrid Programs in Lince",
    "authors": "Reydel Arrieta, José Proença, Patrick Meumeu Yomsi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14436v1",
    "source": "arXiv",
    "abstract": "Hybrid systems are increasingly used in critical applications such as medical devices, infrastructure systems, and autonomous vehicles. Lince is an academic tool for specifying and simulating such systems using a C-like language with differential equations. This paper presents recent experiments that enhance Lince with mechanisms for executing multiple simulation variants and generating histograms that quantify the frequency with which a given property holds. We illustrate our extended Lince using variations of an adaptive cruise control system.",
    "title_zh": "在Lince中分析混合程序的大量仿真",
    "abstract_zh": "混合系统在医疗设备、基础设施系统和自动驾驶汽车等关键应用中正得到越来越广泛的应用。Lince 是一个学术工具，使用类似 C 语言的语法结合微分方程来描述和仿真这类系统。本文介绍了近期对 Lince 的实验性改进，新增了执行多个仿真变体以及生成直方图的功能，以量化特定属性成立的频率。我们通过自适应巡航控制系统的变化实例展示了扩展后的 Lince 的应用效果。"
  },
  {
    "date": "2025-11-18",
    "title": "APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design",
    "authors": "Xinpeng Chen, Xiaofeng Han, Kaihao Zhang, Guochao Ren, Yujie Wang, Wenhao Cao, Yang Zhou, Jianfeng Lu, Zhenbo Song",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14101v1",
    "source": "arXiv",
    "abstract": "Layout design is a crucial step in developing mobile app pages. However, crafting satisfactory designs is time-intensive for designers: they need to consider which controls and content to present on the page, and then repeatedly adjust their size, position, and style for better aesthetics and structure. Although many design software can now help to perform these repetitive tasks, extensive training is needed to use them effectively. Moreover, collaborative design across app pages demands extra time to align standards and ensure consistent styling. In this work, we propose APD-agents, a large language model (LLM) driven multi-agent framework for automated page design in mobile applications. Our framework contains OrchestratorAgent, SemanticParserAgent, PrimaryLayoutAgent, TemplateRetrievalAgent, and RecursiveComponentAgent. Upon receiving the user's description of the page, the OrchestratorAgent can dynamically can direct other agents to accomplish users' design task. To be specific, the SemanticParserAgent is responsible for converting users' descriptions of page content into structured data. The PrimaryLayoutAgent can generate an initial coarse-grained layout of this page. The TemplateRetrievalAgent can fetch semantically relevant few-shot examples and enhance the quality of layout generation. Besides, a RecursiveComponentAgent can be used to decide how to recursively generate all the fine-grained sub-elements it contains for each element in the layout. Our work fully leverages the automatic collaboration capabilities of large-model-driven multi-agent systems. Experimental results on the RICO dataset show that our APD-agents achieve state-of-the-art performance.",
    "title_zh": "APD-Agents：一种由大型语言模型驱动的多智能体协作框架，用于自动化页面设计",
    "abstract_zh": "布局设计是开发移动应用页面的关键步骤。然而，设计师要制作出令人满意的界面设计往往耗时费力：他们需要考虑页面上应展示哪些控件和内容，并反复调整其大小、位置和样式，以获得更佳的视觉效果与结构布局。尽管目前许多设计软件已能协助完成这些重复性任务，但要高效使用这些工具仍需大量培训。此外，在多个应用页面之间进行协同设计时，还需额外花费时间来统一设计标准并确保风格一致。在本研究中，我们提出了APD-agents——一种由大型语言模型（LLM）驱动的多智能体框架，用于实现移动应用页面的自动化设计。该框架包含协调器智能体（OrchestratorAgent）、语义解析智能体（SemanticParserAgent）、主布局生成智能体（PrimaryLayoutAgent）、模板检索智能体（TemplateRetrievalAgent）以及递归组件生成智能体（RecursiveComponentAgent）。当接收到用户对页面的描述后，协调器智能体可动态调度其他智能体协同完成设计任务。具体而言，语义解析智能体负责将用户对页面内容的描述转化为结构化数据；主布局生成智能体能够生成页面的初始粗粒度布局；模板检索智能体则会获取语义相关的少量示例（few-shot examples），从而提升布局生成的质量；此外，递归组件生成智能体可根据布局中的每个元素，决定如何递归地生成其所有细粒度子元素。我们的工作充分挖掘了基于大模型的多智能体系统在自动协作方面的潜力。在RICO数据集上的实验结果表明，APD-agents达到了当前最先进的性能水平。"
  },
  {
    "date": "2025-11-18",
    "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning",
    "authors": "Mingyue Cheng, Jie Ouyang, Shuo Yu, Ruiran Yan, Yucong Luo, Zirui Liu, Daoyu Wang, Qi Liu, Enhong Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14460v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly being explored for building Agents capable of active environmental interaction (e.g., via tool use) to solve complex problems. Reinforcement Learning (RL) is considered a key technology with significant potential for training such Agents; however, the effective application of RL to LLM Agents is still in its nascent stages and faces considerable challenges. Currently, this emerging field lacks in-depth exploration into RL approaches specifically tailored for the LLM Agent context, alongside a scarcity of flexible and easily extensible training frameworks designed for this purpose. To help advance this area, this paper first revisits and clarifies Reinforcement Learning methodologies for LLM Agents by systematically extending the Markov Decision Process (MDP) framework to comprehensively define the key components of an LLM Agent. Secondly, we introduce Agent-R1, a modular, flexible, and user-friendly training framework for RL-based LLM Agents, designed for straightforward adaptation across diverse task scenarios and interactive environments. We conducted experiments on Multihop QA benchmark tasks, providing initial validation for the effectiveness of our proposed methods and framework.",
    "title_zh": "Agent-R1：通过端到端强化学习训练强大的大语言模型代理",
    "abstract_zh": "大型语言模型（LLMs）正日益被探索用于构建能够主动与环境交互（例如通过工具使用）以解决复杂问题的智能体。强化学习（RL）被认为是一项关键技术，具有训练此类智能体的巨大潜力；然而，将强化学习有效应用于LLM智能体仍处于初级阶段，面临诸多挑战。目前，该新兴领域在针对LLM智能体场景量身定制的强化学习方法方面缺乏深入研究，同时缺少灵活且易于扩展的训练框架来支持这一目标。为推动该领域的发展，本文首先系统性地回顾并澄清了面向LLM智能体的强化学习方法，通过扩展马尔可夫决策过程（MDP）框架，全面定义了LLM智能体的关键组成部分。其次，我们提出了Agent-R1，一个模块化、灵活且用户友好的基于强化学习的LLM智能体训练框架，旨在轻松适配多种任务场景和交互环境。我们在多跳问答（Multihop QA）基准任务上进行了实验，初步验证了所提方法与框架的有效性。"
  },
  {
    "date": "2025-11-18",
    "title": "Mutation Testing for Industrial Robotic Systems",
    "authors": "Marcela Gonçalves dos Santos, Sylvain Hallé, Fábio Petrillo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14432v1",
    "source": "arXiv",
    "abstract": "Industrial robotic systems (IRS) are increasingly deployed in diverse environments, where failures can result in severe accidents and costly downtime. Ensuring the reliability of the software controlling these systems is therefore critical. Mutation testing, a technique widely used in software engineering, evaluates the effectiveness of test suites by introducing small faults, or mutants, into the code. However, traditional mutation operators are poorly suited to robotic programs, which involve message-based commands and interactions with the physical world. This paper explores the adaptation of mutation testing to IRS by defining domain-specific mutation operators that capture the semantics of robot actions and sensor readings. We propose a methodology for generating meaningful mutants at the level of high-level read and write operations, including movement, gripper actions, and sensor noise injection. An empirical study on a pick-and-place scenario demonstrates that our approach produces more informative mutants and reduces the number of invalid or equivalent cases compared to conventional operators. Results highlight the potential of mutation testing to enhance test suite quality and contribute to safer, more reliable industrial robotic systems.",
    "title_zh": "工业机器人系统的变异测试",
    "abstract_zh": "工业机器人系统（IRS）正被越来越多地部署于各种环境中，其故障可能导致严重事故和高昂的停机成本。因此，确保控制这些系统的软件可靠性至关重要。突变测试是软件工程中广泛使用的一种技术，通过在代码中引入微小缺陷（即“突变体”）来评估测试用例集的有效性。然而，传统的突变算子并不适用于机器人程序，因为后者涉及基于消息的指令以及与物理世界的交互。本文探讨了将突变测试应用于工业机器人系统的适应性，提出了针对该领域的特定突变算子，以捕捉机器人动作和传感器读数的语义特征。我们提出了一种方法，可在高层读写操作层面生成有意义的突变体，包括运动、夹持器操作以及传感器噪声注入等。对抓取-放置场景的实证研究表明，与传统算子相比，我们的方法生成的突变体更具信息量，并显著减少了无效或等价突变的情况。结果表明，突变测试具有提升测试用例质量的巨大潜力，有助于构建更安全、更可靠的工业机器人系统。"
  },
  {
    "date": "2025-11-18",
    "title": "Keeping Code-Aware LLMs Fresh: Full Refresh, In-Context Deltas, and Incremental Fine-Tuning",
    "authors": "Pradeep Kumar Sharma, Ishaan Puri, Mantinder Jit Singh, Swapnil Shivaprasad, Hritvik Shrivastava",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14022v1",
    "source": "arXiv",
    "abstract": "Modern codebases evolve continuously: files are renamed or deleted; public APIs drift; behavior shifts within otherwise familiar modules. A model trained yesterday to map a developer's natural-language question to the exact set of repository file paths that matter will degrade tomorrow, even if the questions themselves look unchanged. In this paper we study, at system scale and across several widely used repositories, how to keep such a model fresh without surrendering retention on earlier code. We frame freshness as a form of domain drift between a base snapshot and the current HEAD, and we compare three families of update strategies: (A) Full Refresh, retraining the entire model at the new snapshot; (B) In-Context Learning (ICL) that injects recent deltas (raw git diffs or concise English summaries) at inference; and (C) Incremental Fine-Tuning (Inc-FT) on delta-derived training sets, with carefully controlled NEW:OLD mixing to mitigate catastrophic forgetting. We contribute an alias-aware evaluation protocol that credits rename while never rewarding deleted paths, and a practical Forgetting Probe that quantifies residual emissions of obsolete paths. Across Flask, SQLAlchemy, Pandas, and Poetry, Inc-FT with old-aware mixes delivers the best overall balance on mixed sets, ICL with English delta summaries delivers the fastest new-code lift when training is not feasible, and Full Refresh remains the ceiling when maximum NEW accuracy matters. We also compare Git-diff Inc-FT to full-file Inc-FT, showing that diffs excel in rename/delete-heavy windows while full-file context wins in behavior-change-heavy windows.",
    "title_zh": "保持代码感知大模型的时效性：全面刷新、上下文增量更新与增量微调",
    "abstract_zh": "现代代码库持续演进：文件被重命名或删除，公共API发生偏移，即使在看似熟悉的模块中，行为也可能发生变化。一个昨天训练好的模型，能够将开发者的自然语言问题精准映射到相关仓库文件路径，但到了明天，其性能就会下降，即便问题本身看起来没有变化。本文在系统规模上，针对多个广泛使用的代码仓库，研究如何在不牺牲对早期代码保留能力的前提下，保持此类模型的“新鲜度”。我们将“新鲜度”定义为基线快照与当前HEAD之间的一种领域漂移，并比较了三种更新策略：（A）全量刷新（Full Refresh），在新快照下重新训练整个模型；（B）上下文学习（In-Context Learning, ICL），在推理时注入近期变更（原始git diff或简洁的英文摘要）；（C）增量微调（Incremental Fine-Tuning, Inc-FT），基于变更数据构建训练集，并通过精心控制的新旧数据混合比例来缓解灾难性遗忘。我们提出了一种别名感知的评估协议，能够正确奖励文件重命名，同时绝不奖励已被删除的路径；并设计了一个实用的遗忘探测器（Forgetting Probe），用于量化过时路径的残余输出。在Flask、SQLAlchemy、Pandas和Poetry等项目上的实验表明：采用旧数据感知混合策略的Inc-FT在综合表现上达到最佳平衡；当无法进行训练时，使用英文变更摘要的ICL能最快提升对新代码的识别能力；而当追求最大新代码准确率时，全量刷新仍是最优上限。此外，我们还对比了基于Git diff的Inc-FT与基于完整文件的Inc-FT，结果表明：在重命名和删除操作密集的窗口中，diff方法表现更优；而在行为变更密集的场景中，完整文件上下文则更具优势。"
  },
  {
    "date": "2025-11-18",
    "title": "FlakyGuard: Automatically Fixing Flaky Tests at Industry Scale",
    "authors": "Chengpeng Li, Farnaz Behrang, August Shi, Peng Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14002v1",
    "source": "arXiv",
    "abstract": "Flaky tests that non-deterministically pass or fail waste developer time and slow release cycles. While large language models (LLMs) show promise for automatically repairing flaky tests, existing approaches like FlakyDoctor fail in industrial settings due to the context problem: providing either too little context (missing critical production code) or too much context (overwhelming the LLM with irrelevant information). We present FlakyGuard, which addresses this problem by treating code as a graph structure and using selective graph exploration to find only the most relevant context. Evaluation on real-world flaky tests from industrial repositories shows that FlakyGuard repairs 47.6 % of reproducible flaky tests with 51.8 % of the fixes accepted by developers. Besides it outperforms state-of-the-art approaches by at least 22 % in repair success rate. Developer surveys confirm that 100 % find FlakyGuard's root cause explanations useful.",
    "title_zh": "FlakyGuard：在工业规模下自动修复不稳定的测试",
    "abstract_zh": "非确定性地通过或失败的脆弱测试会浪费开发人员的时间并拖慢发布周期。尽管大型语言模型（LLMs）在自动修复脆弱测试方面展现出巨大潜力，但现有方法如 FlakyDoctor 在工业环境中表现不佳，主要原因是“上下文问题”：要么提供的上下文过少（遗漏关键的生产代码），要么提供的上下文过多（向 LLM 传递了大量无关信息，造成干扰）。我们提出了 FlakyGuard，该方法将代码视为图结构，并通过选择性图探索仅提取最相关的上下文信息，从而有效解决这一问题。在来自工业级代码仓库的真实脆弱测试上的评估表明，FlakyGuard 能够修复 47.6% 的可复现脆弱测试，且其中 51.8% 的修复方案被开发者接受。此外，其修复成功率比当前最先进的方法至少高出 22%。开发者调查结果也证实，100% 的受访者认为 FlakyGuard 提供的根本原因解释非常有用。"
  },
  {
    "date": "2025-11-18",
    "title": "KTester: Leveraging Domain and Testing Knowledge for More Effective LLM-based Test Generation",
    "authors": "Anji Li, Mingwei Liu, Zhenxi Chen, Zheng Pei, Zike Li, Dekun Dai, Yanlin Wang, Zibin Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14224v1",
    "source": "arXiv",
    "abstract": "Automated unit test generation using large language models (LLMs) holds great promise but often struggles with generating tests that are both correct and maintainable in real-world projects. This paper presents KTester, a novel framework that integrates project-specific knowledge and testing domain knowledge to enhance LLM-based test generation. Our approach first extracts project structure and usage knowledge through static analysis, which provides rich context for the model. It then employs a testing-domain-knowledge-guided separation of test case design and test method generation, combined with a multi-perspective prompting strategy that guides the LLM to consider diverse testing heuristics. The generated tests follow structured templates, improving clarity and maintainability. We evaluate KTester on multiple open-source projects, comparing it against state-of-the-art LLM-based baselines using automatic correctness and coverage metrics, as well as a human study assessing readability and maintainability. Results demonstrate that KTester significantly outperforms existing methods across six key metrics, improving execution pass rate by 5.69% and line coverage by 8.83% over the strongest baseline, while requiring less time and generating fewer test cases. Human evaluators also rate the tests produced by KTester significantly higher in terms of correctness, readability, and maintainability, confirming the practical advantages of our knowledge-driven framework.",
    "title_zh": "KTester：利用领域与测试知识实现更高效的基于大模型的测试用例生成",
    "abstract_zh": "使用大型语言模型（LLMs）自动生成单元测试具有巨大潜力，但在实际项目中往往难以生成既正确又可维护的测试。本文提出KTester，一种创新的框架，通过融合项目特定知识与测试领域知识，以提升基于LLM的测试生成效果。我们的方法首先通过静态分析提取项目的结构和使用知识，为模型提供丰富的上下文信息。随后，采用基于测试领域知识引导的测试用例设计与测试方法生成分离策略，并结合多角度提示（multi-perspective prompting）机制，引导LLM综合考虑多种测试启发式规则。生成的测试遵循结构化模板，显著提升了代码的清晰度与可维护性。我们在多个开源项目上对KTester进行了评估，采用自动化的正确性与覆盖率指标，以及人工评估来衡量测试的可读性与可维护性，与当前最先进的LLM基线方法进行对比。结果表明，KTester在六项关键指标上均显著优于现有方法：相较于最强基线，执行通过率提升5.69%，行覆盖率提高8.83%，同时耗时更短、生成的测试用例数量更少。人工评估也显示，KTester生成的测试在正确性、可读性和可维护性方面获得更高评分，充分验证了我们基于知识驱动框架的实际优势。"
  },
  {
    "date": "2025-11-18",
    "title": "LAUD: Integrating Large Language Models with Active Learning for Unlabeled Data",
    "authors": "Tzu-Hsuan Chou, Chun-Nan Chou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14738v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have shown a remarkable ability to generalize beyond their pre-training data, and fine-tuning LLMs can elevate performance to human-level and beyond. However, in real-world scenarios, lacking labeled data often prevents practitioners from obtaining well-performing models, thereby forcing practitioners to highly rely on prompt-based approaches that are often tedious, inefficient, and driven by trial and error. To alleviate this issue of lacking labeled data, we present a learning framework integrating LLMs with active learning for unlabeled dataset (LAUD). LAUD mitigates the cold-start problem by constructing an initial label set with zero-shot learning. Experimental results show that LLMs derived from LAUD outperform LLMs with zero-shot or few-shot learning on commodity name classification tasks, demonstrating the effectiveness of LAUD.",
    "title_zh": "LAUD：将大型语言模型与主动学习相结合以处理未标记数据",
    "abstract_zh": "大型语言模型（LLMs）展现出超越其预训练数据的惊人泛化能力，通过微调，LLMs 的性能可达到甚至超过人类水平。然而，在实际应用中，由于缺乏标注数据，从业者往往难以获得高性能模型，从而不得不高度依赖基于提示（prompt-based）的方法，而这些方法通常繁琐、低效且依赖反复试错。为缓解标注数据匮乏的问题，我们提出了一种将大型语言模型与主动学习相结合的学习框架——LAUD（Learning from Unlabeled Datasets）。LAUD 通过零样本学习构建初始标签集，有效缓解了冷启动问题。实验结果表明，在商品名称分类任务中，基于 LAUD 得到的 LLM 性能优于仅采用零样本或少样本学习的 LLM，充分证明了 LAUD 的有效性。"
  },
  {
    "date": "2025-11-18",
    "title": "ALEX:A Light Editing-knowledge Extractor",
    "authors": "Minghu Wang, Shuliang Zhao, Yuanyuan Zhao, Hongxia Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14018v1",
    "source": "arXiv",
    "abstract": "The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retrieval efficiency, particularly when handling complex, multi-hop questions that require multi-step reasoning. To address these challenges, this paper introduces ALEX (A Light Editing-knowledge Extractor), a lightweight knowledge editing framework. The core innovation of ALEX is its hierarchical memory architecture, which organizes knowledge updates (edits) into semantic clusters. This design fundamentally reduces retrieval complexity from a linear O(N) to a highly scalable O(K+N/C). Furthermore, the framework integrates an Inferential Query Synthesis (IQS) module to bridge the semantic gap between queries and facts , and a Dynamic Evidence Adjudication (DEA) engine that executes an efficient two-stage retrieval process. Experiments on the MQUAKE benchmark demonstrate that ALEX significantly improves both the accuracy of multi-hop answers (MultiHop-ACC) and the reliability of reasoning paths (HopWise-ACC). It also reduces the required search space by over 80% , presenting a promising path toward building scalable, efficient, and accurate knowledge editing systems.",
    "title_zh": "ALEX：一种轻量级的编辑知识提取器",
    "abstract_zh": "大型语言模型（LLMs）中知识的静态特性使其难以适应不断变化的信息，因此知识编辑成为一项关键任务。然而，现有方法在可扩展性和检索效率方面面临挑战，尤其是在处理需要多步推理的复杂多跳问题时尤为明显。为应对这些挑战，本文提出了一种轻量级知识编辑框架——ALEX（A Light Editing-knowledge Extractor）。ALEX的核心创新在于其分层记忆架构，将知识更新（编辑）按语义聚类组织，从根本上将检索复杂度从线性O(N)降低至高度可扩展的O(K+N/C)。此外，该框架集成了推理性查询生成（IQS）模块，以弥合查询与事实之间的语义鸿沟，并引入动态证据仲裁（DEA）引擎，实现高效的两阶段检索过程。在MQUAKE基准测试上的实验表明，ALEX显著提升了多跳答案的准确率（MultiHop-ACC）和推理路径的可靠性（HopWise-ACC），同时将所需搜索空间减少超过80%，为构建可扩展、高效且精准的知识编辑系统提供了极具前景的解决方案。"
  },
  {
    "date": "2025-11-18",
    "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents",
    "authors": "Jingyi Jia, Qinbin Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14650v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM) agents have emerged as powerful tools for automating complex tasks by leveraging the reasoning and decision-making abilities of LLMs. However, a major bottleneck in current agent frameworks lies in the high inference cost of tool selection, especially in approaches like ReAct that repeatedly invoke the LLM to determine which tool to use at each step. In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns. AutoTool constructs a directed graph from historical agent trajectories, where nodes represent tools and edges capture transition probabilities, effectively modeling the inertia in tool selection. It further integrates parameter-level information to refine tool input generation. By traversing this structured representation, AutoTool efficiently selects tools and their parameters with minimal reliance on LLM inference. Extensive experiments across diverse agent tasks demonstrate that AutoTool reduces inference costs by up to 30% while maintaining competitive task completion rates, offering a practical and scalable enhancement for inference-heavy frameworks. Our work highlights the promise of integrating statistical structure into LLM agent design for greater efficiency without sacrificing performance.",
    "title_zh": "AutoTool：大型语言模型代理的高效工具选择",
    "abstract_zh": "大型语言模型（LLM）代理已成为通过利用LLM的推理与决策能力来自动化复杂任务的强大工具。然而，当前代理框架的一个主要瓶颈在于工具选择过程中的高推理成本，尤其是在ReAct等方法中，需要反复调用LLM以决定每一步应使用哪个工具。在本研究中，我们提出了AutoTool——一种基于图结构的新框架，该框架通过利用一个关键的实证观察：工具使用的惯性（即工具调用倾向于遵循可预测的序列模式），从而避免了重复的LLM推理。AutoTool从历史代理轨迹中构建有向图，其中节点代表工具，边则捕捉工具之间的转移概率，有效建模了工具选择中的惯性特征。此外，该框架还融合了参数级别的信息，以优化工具输入的生成。通过遍历这一结构化表示，AutoTool能够以极低的LLM推理依赖，高效地完成工具及其参数的选择。在多种代理任务上的大量实验表明，AutoTool将推理成本降低了高达30%，同时保持了具有竞争力的任务完成率，为高推理开销的框架提供了实用且可扩展的优化方案。我们的工作凸显了在LLM代理设计中融入统计结构以提升效率的巨大潜力，且无需牺牲性能。"
  },
  {
    "date": "2025-11-18",
    "title": "Seer: Online Context Learning for Fast Synchronous LLM Reinforcement Learning",
    "authors": "Ruoyu Qin, Weiran He, Weixiao Huang, Yangkun Zhang, Yikai Zhao, Bo Pang, Xinran Xu, Yingdi Shan, Yongwei Wu, Mingxing Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14617v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning (RL) has become critical for advancing modern Large Language Models (LLMs), yet existing synchronous RL systems face severe performance bottlenecks. The rollout phase, which dominates end-to-end iteration time, suffers from substantial long-tail latency and poor resource utilization due to inherent workload imbalance. We present Seer, a novel online context learning system that addresses these challenges by exploiting previously overlooked similarities in output lengths and generation patterns among requests sharing the same prompt. Seer introduces three key techniques: divided rollout for dynamic load balancing, context-aware scheduling, and adaptive grouped speculative decoding. Together, these mechanisms substantially reduce long-tail latency and improve resource efficiency during rollout. Evaluations on production-grade RL workloads demonstrate that Seer improves end-to-end rollout throughput by 74% to 97% and reduces long-tail latency by 75% to 93% compared to state-of-the-art synchronous RL systems, significantly accelerating RL training iterations.",
    "title_zh": "观测者：面向快速同步大语言模型强化学习的在线上下文学习",
    "abstract_zh": "强化学习（RL）已成为推动现代大语言模型（LLMs）发展的关键力量，然而现有的同步强化学习系统面临严重的性能瓶颈。在端到端迭代过程中，占据主要时间的生成阶段由于固有的负载不均衡，导致显著的长尾延迟和资源利用率低下。我们提出了Seer——一种新颖的在线上下文学习系统，通过挖掘共享相同提示（prompt）的不同请求之间在输出长度和生成模式上的潜在相似性，有效解决了上述挑战。Seer引入了三项关键技术：分段生成以实现动态负载均衡、基于上下文感知的调度策略，以及自适应分组推测解码。这些机制协同作用，大幅降低了长尾延迟，并提升了生成阶段的资源利用效率。在真实生产级强化学习工作负载上的评估表明，与当前最先进的同步RL系统相比，Seer将端到端生成吞吐量提升了74%至97%，长尾延迟降低75%至93%，显著加速了强化学习训练的迭代进程。"
  },
  {
    "date": "2025-11-18",
    "title": "Entropy-Guided Reasoning Compression",
    "authors": "Hourun Zhu, Yang Gao, Wenlong Fei, Jiawei Li, Huashan Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14258v1",
    "source": "arXiv",
    "abstract": "Large reasoning models have demonstrated remarkable performance on complex reasoning tasks, yet the excessive length of their chain-of-thought outputs remains a major practical bottleneck due to high computation cost and poor deployability. Existing compression methods have achieved partial success but overlook a crucial phenomenon in the training process -- the entropy conflict. During compression training, entropy decreases, leading to shorter reasoning but limited exploration, while accuracy-oriented objectives increase entropy, lengthening reasoning chains. This can cause the model to get stuck in a local dilemma. Our analysis further reveals the origin of the entropy conflict: many high-entropy tokens are logical connectors that receive larger gradients and are encouraged under the performance objective, while the compression objective simultaneously penalizes these potentially redundant connectors. This opposing pressure creates a direct source of entropy conflict. To address these issues, we adopt an entropy-guided training framework. As entropy descends, the model is guided toward efficient reasoning by encouraging concise thought steps; as entropy rises, exploration is reinforced under the compact reasoning mode to improve robustness. Experiments on six mathematical benchmarks show that our method compresses reasoning length to 20% of the original while maintaining or even surpassing baseline accuracy. Code and models will be released publicly.",
    "title_zh": "熵引导的推理压缩",
    "abstract_zh": "大型推理模型在复杂推理任务上展现了卓越的性能，但其思维链（chain-of-thought）输出过长仍是制约实际应用的主要瓶颈，原因在于高昂的计算成本和较差的部署可行性。现有的压缩方法虽取得部分成功，却忽视了训练过程中一个关键现象——熵冲突。在压缩训练中，熵值下降，导致推理路径变短，但探索能力受限；而以准确率为导向的目标则会提升熵值，延长推理链条。这种矛盾使得模型容易陷入局部困境。我们的分析进一步揭示了熵冲突的根源：许多高熵的词元是逻辑连接词，它们因接收更大的梯度而在性能目标下被鼓励保留，然而压缩目标却同时惩罚这些可能冗余的连接词。这种相互抵消的约束力构成了熵冲突的直接来源。为解决上述问题，我们提出一种基于熵引导的训练框架：当熵值下降时，模型通过鼓励简洁的思维步骤，被引导向高效推理；当熵值上升时，则在紧凑推理模式下强化探索能力，以提升鲁棒性。在六个数学基准上的实验表明，我们的方法可将推理长度压缩至原始长度的20%，同时保持甚至超越基线模型的准确率。代码与模型将公开发布。"
  },
  {
    "date": "2025-11-18",
    "title": "From Topology to Behavioral Semantics: Enhancing BGP Security by Understanding BGP's Language with LLMs",
    "authors": "Heng Zhao, Ruoyu Wang, Tianhang Zheng, Qi Li, Bo Lv, Yuyi Wang, Wenliang Du",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14467v1",
    "source": "arXiv",
    "abstract": "The trust-based nature of Border Gateway Protocol (BGP) makes it vulnerable to disruptions like prefix hijacking and misconfigurations, threatening routing stability. Traditional detection relies on manual inspection with limited scalability. Machine/Deep Learning (M/DL) approaches automate detection but suffer from suboptimal precision, limited generalizability, and high retraining costs. This is because existing methods focus on topological structures rather than comprehensive semantic characteristics of Autonomous Systems (ASes), often misinterpreting functionally similar but topologically distant ASes. To address this, we propose BGPShield, an anomaly detection framework built on LLM embeddings that captures the Behavior Portrait and Routing Policy Rationale of each AS beyond topology, such as operational scale and global role. We propose a segment-wise aggregation scheme to transform AS descriptions into LLM representations without information loss, and a lightweight contrastive reduction network to compress them into a semantic-consistent version. Using these representations, our AR-DTW algorithm aligns and accumulates semantic distances to reveal behavioral inconsistencies. Evaluated on 16 real-world datasets, BGPShield detects 100% of verified anomalies with a false discovery rate below 5%. Notably, the employed LLMs were released prior to evaluation events, verifying generalizability. Furthermore, BGPShield constructs representations for unseen ASes within one second, significantly outperforming BEAM which demands costly retraining (averaging 65 hours).",
    "title_zh": "从拓扑到行为语义：通过大语言模型理解BGP语言以增强BGP安全性",
    "abstract_zh": "边界网关协议（BGP）基于信任的特性使其容易受到前缀劫持和配置错误等干扰，威胁路由系统的稳定性。传统的检测方法依赖人工审查，可扩展性有限。而机器/深度学习（M/DL）方法虽能实现自动化检测，却存在精度不理想、泛化能力弱以及重训练成本高等问题。其根源在于现有方法主要关注自治系统（AS）的拓扑结构，而忽视了AS的全面语义特征，常将功能相似但拓扑上相距甚远的AS误判为同类。针对这一问题，我们提出BGPShield——一种基于大语言模型（LLM）嵌入的异常检测框架，能够捕捉每个AS的行为画像与路由策略逻辑，超越传统拓扑视角，涵盖运营规模、全球角色等语义维度。我们设计了一种分段聚合方案，将AS描述无损转换为LLM表示，并引入轻量级对比压缩网络，将其压缩为语义一致的紧凑表达。基于这些表示，我们的AR-DTW算法通过对齐并累积语义距离，揭示行为不一致性。在16个真实世界数据集上的评估表明，BGPShield实现了100%的已验证异常检出率，且误报率低于5%。尤为关键的是，所使用的LLM均在评估事件发生前发布，充分验证了方法的泛化能力。此外，BGPShield可在一秒内为未见AS构建表征，显著优于BEAM方法（平均需耗时65小时进行昂贵的重训练）。"
  },
  {
    "date": "2025-11-18",
    "title": "Watchdogs and Oracles: Runtime Verification Meets Large Language Models for Autonomous Systems",
    "authors": "Angelo Ferrando",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14435v1",
    "source": "arXiv",
    "abstract": "Assuring the safety and trustworthiness of autonomous systems is particularly difficult when learning-enabled components and open environments are involved. Formal methods provide strong guarantees but depend on complete models and static assumptions. Runtime verification (RV) complements them by monitoring executions at run time and, in its predictive variants, by anticipating potential violations. Large language models (LLMs), meanwhile, excel at translating natural language into formal artefacts and recognising patterns in data, yet they remain error-prone and lack formal guarantees. This vision paper argues for a symbiotic integration of RV and LLMs. RV can serve as a guardrail for LLM-driven autonomy, while LLMs can extend RV by assisting specification capture, supporting anticipatory reasoning, and helping to handle uncertainty. We outline how this mutual reinforcement differs from existing surveys and roadmaps, discuss challenges and certification implications, and identify future research directions towards dependable autonomy.",
    "title_zh": "看门狗与先知：运行时验证结合大语言模型用于自主系统",
    "abstract_zh": "在涉及学习型组件和开放环境的情况下，确保自主系统的安全性和可信性尤为困难。形式化方法虽能提供强有力的保障，但依赖于完整的模型和静态假设。运行时验证（Runtime Verification, RV）则通过在运行时监控系统执行过程来弥补这一不足，其预测性变体还能提前预判潜在的违规行为。与此同时，大语言模型（LLMs）在将自然语言转化为形式化产物以及识别数据模式方面表现出色，但仍然存在易出错的问题，且缺乏形式化保证。本文提出一种协同融合RV与LLMs的愿景：RV可作为LLM驱动自主性的“安全护栏”，而LLMs则可通过辅助规范捕获、支持前瞻推理以及处理不确定性，拓展RV的能力。我们阐述了这种相互增强机制与现有综述和路线图的本质区别，探讨了面临的挑战及其对认证的影响，并指明了迈向可靠自主性的未来研究方向。"
  },
  {
    "date": "2025-11-18",
    "title": "Strategic Innovation Management in the Age of Large Language Models Market Intelligence, Adaptive R&D, and Ethical Governance",
    "authors": "Raha Aghaei, Ali A. Kiaei, Mahnaz Boush, Mahan Rofoosheh, Mohammad Zavvar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14709v1",
    "source": "arXiv",
    "abstract": "This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market for breakthrough ideas.",
    "title_zh": "大语言模型时代的战略创新管理：市场洞察、适应性研发与伦理治理",
    "abstract_zh": "本研究分析了大型语言模型（LLMs）在变革研发（R&D）流程中所发挥的多重功能。通过自动化知识发现、促进假设生成、整合跨学科洞见，以及推动创新生态系统内的协作，LLMs 显著提升了研究工作的效率与成效。通过对科学文献、专利数据库和实验数据的广泛分析，这些模型使研发流程更加灵活且更具信息支撑，最终加速创新周期，缩短突破性理念推向市场的时间。"
  },
  {
    "date": "2025-11-18",
    "title": "When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling",
    "authors": "Alessio Pellegrino, Jacopo Mauro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14334v1",
    "source": "arXiv",
    "abstract": "One of the long-standing goals in optimisation and constraint programming is to describe a problem in natural language and automatically obtain an executable, efficient model. Large language models appear to bring this vision closer, showing impressive results in automatically generating models for classical benchmarks. However, much of this apparent success may derive from data contamination rather than genuine reasoning: many standard CP problems are likely included in the training data of these models. To examine this hypothesis, we systematically rephrased and perturbed a set of well-known CSPLib problems to preserve their structure while modifying their context and introducing misleading elements. We then compared the models produced by three representative LLMs across original and modified descriptions. Our qualitative analysis shows that while LLMs can produce syntactically valid and semantically plausible models, their performance drops sharply under contextual and linguistic variation, revealing shallow understanding and sensitivity to wording.",
    "title_zh": "词语改变模型：大语言模型在约束编程建模中的敏感性",
    "abstract_zh": "在优化和约束编程领域，一个长期的目标是能够用自然语言描述问题，并自动生成可执行且高效的模型。大型语言模型似乎使这一愿景更接近现实，它们在自动为经典基准问题生成模型方面表现出色。然而，这种看似成功的结果可能更多源于数据污染而非真正的推理能力：这些模型的训练数据中很可能包含了大量标准的约束编程问题。为了检验这一假设，我们系统地重新表述并扰动了一组著名的CSPLib问题，在保持其结构不变的同时，改变其背景语境并引入误导性元素。随后，我们将三种代表性大语言模型在原始描述和修改后描述下生成的模型进行了对比。定性分析表明，尽管大语言模型能够生成语法正确、语义合理的模型，但当面临上下文或语言表达的变化时，其性能急剧下降，暴露出对问题理解浅显、对措辞高度敏感的问题。"
  },
  {
    "date": "2025-11-18",
    "title": "DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning",
    "authors": "Xiaochuan Liu, Yuanfeng Song, Xiaoming Yin, Xing Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14299v1",
    "source": "arXiv",
    "abstract": "In today's data-driven era, fully automated end-to-end data analytics, particularly insight discovery, is critical for discovering actionable insights that assist organizations in making effective decisions. With the rapid advancement of large language models (LLMs), LLM-driven agents have emerged as a promising paradigm for automating data analysis and insight discovery. However, existing data insight agents remain limited in several key aspects, often failing to deliver satisfactory results due to: (1) insufficient utilization of domain knowledge, (2) shallow analytical depth, and (3) error-prone code generation during insight generation. To address these issues, we propose DataSage, a novel multi-agent framework that incorporates three innovative features including external knowledge retrieval to enrich the analytical context, a multi-role debating mechanism to simulate diverse analytical perspectives and deepen analytical depth, and multi-path reasoning to improve the accuracy of the generated code and insights. Extensive experiments on InsightBench demonstrate that DataSage consistently outperforms existing data insight agents across all difficulty levels, offering an effective solution for automated data insight discovery.",
    "title_zh": "DataSage：基于外部知识检索、多角色辩论与多路径推理的多智能体协作洞察发现",
    "abstract_zh": "在当今数据驱动的时代，实现端到端的全自动数据分析，尤其是洞察发现，对于帮助组织挖掘可操作的见解、做出有效决策至关重要。随着大语言模型（LLMs）的快速发展，基于LLM的智能代理已成为自动化数据处理与洞察发现的一种极具前景的新范式。然而，现有的数据洞察代理在多个关键方面仍存在局限，常常因以下原因导致效果不理想：（1）领域知识利用不足，（2）分析深度有限，以及（3）生成洞察时代码错误频发。为解决这些问题，我们提出了DataSage——一种新颖的多智能体框架，包含三项创新特性：引入外部知识检索以丰富分析上下文，采用多角色辩论机制模拟多样化的分析视角并深化分析深度，以及通过多路径推理提升生成代码和洞察的准确性。在InsightBench上的大量实验表明，DataSage在所有难度级别上均持续优于现有数据洞察代理，为自动化数据洞察发现提供了一种高效可行的解决方案。"
  },
  {
    "date": "2025-11-18",
    "title": "Chipmink: Efficient Delta Identification for Massive Object Graph",
    "authors": "Supawit Chockchowwat, Sumay Thakurdesai, Zhaoheng Li, Matthew Krafczyk, Yongjoo Park",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.14162v1",
    "source": "arXiv",
    "abstract": "Ranging from batch scripts to computational notebooks, modern data science tools rely on massive and evolving object graphs that represent structured data, models, plots, and more. Persisting these objects is critical, not only to enhance system robustness against unexpected failures but also to support continuous, non-linear data exploration via versioning. Existing object persistence mechanisms (e.g., Pickle, Dill) rely on complete snapshotting, often redundantly storing unchanged objects during execution and exploration, resulting in significant inefficiency in both time and storage. Unlike DBMSs, data science systems lack centralized buffer managers that track dirty objects. Worse, object states span various locations such as memory heaps, shared memory, GPUs, and remote machines, making dirty object identification fundamentally more challenging. In this work, we propose a graph-based object store, named Chipmink, that acts like the centralized buffer manager. Unlike static pages in DBMSs, persistence units in Chipmink are dynamically induced by partitioning objects into appropriate subgroups (called pods), minimizing expected persistence costs based on object sizes and reference structure. These pods effectively isolate dirty objects, enabling efficient partial persistence. Our experiments show that Chipmink is general, supporting libraries that rely on shared memory, GPUs, and remote objects. Moreover, Chipmink achieves up to 36.5x smaller storage sizes and 12.4x faster persistence than the best baselines in real-world notebooks and scripts.",
    "title_zh": "松鼠：面向大规模对象图的高效增量识别",
    "abstract_zh": "从批处理脚本到计算笔记本，现代数据科学工具依赖于庞大且不断演化的对象图，这些对象图代表了结构化数据、模型、图表等多种内容。持久化这些对象至关重要，不仅有助于提升系统在意外故障下的鲁棒性，还能通过版本控制支持连续的、非线性的数据探索。现有的对象持久化机制（如 Pickle、Dill）依赖于完整的快照保存，常常在执行和探索过程中重复存储未发生变化的对象，导致时间和存储资源上的显著浪费。与数据库管理系统（DBMS）不同，数据科学系统缺乏集中式的缓冲区管理器来追踪“脏”对象。更糟糕的是，对象状态分布在内存堆、共享内存、GPU 以及远程机器等多个位置，使得识别“脏”对象变得尤为困难。本文提出一种基于图的对象存储系统——Chipmink，其作用类似于集中式缓冲区管理器。不同于 DBMS 中静态的页面划分，Chipmink 的持久化单元是动态生成的，通过将对象划分为合适的子组（称为“Pod”），依据对象大小和引用结构最小化预期的持久化成本。这些 Pod 有效隔离了“脏”对象，从而实现高效的局部持久化。实验结果表明，Chipmink 具有良好的通用性，能够支持依赖共享内存、GPU 和远程对象的各类库。此外，在真实世界中的笔记本和脚本中，Chipmink 的存储空间比最佳基线小最多达 36.5 倍，持久化速度最快可达基线的 12.4 倍。"
  },
  {
    "date": "2025-11-18",
    "title": "Browser-Embedded, Legal-Aware Cybersecurity Co-Pilot for Myanmar with RAG, Multilingual Defense and Privacy",
    "authors": "Htet Myet Zaw, Hpone Khant Naing, Aung Kaung Myat, Htet Paing Linn, Thurein Lin, Thiri Thitsar Khaing",
    "publish": "2025 6th International Conference on Advanced Information Technologies (ICAIT)",
    "url": "https://doi.org/10.1109/icait68809.2025.11236800",
    "source": "IEEE",
    "abstract": "We present Konbaung AI, a multilingual, privacy-preserving browser extension that integrates real-time cyber defense with contextual legal awareness for Myanmar’s digital citizens. The system combines an Ollama-compatible large language model with Retrieval-Augmented Generation (RAG) over Myanmar Cyber Law and global privacy and security frameworks, while incorporating natural language– based phishing detection, URL heuristics, cryptographic file hashing with malware verification, and breach exposure analysis. A privacy-by-default design ensures local inference, minimal external dependencies, and the absence of remote user data storage. We formalize a threat model for browser-resident AI and propose a modular architecture that couples lightweight client processing with secure backend services. Experimental evaluation across detection accuracy, response latency, and user interaction indicates phishing and spam classification, close alignment with established malware verdicts, effective legal and privacy policy summarization in Burmese, and sustained engagement through adaptive gamification. Remaining challenges include dialectal speech processing and limited domain-specific datasets, offline-capable mechanisms, and broader cross-platform deployment.",
    "title_zh": "嵌入浏览器、具备法律意识的缅甸网络安全协同助手，支持RAG、多语言防护与隐私保护",
    "abstract_zh": "我们提出Konbaung AI，这是一款多语言、注重隐私保护的浏览器扩展程序，专为缅甸数字公民设计，集实时网络防御与情境化法律意识于一体。该系统结合了兼容Ollama的大语言模型，并基于缅甸网络安全法及全球隐私与安全框架进行检索增强生成（RAG），同时集成基于自然语言的钓鱼攻击检测、URL启发式分析、加密文件哈希与恶意软件验证，以及数据泄露风险评估功能。采用默认隐私保护设计，确保本地推理、极少依赖外部服务，且不存储用户远程数据。我们为浏览器内嵌AI构建了形式化威胁模型，并提出一种模块化架构，将轻量级客户端处理与安全后端服务相结合。实验评估表明，在检测准确率、响应延迟和用户交互方面，系统在识别钓鱼与垃圾信息、与权威恶意软件判定高度一致、以缅甸语有效总结法律与隐私政策，以及通过自适应游戏化机制维持用户持续参与等方面表现优异。当前仍面临若干挑战：方言语音处理能力有限、领域特定数据集不足、离线可用机制欠缺，以及跨平台部署范围较窄等问题。"
  },
  {
    "date": "2025-11-18",
    "title": "Instruction Frequency-Based ALU Simplification on RISC-V for TinyML",
    "authors": "Yosuke Asai, Wai Leong Pang, Hui Hwang Goh",
    "publish": "2025 9th International Conference on Recent Advances and Innovations in Engineering (ICRAIE)",
    "url": "https://doi.org/10.1109/icraie65839.2025.11239153",
    "source": "IEEE",
    "abstract": "TinyML has gained significant attention for enabling machine learning inference on edge devices with limited resources. In such contexts, minimizing power consumption and chip area is critical. This study focuses on optimizing the Arithmetic Logic Unit (ALU) in RISC-V, leveraging its open-source and highly modular architecture. An analysis of the impact of instruction usage frequency guides the optimization. An extensive simulation was carried out. A sine wave prediction model was trained and implemented on an RISC-V system using a C program. Instruction usage was profiled using the Spike simulator. The design was synthesized and evaluated on an Xilinx Artix-7 FPGA using Vivado, resulting in a 27% reduction in Look-Up Table (LUT) usage and a 13% reduction in static power. These results highlight the potential of application-driven optimization through instruction profiling in enhancing RISC-V architectures for TinyML applications.",
    "title_zh": "基于指令频率的RISC-V小型化机器学习ALU简化",
    "abstract_zh": "TinyML因其能够在资源受限的边缘设备上实现机器学习推理而受到广泛关注。在这一背景下，降低功耗和芯片面积至关重要。本研究聚焦于优化RISC-V架构中的算术逻辑单元（ALU），充分利用其开源且高度模块化的特点。通过分析指令使用频率的影响，指导优化方向。研究进行了大量仿真：训练并实现了一个正弦波预测模型，该模型基于C语言程序部署在RISC-V系统上，并利用Spike模拟器对指令使用情况进行性能剖析。设计随后在Xilinx Artix-7 FPGA上通过Vivado工具进行综合与评估，最终实现了查找表（LUT）使用量减少27%，静态功耗降低13%。这些结果表明，通过指令使用情况的分析驱动优化，能够有效提升RISC-V架构在TinyML应用中的性能表现。"
  },
  {
    "date": "2025-11-18",
    "title": "Towards Novel Gesture Recognition for Real-Time Code Generation in Extended Reality",
    "authors": "Clare E. Heinbaugh, Per Ola Kristensson",
    "publish": "2025 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)",
    "url": "https://doi.org/10.1109/ismar-adjunct68609.2025.00068",
    "source": "IEEE",
    "abstract": "Advances in code generation using large language models (LLMs) enable novel virtual reality (VR) interactions defined at runtime [4]. Further, gestures allow users to express intent in VR, often with a metaphoric correspondence to a real-life object or action [16], [14]. In this paper, we propose a system that allows users to define novel gestures with metaphoric significance to inform real-time code generation in extended reality. The system enables the articulation of novel gestures to trigger novel interactions on-the-fly. Such a system can potentially enable more flexible experiences for users as the system can provide appropriate gesture interaction tools for specific contexts of use. However, to fully realize this vision requires tackling three challenges: (1) online gesture recognition; (2) the tradeoff between scene context and creative ambiguity; and (3) limitations of LLMs.",
    "title_zh": "面向扩展现实中的实时代码生成的新手势识别",
    "abstract_zh": "利用大型语言模型（LLMs）在代码生成方面的进展，使得在运行时动态定义新型虚拟现实（VR）交互成为可能[4]。此外，手势使用户能够在VR中表达意图，通常与现实生活中的物体或动作存在隐喻性对应关系[16]、[14]。本文提出了一种系统，允许用户定义具有隐喻意义的新手势，以指导扩展现实环境中的实时代码生成。该系统能够通过表达新颖的手势来即时触发新的交互行为。这种系统有望为用户提供更灵活的体验，因为系统可以根据具体使用场景提供相应的手势交互工具。然而，要完全实现这一愿景，仍需解决三个关键挑战：（1）在线手势识别；（2）场景上下文与创造性的模糊性之间的权衡；以及（3）大型语言模型自身的局限性。"
  },
  {
    "date": "2025-11-18",
    "title": "Automated IC Footprint Recognition and Classification Using Deep Learning and Dimensional Similarity Metrics",
    "authors": "Tushar Shrivastava",
    "publish": "2025 International Conference on Intelligent Communication Networks and Computational Techniques (ICICNCT)",
    "url": "https://doi.org/10.1109/icicnct66124.2025.11233194",
    "source": "IEEE",
    "abstract": "Accurate mapping of integrated-circuit (IC) footprints to PCB layouts is time-consuming and error-prone in highdensity manufacturing. We present an automated pipeline combining tolerance-aware dimensional similarity metrics with an ensemble of fine-tuned convolutional neural networks (ResNet-50, EfficientNet-B3) and a recommendation engine implemented in Python-SQLite3-Qt. The system normalizes datasheet parameters, applies candidate filtering, computes weighted similarity scores, and fuses visual classification probabilities into a single ranking score. On a curated dataset of <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{4, 5 0 0}$</tex> images spanning 12 package types, our optimized pipeline attains 95.0 % test accuracy with 0.15 s average inference latency. Ablation studies show the benefit of weighted dimensional prioritization and transfer learning. The approach is practical for inline designassist and pick-and-place recommendation, reducing manual footprint lookup and improving placement accuracy.",
    "title_zh": "基于深度学习与维度相似性度量的自动化集成电路封装识别与分类",
    "abstract_zh": "在高密度制造中，将集成电路（IC）封装图精确映射到印刷电路板（PCB）布局是一项耗时且易出错的任务。本文提出了一种自动化流程，该流程结合了具有容差意识的尺寸相似性度量方法，以及一组经过微调的卷积神经网络（ResNet-50、EfficientNet-B3），并采用 Python-SQLite3-Qt 实现推荐引擎。系统首先对数据手册参数进行归一化处理，随后应用候选筛选机制，计算加权相似性得分，并将视觉分类概率融合为单一排序分数。在包含4,500张图像、覆盖12种封装类型的精选数据集上，优化后的管道实现了95.0%的测试准确率，平均推理延迟仅为0.15秒。消融实验表明，加权尺寸优先级和迁移学习均显著提升了性能。该方法适用于在线设计辅助与贴片放置推荐，可减少人工查找封装图的工作量，同时提高元件布局的准确性。"
  },
  {
    "date": "2025-11-18",
    "title": "Retrieval-Augmented Generation: A Comprehensive Survey of Foundations, Evolution, Applications, Limitations, and Future Directions",
    "authors": "Junzhe Feng, MohammadMahdi Ariannejad, Intan Izafina Idrus, Zhe Kai Goh, Jian Ding Tan, Chia Chao Kang, Mohammad Arif Sobhan Byuiyan, Wei Hown Tee",
    "publish": "2025 9th International Conference on Recent Advances and Innovations in Engineering (ICRAIE)",
    "url": "https://doi.org/10.1109/icraie65839.2025.11239329",
    "source": "IEEE",
    "abstract": "Retrieval-augmented generation (RAG) is one of the best methods for performing language tasks these days. RAG uses large language models with external tools for better accuracy, correctness, and contextual understanding. The review discusses key concepts in RAG, how RAG differs from previous systems that retrieved or generated content, how RAG is utilized in question answering, knowledge management, and content generation, and it discusses some limitations, including quality of retrieval, requirement for high-performance computers, complicated integration, as well as data privacy problems, and presents new approaches to address these limitations. The review examines over a quarter-century of key recent studies and concludes with some future research areas, such as multimodal RAG, novel methods for retrieval, personalization, ethics, explanability, as well as incorporating human feedback. The review seeks to make the reader understand RAG's current state as well as future research areas through intensive discussion as well as lucid examples.",
    "title_zh": "检索增强生成：基础、演进、应用、局限与未来方向的全面综述",
    "abstract_zh": "检索增强生成（RAG）是当前执行语言任务的最佳方法之一。RAG通过结合大型语言模型与外部工具，提升了准确性、正确性以及上下文理解能力。本文综述了RAG的核心概念，阐述了RAG与以往仅依赖检索或生成内容的系统之间的区别；探讨了RAG在问答系统、知识管理及内容生成中的应用；同时指出了其存在的若干局限性，包括检索质量不足、对高性能计算设备的需求、集成复杂性以及数据隐私问题，并介绍了针对这些问题的新解决方案。该综述回顾了过去二十五年来的关键研究进展，最后展望了未来的研究方向，如多模态RAG、新型检索方法、个性化、伦理问题、可解释性，以及融入人类反馈等。通过深入的讨论和清晰的实例，本文旨在帮助读者全面理解RAG的当前发展状况及其未来研究前景。"
  },
  {
    "date": "2025-11-18",
    "title": "ShadAR: LLM-driven shader generation to transform visual perception in Augmented Reality",
    "authors": "Yanni Mei, Samuel Wendt, Florian Müller, Jan Gugenheimer",
    "publish": "2025 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)",
    "url": "https://doi.org/10.1109/ismar-adjunct68609.2025.00267",
    "source": "IEEE",
    "abstract": "Augmented Reality (AR) can simulate various visual perceptions, such as how individuals with colorblindness see the world. However, these simulations require developers to predefine each visual effect, limiting flexibility. We present ShadAR, an AR application enabling real-time transformation of visual perception through shader generation using large language models (LLMs). ShadAR allows users to express their visual intent via natural language, which is interpreted by an LLM to generate corresponding shader code. This shader is then compiled real-time to modify the AR headset’s viewport. We present our LLM-driven shader generation pipeline and demonstrate its ability to transform visual perception for inclusiveness and creativity.",
    "title_zh": "ShadAR：由大语言模型驱动的着色器生成，以改变增强现实中的视觉感知",
    "abstract_zh": "增强现实（AR）能够模拟各种视觉感知效果，例如色盲人士眼中的世界。然而，这些模拟通常需要开发者预先定义每种视觉效果，限制了灵活性。我们提出了ShadAR——一款基于增强现实的应用程序，通过大型语言模型（LLMs）生成着色器，实现实时的视觉感知转换。ShadAR允许用户通过自然语言表达其视觉意图，由大语言模型解析并生成相应的着色器代码，随后实时编译并应用于AR头显的视口，实现动态视觉调整。本文介绍了我们基于大语言模型的着色器生成流程，并展示了该系统在促进视觉包容性与激发创造力方面的应用潜力。"
  },
  {
    "date": "2025-11-18",
    "title": "A Model-Based Design Approach Towards Software-Defined Vehicles with Service-Oriented Architecture",
    "authors": "Tanuku SaiLakshmi Madhuri, Bala Vishnu J, Prasad Patil",
    "publish": "2025 3rd International Conference on Recent Advances in Information Technology for Sustainable Development (ICRAIS)",
    "url": "https://doi.org/10.1109/icrais66073.2025.11234710",
    "source": "IEEE",
    "abstract": "The advent of Software-Defined Vehicles (SDVs) requires flexibility, scalability, and upgradability in advanced architectures.Traditional signal-based systems are tightly coupled to monolithic architectures, which limit adaptability and modular expansion. The paper proposes a change in architecture from monolithic to Service-Oriented Architecture (SOA) by ModelBased Design (MBD) and Adaptive AUTOSAR. The shift involves moving from signal-based to event-driven communication, enabling better modularization and integration. The modeling and code generation in an MBD environment and then an executable was obtained and exported onto a Linux-based system on the Raspberry Pi and QEMU for validation. The AEB (Autonomous Emergency Braking) model was considered to demonstrate this transition. Performance metrics, including latency, CPU usage, and service discovery time, were measured on both platforms to validate real-time suitability.",
    "title_zh": "基于模型的设计方法在面向服务架构的软件定义汽车中的应用",
    "abstract_zh": "软件定义汽车（SDV）的出现对先进架构的灵活性、可扩展性和可升级性提出了更高要求。传统的基于信号的系统与单体式架构紧密耦合，限制了系统的适应能力及模块化扩展。本文提出通过基于模型的设计（MBD）和自适应AUTOSAR，将架构从单体式转变为面向服务的架构（SOA），实现通信方式从基于信号向事件驱动的转变，从而提升系统的模块化程度与集成能力。在MBD环境中完成建模与代码生成后，生成可执行程序并部署至基于Linux的树莓派（Raspberry Pi）和QEMU平台进行验证。以自动紧急制动（AEB）模型为例，展示了这一转型过程。在两个平台上测量了包括延迟、CPU使用率和服务发现时间在内的性能指标，以验证其在实时应用中的适用性。"
  },
  {
    "date": "2025-11-18",
    "title": "Lifelong Learning in Software Engineering: Towards an AI-driven Tutor for Cloud-Based Software Architectures",
    "authors": "Marcel Mitas, Sabine Sachweh",
    "publish": "2025 IEEE European Technology and Engineering Management Summit (E-TEMS)",
    "url": "https://doi.org/10.1109/e-tems64751.2025.11239087",
    "source": "IEEE",
    "abstract": "The emerging of large language models (LLM’s) like ChatGPT helped to utilize artificial intelligence (AI) to understand basic concepts of programming in university courses, but also to automate and assist in repetitive procedures in the software engineering process. However, existing approaches to learn the skills and best practices to create software architectures and the underlying domain models with the help of AI expect a certain level of experience in software engineering. Besides, current approaches to configure LLMs with prompt engineering to answer as an AI tutor rather assist students in learning basic programming skills in university courses than in software architecture design. In this paper, a four-step-approach is proposed to prompt LLMs, namely ChatGPT-4o and Llama 3.1, to act like a tutor and help novices in software engineering build their own software architectures, apply best practices and understand them. To do this, the LLMs receive initial prompts with the assignment of a tutor role, and descriptions of the target group, system’s requirements and context. Then, example questions, domain models, and software architectures will be sent to the LLMs and evaluated if the answers relate to the models and requirements and comply with the initial prompt. Tests with the MobSTr dataset showed overall suitability of these LLMs for tutoring in software design, but also limitations regarding some general answers and the processing speed of local built LLMs.",
    "title_zh": "软件工程中的终身学习：面向基于云的软件架构的AI驱动导师",
    "abstract_zh": "像ChatGPT这样的大型语言模型（LLM）的出现，帮助将人工智能（AI）应用于大学课程中理解编程的基本概念，同时也实现了软件工程过程中重复性任务的自动化与辅助。然而，现有借助AI学习软件架构设计及底层领域建模技能与最佳实践的方法，通常要求用户具备一定的软件工程经验。此外，当前通过提示工程（prompt engineering）配置LLM以扮演AI导师角色的做法，更多是协助学生掌握大学课程中的基础编程技能，而非专注于软件架构设计的学习。\n\n本文提出了一种四步法，用于引导大型语言模型（如ChatGPT-4o和Llama 3.1）扮演导师角色，帮助软件工程初学者自主构建软件架构、应用最佳实践并深入理解其原理。具体而言，这些LLM首先接收包含导师角色设定、目标学习群体描述、系统需求与上下文信息的初始提示。随后，向LLM提供示例问题、领域模型和软件架构案例，并评估其回答是否与所给模型和需求相关，且符合初始提示的要求。\n\n基于MobSTr数据集的测试表明，这些LLM在软件设计辅导方面总体上具有适用性，但也暴露出一些局限性，例如部分回答过于泛化，以及本地部署的LLM在处理速度上的不足。"
  },
  {
    "date": "2025-11-18",
    "title": "Unsafe by Design? A First Look at Security and Privacy Risks in OpenAI’s Custom GPT Ecosystem",
    "authors": "Sunday Oyinlola Ogundoyin, Muhammad Ikram, Hassan Jameel Asghar, Benjamin Zi Hao Zhao, Dali Kaafar",
    "publish": "Proceedings of the 24th Workshop on Privacy in the Electronic Society",
    "url": "https://doi.org/10.1145/3733802.3764054",
    "source": "ACM",
    "abstract": "Millions of users leverage generative pretrained transformer (GPT)-based language models developed by leading model providers for a wide range of tasks. To support enhanced user interaction and customization, many platforms–such as OpenAI–now enable developers to create and publish tailored model instances, known as custom GPTs, via dedicated repositories or application stores. These custom GPTs empower users to browse and interact with specialized applications designed to meet specific needs. However, as custom GPTs see growing adoption, concerns regarding their security vulnerabilities have intensified. Existing research on these vulnerabilities remains largely theoretical, often lacking empirical, large-scale, and statistically rigorous assessments of associated risks. In this study, we analyze 14,904 custom GPTs to assess their susceptibility to seven exploitable threats, such as roleplay-based attacks, system prompt leakage, phishing content generation, and malicious code synthesis, across various categories and popularity tiers within the OpenAI marketplace. We introduce a multi-metric ranking system to examine the relationship between a custom GPT’s popularity and its associated security risks. Our findings reveal that over 95% of custom GPTs lack adequate security protections. The most prevalent vulnerabilities include roleplay-based vulnerabilities (96.51%), system prompt leakage (92.20%), and phishing (91.22%). Furthermore, we demonstrate that OpenAI’s foundational models exhibit inherent security weaknesses, which are often inherited or amplified in custom GPTs. These results highlight the urgent need for enhanced security measures and stricter content moderation to ensure the safe deployment of GPT-based applications.",
    "title_zh": "设计上的不安全？初探OpenAI自定义GPT生态系统中的安全与隐私风险",
    "abstract_zh": "数以百万计的用户利用由领先模型提供商开发的基于生成式预训练变换器（GPT）的语言模型，完成各种任务。为了支持更丰富的用户交互和个性化定制，许多平台（如OpenAI）现已允许开发者通过专用仓库或应用商店创建并发布量身定制的模型实例，即“自定义GPT”。这些自定义GPT使用户能够浏览并使用针对特定需求设计的专业化应用。然而，随着自定义GPT的广泛应用，其安全漏洞问题日益引发关注。目前关于这些漏洞的研究仍主要停留在理论层面，往往缺乏对相关风险进行大规模、实证性且统计严谨的评估。在本研究中，我们分析了14,904个自定义GPT，评估它们在OpenAI市场中不同类别和流行度层级下对七种可被利用威胁的易受攻击程度，包括基于角色扮演的攻击、系统提示泄露、钓鱼内容生成以及恶意代码合成等。我们提出了一种多指标排名体系，用以探究自定义GPT的流行度与其安全风险之间的关系。研究发现，超过95%的自定义GPT缺乏充分的安全防护措施。最常见的漏洞包括基于角色扮演的漏洞（96.51%）、系统提示泄露（92.20%）以及钓鱼攻击（91.22%）。此外，我们还证明了OpenAI的基础模型本身存在固有的安全缺陷，这些缺陷常常在自定义GPT中被继承甚至放大。上述结果凸显了亟需加强安全防护机制和实施更严格的内容审核，以确保基于GPT的应用程序能够安全部署。"
  }
]