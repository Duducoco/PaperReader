[
  {
    "date": "2025-12-29",
    "title": "The Dawn of Agentic EDA: A Survey of Autonomous Digital Chip Design",
    "authors": "Zelin Zang, Yuhang Song, Bingo Wing-Kuen Ling, Aili Wang, Fuji Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23189v1",
    "source": "arXiv",
    "abstract": "This survey provides a comprehensive overview of the integration of Generative AI and Agentic AI within the field of Digital Electronic Design Automation (EDA). The paper first reviews the paradigmatic evolution from traditional Computer-Aided Design (CAD) to AI-assisted EDA (AI4EDA), and finally to the emerging AI-Native and Agentic design paradigms. We detail the application of these paradigms across the digital chip design flow, including the construction of agentic cognitive architectures based on multimodal foundation models, frontend RTL code generation and intelligent verification, and backend physical design featuring algorithmic innovations and tool orchestration. We validate these methodologies through integrated case studies, demonstrating practical viability from microarchitecture definition to GDSII. Special emphasis is placed on the potential for cross-stage feedback loops where agents utilize backend PPA metrics to autonomously refine frontend logic. Furthermore, this survey delves into the dual-faceted impact on security, covering novel adversarial risks, automated vulnerability repair, and privacy-preserving infrastructure. Finally, the paper critically summarizes current challenges related to hallucinations, data scarcity, and black-box tools, and outlines future trends towards L4 autonomous chip design. Ultimately, this work aims to define the emerging field of Agentic EDA and provide a strategic roadmap for the transition from AI-assisted tools to fully autonomous design engineers.",
    "title_zh": "代理EDA的曙光：自主数字芯片设计综述",
    "abstract_zh": "本综述全面概述了生成式人工智能和代理人工智能在数字电子设计自动化（EDA）领域的整合。本文首先回顾了从传统计算机辅助设计（CAD）到人工智能辅助EDA（AI4EDA），再到新兴的AI原生和代理设计范式的范式演变。我们详细介绍了这些范式在数字芯片设计流程中的应用，包括基于多模态基础模型的代理认知架构构建、前端RTL代码生成与智能验证，以及后端物理设计中的算法创新和工具编排。我们通过综合案例研究验证了这些方法，从微架构定义到GDSII，展示了其实用可行性。特别强调了代理利用后端PPA指标自主优化前端逻辑的跨阶段反馈回路的潜力。此外，本综述深入探讨了对安全性的双重影响，涵盖了新型对抗性风险、自动化漏洞修复和隐私保护基础设施。最后，本文批判性地总结了与幻觉、数据稀缺和黑箱工具相关的当前挑战，并概述了向L4自主芯片设计发展的未来趋势。最终，这项工作旨在定义新兴的代理EDA领域，并为从人工智能辅助工具向完全自主设计工程师的过渡提供战略路线图。"
  },
  {
    "date": "2025-12-30",
    "title": "Tracing the Logic: Evaluating LLM Reasoning Paths in RTL Generation",
    "authors": "Matthew DeLorenzo, Kevin Tieu, Jeyavijayan Rajendran",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00115",
    "source": "IEEE",
    "abstract": "Large reasoning models (LRMs) have recently demonstrated strong improvements in complex problem-solving by leveraging inference-time reasoning strategies. In hardware design, these approaches have been applied to Verilog generation, enabling models to produce more functional designs compared to conventional LLMs. However, while the effectiveness of reasoning-augmented models has been established, the intermediate reasoning traces themselves remain underexplored. This work presents the first systematic framework for evaluating reasoning traces in Verilog generation. We analyze state-of-the-art reasoning-trained models using a suite of text-based, semantic, and structural metrics that quantify redundancy, coherence, and alignment between reasoning tokens and final Verilog outputs. Our evaluation highlights both the advantages and inefficiencies of current reasoning approaches: while extended reasoning can support functional correctness, it often introduces significant redundancy and inference overhead. These findings point toward the need for more concise, purposeful reasoning strategies. By characterizing the quality of reasoning traces, this work provides new insights and directions for optimizing reasoning structures in LLM-assisted hardware design.",
    "title_zh": "追踪逻辑：评估RTL生成中的LLM推理路径",
    "abstract_zh": "大型推理模型（LRM）最近通过利用推理时的策略在复杂问题解决方面展示了显著的改进。在硬件设计中，这些方法已被应用于Verilog生成，使模型能够比传统的LLM生成更具功能性的设计。然而，尽管增强推理的模型的有效性已被确立，但中间的推理轨迹本身仍未被充分探索。本文提出了第一个系统框架，用于评估Verilog生成中的推理轨迹。我们使用一套基于文本、语义和结构的指标来分析最先进的推理训练模型，这些指标量化了推理标记与最终Verilog输出之间的冗余性、一致性和对齐性。我们的评估突出了当前推理方法的优点和低效之处：尽管扩展推理可以支持功能正确性，但它往往引入显著的冗余和推理开销。这些发现表明需要更简洁、有目的的推理策略。通过表征推理轨迹的质量，本文为优化LLM辅助硬件设计中的推理结构提供了新的见解和方向。"
  },
  {
    "date": "2025-12-30",
    "title": "CircuitGuard: Mitigating LLM Memorization in RTL Code Generation Against IP Leakage",
    "authors": "Nowfel Mashnoor, Mohammad Akyash, Hadi Kamali, Kimia Azar",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00117",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in generative tasks, including register-transfer level (RTL) hardware synthesis. However, their tendency to memorize training data poses critical risks when proprietary or security-sensitive designs are unintentionally exposed during inference. While prior work has examined memorization in natural language, RTL introduces unique challenges: In RTL, structurally different implementations (e.g., behavioral vs. gatelevel descriptions) can realize the same hardware, leading to intellectual property (IP) leakage (full or partial) even without verbatim overlap. Conversely, even small syntactic variations (e.g., operator precedence or blocking vs. non-blocking assignments) can drastically alter circuit behavior, making correctness preservation especially challenging. In this work, we systematically study memorization in RTL code generation and propose CircuitGuard, a defense strategy that balances leakage reduction with correctness preservation. CircuitGuard (i) introduces a novel RTL-aware similarity metric that captures both structural and functional equivalence beyond surface-level overlap, and (ii) develops an activation-level steering method that identifies and attenuates transformer components most responsible for memorization. Our empirical evaluation demonstrates that CircuitGuard identifies (and isolates) 275 memorization-critical features across layers 18-28 of Llama 3.1-8B model, achieving up to 80% reduction in semantic similarity to proprietary patterns while maintaining generation quality. CircuitGuard further shows 78-85% crossdomain transfer effectiveness, enabling robust memorization mitigation across circuit categories without retraining. <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup><sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>Code is available at https://github.com/mashnoor/circuitguard.",
    "title_zh": "CircuitGuard：在RTL代码生成中缓解LLM记忆以防止IP泄漏",
    "abstract_zh": "大型语言模型（LLMs）在生成任务中取得了显著成功，包括寄存器传输级（RTL）硬件综合。然而，它们倾向于记忆训练数据，这在推理过程中无意中暴露专有或安全敏感设计时会带来严重风险。尽管先前的研究已经考察了自然语言中的记忆现象，但RTL引入了独特的挑战：在RTL中，结构上不同的实现（例如，行为描述与门级描述）可以实现相同的硬件，即使没有逐字重叠也可能导致知识产权（IP）泄漏（全部或部分）。相反，即使是小的语法变化（例如，运算符优先级或阻塞与非阻塞赋值）也可能显著改变电路行为，使得正确性维护尤其具有挑战性。在这项工作中，我们系统地研究了RTL代码生成中的记忆现象，并提出了CircuitGuard，这是一种在减少泄漏与保持正确性之间取得平衡的防御策略。CircuitGuard（i）引入了一种新颖的RTL感知相似性度量，能够捕捉到超越表面重叠的结构和功能等价性，并且（ii）开发了一种激活级别的引导方法，识别并减弱对记忆最负责任的变压器组件。我们的实证评估表明，CircuitGuard在Llama 3.1-8B模型的第18-28层中识别（并隔离）了275个对记忆至关重要的特征，实现了对专有模式语义相似度的高达80%的减少，同时保持了生成质量。CircuitGuard还显示出78-85%的跨领域转移效果，能够在不重新训练的情况下实现跨电路类别的稳健记忆缓解。代码可在https://github.com/mashnoor/circuitguard获取。"
  },
  {
    "date": "2025-12-30",
    "title": "RTLBench: A Multi-Dimensional Benchmark Suite for Evaluating LLM-Generated RTL Code",
    "authors": "Zhigang Fang, Renzhi Chen, Yang Guo, Huadong Dai, Lei Wang",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00087",
    "source": "IEEE",
    "abstract": "The rapid advancement of large language models (LLMs) has enabled automated Register Transfer Level (RTL) code generation, accelerating chip design workflows. However, existing benchmarks focus mainly on syntax and functionality, overlooking critical engineering aspects such as lint compliance, readability, and coding style. To address this gap, we propose RTLBench, a benchmark suite of 160 copyright-free RTL cases sourced from textbooks and open-source projects. RTLBench features a multi-dimensional evaluation framework covering syntax, functionality, lint compliance, readability, and style consistency. To assess subjective code quality metrics, it also incorporates an LLM-as-a-judge mechanism. We evaluated 24 state-of-the-art LLMs using RTLBench, finding that while several models perform well in syntax and functionality, most fall short on engineering quality. To address this, we propose Log2BetterRTL, a log-driven feedback system that transforms EDA tool diagnostics into iterative improvement prompts. It improves syntax correctness by up to 18.13 %, boosts functional correctness by 14.38 %, reduces lint violations by up to 229, and raises clarity scores by 0.51. These results demonstrate RTLBench's effectiveness in evaluating and enhancing LLMgenerated RTL, bridging the gap between generative AI and industrial-grade hardware design. The suite and scripts are available at: https://fangzhigang32.github.io/RTLBench.",
    "title_zh": "RTLBench：用于评估LLM生成的RTL代码的多维基准套件",
    "abstract_zh": "大型语言模型（LLMs）的快速发展使得自动化的寄存器传输级（RTL）代码生成成为可能，加速了芯片设计工作流程。然而，现有的基准测试主要关注语法和功能，忽视了诸如代码检查合规性、可读性和编码风格等关键工程方面。为了解决这一差距，我们提出了RTLBench，这是一套由教科书和开源项目中获取的160个无版权限制的RTL案例组成的基准套件。RTLBench具有一个多维评估框架，涵盖语法、功能、代码检查合规性、可读性和风格一致性。为了评估主观的代码质量指标，它还引入了一个以LLM为评判的机制。我们使用RTLBench评估了24个最先进的LLM，发现尽管有几个模型在语法和功能上表现良好，但大多数在工程质量上表现不佳。为此，我们提出了Log2BetterRTL，一个将EDA工具诊断转化为迭代改进提示的日志驱动反馈系统。它将语法正确性提高了最多18.13%，功能正确性提高了14.38%，代码检查违规减少了最多229次，并将清晰度评分提高了0.51。这些结果表明，RTLBench在评估和增强LLM生成的RTL方面的有效性，弥合了生成式AI与工业级硬件设计之间的差距。该套件和脚本可在以下网址获取：https://fangzhigang32.github.io/RTLBench。"
  },
  {
    "date": "2025-12-30",
    "title": "FV-PAL: Scalable Formal Verification through Partitioning and LLM-Guided Property Generation",
    "authors": "Sudipta Paria, Aritra Dasgupta, Dinesh Reddy Ankireddy, Prabuddha Chakraborty, Swarup Bhunia",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00114",
    "source": "IEEE",
    "abstract": "The growing complexity of modern system-on-chip (SoC) designs, coupled with the integration of untrusted thirdparty Intellectual Property (IP) blocks, presents significant challenges for security verification to ensure the trust and integrity of the fabricated silicon. Traditional verification methods, such as functional simulation and Formal Property Verification (FPV), suffer from limited scalability, substantial manual effort, and often incomplete coverage. To address these issues, we propose an automated formal verification framework FV-PAL that can vastly enhance security verification at both module and submodule levels. Our approach introduces judicious design partitioning to identify submodules using structural analysis and enables targeted verification of gate-level netlists, reducing computational overhead. Leveraging Large Language Models (LLMs) and retrieval-augmented generation (RAG), the framework automatically generates non-vacuous security properties translated into SystemVerilog Assertions (SVAs) using design specifications and related documentation. FV-PAL can be integrated with the commercial EDA toolflow to perform FPV and generate coverage metrics with iterative refinement via a feedback loop if coverage falls below specified threshold. FV-PAL demonstrates significant improvements in verification efficiency and coverage based on our evaluation on open-source benchmarks, offering a scalable and efficient formal verification approach for hardware designs.",
    "title_zh": "FV-PAL：通过分区和LLM引导的属性生成实现可扩展的形式化验证",
    "abstract_zh": "现代片上系统（SoC）设计的日益复杂性，加上不可信的第三方知识产权（IP）模块的集成，为确保制造硅片的信任和完整性带来了重大的安全验证挑战。传统的验证方法，如功能仿真和形式化属性验证（FPV），在可扩展性、手动工作量和覆盖范围上存在局限性。为了解决这些问题，我们提出了一种自动化的形式化验证框架FV-PAL，可以在模块和子模块级别大幅提升安全验证。我们的方法引入了明智的设计分区，通过结构分析识别子模块，并实现门级网表的针对性验证，从而减少计算开销。利用大型语言模型（LLMs）和检索增强生成（RAG），该框架自动生成非空的安全属性，并使用设计规范和相关文档将其翻译为SystemVerilog断言（SVAs）。FV-PAL可以与商业EDA工具流程集成，执行FPV并生成覆盖率指标，如果覆盖率低于指定阈值，则通过反馈循环进行迭代优化。基于我们在开源基准上的评估，FV-PAL在验证效率和覆盖率方面表现出显著的改进，为硬件设计提供了一种可扩展且高效的形式化验证方法。"
  },
  {
    "date": "2025-12-30",
    "title": "LLM-Driven Code Generation for Neural Networks on FPGAs: Bridging Python and HLS",
    "authors": "Rupesh Raj Karn, Johann Knechtel, Ramesh Karri, Ozgur Sinanoglu",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00090",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) have transformed code generation across various fields. Here, we study the specific opportunities and challenges that LLMs present in generating hardware designs for neural networks (NNs) on fieldprogrammable gate arrays (FPGAs). We illustrate how LLMs can be utilized to achieve code optimizations essential for this task, such as parallelism, memory management, and latency reduction. Additionally, we compare the proposed specialized approach for NN code generation with others for more generalized hardware. Through a series of case studies and performance evaluations, we also contrast our results with prior state of the art.",
    "title_zh": "基于大型语言模型的FPGA神经网络代码生成：桥接Python与HLS",
    "abstract_zh": "大型语言模型（LLMs）已经在多个领域改变了代码生成的方式。在本文中，我们研究了LLMs在为现场可编程门阵列（FPGAs）上的神经网络（NNs）生成硬件设计时所带来的特定机遇和挑战。我们展示了如何利用LLMs实现此任务所需的代码优化，例如并行化、内存管理和延迟减少。此外，我们将提出的神经网络代码生成专用方法与其他更通用的硬件方法进行了比较。通过一系列案例研究和性能评估，我们还将我们的结果与之前的最新技术进行了对比。"
  },
  {
    "date": "2025-12-30",
    "title": "EEsizer: LLM-Based AI Agent for Sizing of Analog and Mixed Signal Circuit",
    "authors": "Chang Liu, Danial Chitnis",
    "publish": "IEEE Transactions on Circuits and Systems I: Regular Papers",
    "url": "https://doi.org/10.1109/tcsi.2025.3646359",
    "source": "IEEE",
    "abstract": "The design of Analog and Mixed-Signal (AMS) integrated circuits (ICs) often involves significant manual effort, especially during the transistor sizing process. While Machine Learning techniques in Electronic Design Automation (EDA) have shown promise in reducing complexity and minimizing human intervention, they still face challenges such as numerous iterations and a lack of knowledge about AMS circuit design. Recently, Large Language Models (LLMs) have demonstrated significant potential across various fields, showing a certain level of knowledge in circuit design and indicating their potential to automate the transistor sizing process. In this work, we propose EEsizer, an LLM-based AI agent that integrates large language models with circuit simulators and custom data analysis functions, enabling fully automated, closed-loop transistor sizing without relying on external knowledge. By employing prompt engineering and Chain-of-Thought reasoning, the agent iteratively explores design directions, evaluates performance, and refines solutions with minimal human intervention. We first benchmarked 8 LLMs on six basic circuits and selected three high-performing models to optimize a 20-transistor CMOS operational amplifier, targeting multiple performance metrics, including rail-to-rail operation from 180 nm to 90 nm technology nodes. Notably, OpenAI o3 successfully achieved the user-intended target at 90 nm across three different test groups, with a maximum of 20 iterations, demonstrating adaptability and robustness at advanced nodes. To assess design robustness, we manually designed a bias circuit and performed a variation analysis using Gaussian-distributed variations on transistor dimensions and threshold voltages. Overall, the results demonstrate the potential of LLMs to accelerate AMS circuit design by reducing manual effort while maintaining efficiency and adaptability across circuits, models, and technology nodes.",
    "title_zh": "EEsizer：基于大型语言模型的模拟和混合信号电路尺寸调整AI代理",
    "abstract_zh": "模拟和混合信号（AMS）集成电路（IC）的设计通常需要大量的人工努力，特别是在晶体管尺寸调整过程中。尽管电子设计自动化（EDA）中的机器学习技术在降低复杂性和减少人为干预方面显示出潜力，但它们仍面临诸如多次迭代和缺乏AMS电路设计知识等挑战。最近，大型语言模型（LLM）在各个领域展示了显著的潜力，显示出一定程度的电路设计知识，并表明其在自动化晶体管尺寸调整过程中的潜力。在这项工作中，我们提出了EEsizer，这是一种基于LLM的AI代理，它将大型语言模型与电路模拟器和自定义数据分析功能相结合，实现了无需依赖外部知识的全自动闭环晶体管尺寸调整。通过使用提示工程和链式思维推理，该代理迭代地探索设计方向，评估性能，并以最小的人为干预优化解决方案。我们首先在六个基本电路上对8个LLM进行了基准测试，并选择了三个高性能模型来优化一个20晶体管的CMOS运算放大器，目标是包括从180 nm到90 nm技术节点的轨到轨操作在内的多个性能指标。值得注意的是，OpenAI o3在三个不同的测试组中成功地在90 nm节点上实现了用户预期的目标，最多只需20次迭代，展示了在先进节点上的适应性和稳健性。为了评估设计的稳健性，我们手动设计了一个偏置电路，并使用高斯分布的晶体管尺寸和阈值电压变化进行了变化分析。总体而言，结果表明LLM在加速AMS电路设计方面具有潜力，能够在减少人工努力的同时保持跨电路、模型和技术节点的效率和适应性。"
  },
  {
    "date": "2025-12-30",
    "title": "SAGE-HLS: Syntax-Aware AST-Guided LLM for High-Level Synthesis Code Generation",
    "authors": "M Zafir Sadik Khan, Nowfel Mashnoor, Mohammad Akyash, Kimia Azar, Hadi Kamali",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00088",
    "source": "IEEE",
    "abstract": "In today's rapidly evolving field of electronic design automation (EDA), the complexity of hardware designs is increasing, necessitating more sophisticated automation solutions. High-level synthesis (HLS), as a pivotal solution, automates hardware designs from high-level abstractions (e.g., C/C++). However, it faces significant challenges, particularly in design space exploration and optimization. While large language models (LLMs) have shown notable capabilities in code generation, their application to HLS has been limited due to the scarcity of (publicly) available HLS code datasets. Hence, research in this domain has primarily focused on techniques such as prompt engineering and retrieval-augmented generation (RAG). To overcome this limitation, this paper introduces SAGE-HLS, the first-of-its-kind fine-tuned LLM specifically for HLS code generation. Our method includes three key advancements: (i) We implement Verilog-to-C/C++ porting, converting verified and synthesizable Verilog codes into corresponding C, creating a dataset of 16.7 K HLS codes; (ii) We implement a fine-tuning strategy, which is based on instruction prompting to code generation guided by abstract syntax tree (AST); (iii) We develop a semi-automated evaluation framework using VerilogEval to assess the functionality of the generated HLS code. Our experiments show that SAGE-HLS, fined-tuned on the QwenCoder (2.5) 7B model, achieves a near 100 % success rate in code synthesizability and a 75% success rate in functional correctness <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup><sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup> The code and resources related to this work are publicly available at: https://github.com/zfsadik/SAGEHLS.",
    "title_zh": "SAGE-HLS：语法感知的AST引导LLM用于高级综合代码生成",
    "abstract_zh": "在当今快速发展的电子设计自动化（EDA）领域，硬件设计的复杂性不断增加，迫切需要更复杂的自动化解决方案。高级综合（HLS）作为一个关键解决方案，从高级抽象（例如C/C++）自动化硬件设计。然而，它面临着显著的挑战，特别是在设计空间探索和优化方面。虽然大型语言模型（LLMs）在代码生成方面表现出显著能力，但由于缺乏（公开）可用的HLS代码数据集，它们在HLS中的应用受到限制。因此，该领域的研究主要集中在提示工程和检索增强生成（RAG）等技术上。为克服这一限制，本文介绍了SAGE-HLS，这是首个专门针对HLS代码生成的微调LLM。我们的方法包括三个关键进展：（i）我们实现了Verilog到C/C++的移植，将经过验证和可综合的Verilog代码转换为相应的C，创建了一个包含16.7K HLS代码的数据集；（ii）我们实施了一种微调策略，该策略基于指令提示到由抽象语法树（AST）引导的代码生成；（iii）我们开发了一个半自动化评估框架VerilogEval，用于评估生成的HLS代码的功能性。我们的实验表明，SAGE-HLS在QwenCoder（2.5）7B模型上进行微调后，在代码可综合性方面实现了接近100%的成功率，在功能正确性方面实现了75%的成功率<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup><sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>。与此工作相关的代码和资源可在以下网址公开获取：https://github.com/zfsadik/SAGEHLS。"
  }
]