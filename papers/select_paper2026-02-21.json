[
  {
    "date": "2026-02-18",
    "title": "LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation",
    "authors": "Hejia Zhang, Zhongming Yu, Chia-Tung Ho, Haoxing Ren, Brucek Khailany, Jishen Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.16953v1",
    "source": "arXiv",
    "abstract": "Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its reliance on industrial simulators and non-differentiable execution signals. We propose LLM4Cov, an offline agent-learning framework that models verification as memoryless state transitions guided by deterministic evaluators. Building on this formulation, we introduce execution-validated data curation, policy-aware agentic data synthesis, and worst-state-prioritized sampling to enable scalable learning under execution constraints. We further curate a reality-aligned benchmark adapted from an existing verification suite through a revised evaluation protocol. Using the proposed pipeline, a compact 4B-parameter model achieves 69.2% coverage pass rate under agentic evaluation, outperforming its teacher by 5.3% and demonstrating competitive performance against models an order of magnitude larger.",
    "title_zh": "LLM4Cov：面向执行的代理学习用于高覆盖率测试平台生成",
    "abstract_zh": "面向执行的LLM代理提供了一种从工具反馈中学习的有前途的范式，但这种反馈通常昂贵且获取速度慢，使得在线强化学习（RL）变得不切实际。高覆盖率硬件验证因其依赖工业模拟器和不可微分的执行信号而体现了这一挑战。我们提出了LLM4Cov，一种离线代理学习框架，将验证建模为由确定性评估器指导的无记忆状态转换。在此基础上，我们引入了执行验证的数据策划、政策感知的代理数据合成以及最差状态优先采样，以在执行约束下实现可扩展学习。我们进一步通过修订的评估协议从现有验证套件中策划了一个与现实对齐的基准。使用所提出的管道，一个紧凑的4B参数模型在代理评估下实现了69.2%的覆盖率通过率，超过其教师5.3%，并展示了与大一个数量级的模型竞争的性能。"
  }
]