[
  {
    "date": "2026-02-10",
    "title": "Perception with Guarantees: Certified Pose Estimation via Reachability Analysis",
    "authors": "Tobias Ladner, Yasser Shoukry, Matthias Althoff",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10032v1",
    "source": "arXiv",
    "abstract": "Agents in cyber-physical systems are increasingly entrusted with safety-critical tasks. Ensuring safety of these agents often requires localizing the pose for subsequent actions. Pose estimates can, e.g., be obtained from various combinations of lidar sensors, cameras, and external services such as GPS. Crucially, in safety-critical domains, a rough estimate is insufficient to formally determine safety, i.e., guaranteeing safety even in the worst-case scenario, and external services might additionally not be trustworthy. We address this problem by presenting a certified pose estimation in 3D solely from a camera image and a well-known target geometry. This is realized by formally bounding the pose, which is computed by leveraging recent results from reachability analysis and formal neural network verification. Our experiments demonstrate that our approach efficiently and accurately localizes agents in both synthetic and real-world experiments."
  },
  {
    "date": "2026-02-10",
    "title": "MEVER: Multi-Modal and Explainable Claim Verification with Graph-based Evidence Retrieval",
    "authors": "Delvin Ce Zhang, Suhan Cui, Zhelin Chu, Xianren Zhang, Dongwon Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.10023v1",
    "source": "arXiv",
    "abstract": "Verifying the truthfulness of claims usually requires joint multi-modal reasoning over both textual and visual evidence, such as analyzing both textual caption and chart image for claim verification. In addition, to make the reasoning process transparent, a textual explanation is necessary to justify the verification result. However, most claim verification works mainly focus on the reasoning over textual evidence only or ignore the explainability, resulting in inaccurate and unconvincing verification. To address this problem, we propose a novel model that jointly achieves evidence retrieval, multi-modal claim verification, and explanation generation. For evidence retrieval, we construct a two-layer multi-modal graph for claims and evidence, where we design image-to-text and text-to-image reasoning for multi-modal retrieval. For claim verification, we propose token- and evidence-level fusion to integrate claim and evidence embeddings for multi-modal verification. For explanation generation, we introduce multi-modal Fusion-in-Decoder for explainability. Finally, since almost all the datasets are in general domain, we create a scientific dataset, AIChartClaim, in AI domain to complement claim verification community. Experiments show the strength of our model."
  },
  {
    "date": "2026-02-10",
    "title": "Focus Session: LLM4PQC -- An Agentic Framework for Accurate and Efficient Synthesis of PQC Cores",
    "authors": "Buddhi Perera, Zeng Wang, Weihua Xiao, Mohammed Nabeel, Ozgur Sinanoglu, Johann Knechtel, Ramesh Karri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09919v1",
    "source": "arXiv",
    "abstract": "The design of post-quantum cryptography (PQC) hardware is a complex and hierarchical process with many challenges. A primary bottleneck is the conversion of PQC reference codes from C to high-level synthesis (HLS) specifications, which requires extensive manual refactoring [1]-[3]. Another bottleneck is the scalability of synthesis for complex PQC primitives, including number theoretic transform (NTT) accelerators and wide memory interfaces. While large language models (LLMs) have shown remarkable results for coding in general-purpose languages like Python, coding for hardware design is more challenging; feedback-driven and agentic integration are key principles of successful state-of-the-art approaches. Here, we propose LLM4PQC, an LLM-based agentic framework that refactors high-level PQC specifications and reference C codes into HLS-ready and synthesizable C code. Our framework generates and verifies the resulting RTL code. For correctness, we leverage a hierarchy of checks, covering fast C compilation and simulation as well as RTL simulation. Case studies on NIST PQC reference designs demonstrate a reduction in manual effort and accelerated design-space exploration compared to traditional flows. Overall, LLM4PQC provides a powerful and efficient pathway for synthesizing complex hardware accelerators."
  },
  {
    "date": "2026-02-10",
    "title": "Eve-positional languages: putting order into Büchi automata",
    "authors": "Olivier Idir",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09896v1",
    "source": "arXiv",
    "abstract": "An $ω$-regular language is Eve-positional if, in all games with this language as objective, the existential player can play optimally without keeping any information from the previous moves. This notion plays a crucial role in verification, automata theory and synthesis. Casares and Ohlmann recently gave several characterizations of Eve-positionallity of $ω$-regular languages. For this, they introduce the notion $\\varepsilon$-complete parity automaton and show (among other results) that an $ω$-regular language is Eve-positional if and only if it can be recognized by some $\\varepsilon$-completion of a deterministic parity automaton. Colcombet and Idir extended on their work, and obtained a more direct semantic characterization of Eve-positionality. We introduce a new formalism that characterizes the Eve-positional languages, consisting in a restriction of non-deterministic Büchi automata. This allows us to complete a missing implication in Casares and Ohlmann's work. We then use this formalism to describe a determinization procedure for non-deterministic Büchi automaton recognizing such languages, with size blow-up at most factorial. We also show that this construction is, in a suitable sense, optimal."
  },
  {
    "date": "2026-02-10",
    "title": "The quantum multinomial distribution: a combinatorial formulation of multiphoton interference",
    "authors": "Alfonso Martinez, Josep Font-Segura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09894v1",
    "source": "arXiv",
    "abstract": "This paper presents a quantum generalization of the multinomial distribution for the transition probabilities of $m$ identical photons in a $k$-port linear optical interferometer: two multinomial coefficients (one for the input configuration, one for the output) times the squared modulus of a coherent sum over routing matrices, weighted by the multivariate hypergeometric distribution; no Hilbert space formalism is needed to state or evaluate it. The classical multinomial is recovered when all photons enter through a single port, the coherent sum degenerating to a single term with no interference; the quantum family is not a generalization in the Askey sense but a parallel family that departs from classical statistics through the coherence of the amplitude summation. The $r$-th factorial moment carries a squared multinomial coefficient in place of the classical single one, the extra factor arising from the two copies of the amplitude expansion whose indices the Fock state forces to agree; for the beam splitter, the third cumulant is invariant under bosonic interference and the quantum departure first appears in the fourth cumulant as negative excess kurtosis; for multiport interferometers, however, three-body interference breaks this invariance and the departure enters already at the third cumulant. Cross-mode covariances involve the phases of the scattering matrix through coherence terms that strengthen output anti-correlations beyond the classical value; together with the squared-coefficient signature in the single-mode moments, these provide low-order statistical witnesses for boson sampling verification without requiring the full permanent computation."
  },
  {
    "date": "2026-02-10",
    "title": "Simpler Presentations for Many Fragments of Quantum Circuits",
    "authors": "Colin Blake",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09874v1",
    "source": "arXiv",
    "abstract": "Equational reasoning is central to quantum circuit optimisation and verification: one replaces subcircuits by provably equivalent ones using a fixed set of rewrite rules viewed as equations. We study such reasoning through finite equational theories, presenting restricted quantum gate fragments as symmetric monoidal categories (PROPs), where wire permutations are treated as structural and separated cleanly from fragment-specific gate axioms. For six widely used near-Clifford fragments: qubit Clifford, real Clifford, Clifford+T (up to two qubits), Clifford+CS (up to three qubits) and CNOT-dihedral, we transfer the completeness results of prior work into our PROP framework. Beyond completeness, we address minimality (axiom independence). Using uniform separating interpretations into simple semantic targets, we prove minimality for several fragments (including all arities for qubit Clifford, real Clifford, and CNOT-dihedral), and bounded minimality for the remaining cases. Overall, our presentations significantly reduce rule counts compared to prior work and provide a reusable categorical framework for constructing complete and often minimal rewrite systems for quantum circuit fragments."
  },
  {
    "date": "2026-02-10",
    "title": "AI-Assisted Scientific Assessment: A Case Study on Climate Change",
    "authors": "Christian Buck, Levke Caesar, Michelle Chen Huebscher, Massimiliano Ciaramita, Erich M. Fischer, Zeke Hausfather, Özge Kart Tokmak, Reto Knutti, Markus Leippold, Joseph Ludescher, Katharine J. Mach, Sofia Palazzo Corner, Kasra Rafiezadeh Shahi, Johan Rockström, Joeri Rogelj, Boris Sakschewski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09723v1",
    "source": "arXiv",
    "abstract": "The emerging paradigm of AI co-scientists focuses on tasks characterized by repeatable verification, where agents explore search spaces in 'guess and check' loops. This paradigm does not extend to problems where repeated evaluation is impossible and ground truth is established by the consensus synthesis of theory and existing evidence. We evaluate a Gemini-based AI environment designed to support collaborative scientific assessment, integrated into a standard scientific workflow. In collaboration with a diverse group of 13 scientists working in the field of climate science, we tested the system on a complex topic: the stability of the Atlantic Meridional Overturning Circulation (AMOC). Our results show that AI can accelerate the scientific workflow. The group produced a comprehensive synthesis of 79 papers through 104 revision cycles in just over 46 person-hours. AI contribution was significant: most AI-generated content was retained in the report. AI also helped maintain logical consistency and presentation quality. However, expert additions were crucial to ensure its acceptability: less than half of the report was produced by AI. Furthermore, substantial oversight was required to expand and elevate the content to rigorous scientific standards."
  },
  {
    "date": "2026-02-10",
    "title": "Administrative Law's Fourth Settlement: AI and the Capability-Accountability Trap",
    "authors": "Nicholas Caputo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09678v1",
    "source": "arXiv",
    "abstract": "Since 1887, administrative law has navigated a \"capability-accountability trap\": technological change forces government to become more sophisticated, but sophistication renders agencies opaque to generalist overseers like the courts and Congress. The law's response--substituting procedural review for substantive oversight--has produced a sedimentary accretion of requirements that ossify capacity without ensuring democratic control. This Article argues that the Supreme Court's post-Loper Bright retrenchment is best understood as an effort to shrink administration back to comprehensible size in response to this complexification. But reducing complexity in this way sacrifices capability precisely when climate change, pandemics, and AI risks demand more sophisticated governance. AI offers a different path. Unlike many prior administrative technologies that increased opacity alongside capacity, AI can help build \"scrutability\" in government, translating technical complexity into accessible terms, surfacing the assumptions that matter for oversight, and enabling substantive verification of agency reasoning. This Article proposes three doctrinal innovations within administrative law to realize this potential: a Model and System Dossier (documenting model purpose, evaluation, monitoring, and versioning) extending the administrative record to AI decision-making; a material-model-change trigger specifying when AI updates require new process; and a \"deference to audit\" standard that rewards agencies for auditable evaluation of their AI tools. The result is a framework for what this Article calls the \"Fourth Settlement,\" administrative law that escapes the capability-accountability trap by preserving capability while restoring comprehensible oversight of administration."
  },
  {
    "date": "2026-02-10",
    "title": "The CLEF-2026 CheckThat! Lab: Advancing Multilingual Fact-Checking",
    "authors": "Julia Maria Struß, Sebastian Schellhammer, Stefan Dietze, Venktesh V, Vinay Setty, Tanmoy Chakraborty, Preslav Nakov, Avishek Anand, Primakov Chungkham, Salim Hafid, Dhruv Sahnan, Konstantin Todorov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09516v1",
    "source": "arXiv",
    "abstract": "The CheckThat! lab aims to advance the development of innovative technologies combating disinformation and manipulation efforts in online communication across a multitude of languages and platforms. While in early editions the focus has been on core tasks of the verification pipeline (check-worthiness, evidence retrieval, and verification), in the past three editions, the lab added additional tasks linked to the verification process. In this year's edition, the verification pipeline is at the center again with the following tasks: Task 1 on source retrieval for scientific web claims (a follow-up of the 2025 edition), Task 2 on fact-checking numerical and temporal claims, which adds a reasoning component to the 2025 edition, and Task 3, which expands the verification pipeline with generation of full-fact-checking articles. These tasks represent challenging classification and retrieval problems as well as generation challenges at the document and span level, including multilingual settings."
  },
  {
    "date": "2026-02-10",
    "title": "AlgoVeri: An Aligned Benchmark for Verified Code Generation on Classical Algorithms",
    "authors": "Haoyu Zhao, Ziran Yang, Jiawei Li, Deyuan He, Zenan Li, Chi Jin, Venugopal V. Veeravalli, Aarti Gupta, Sanjeev Arora",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09464v1",
    "source": "arXiv",
    "abstract": "Vericoding refers to the generation of formally verified code from rigorous specifications. Recent AI models show promise in vericoding, but a unified methodology for cross-paradigm evaluation is lacking. Existing benchmarks test only individual languages/tools (e.g., Dafny, Verus, and Lean) and each covers very different tasks, so the performance numbers are not directly comparable. We address this gap with AlgoVeri, a benchmark that evaluates vericoding of $77$ classical algorithms in Dafny, Verus, and Lean. By enforcing identical functional contracts, AlgoVeri reveals critical capability gaps in verification systems. While frontier models achieve tractable success in Dafny ($40.3$% for Gemini-3 Flash), where high-level abstractions and SMT automation simplify the workflow, performance collapses under the systems-level memory constraints of Verus ($24.7$%) and the explicit proof construction required by Lean (7.8%). Beyond aggregate metrics, we uncover a sharp divergence in test-time compute dynamics: Gemini-3 effectively utilizes iterative repair to boost performance (e.g., tripling pass rates in Dafny), whereas GPT-OSS saturates early. Finally, our error analysis shows that language design affects the refinement trajectory: while Dafny allows models to focus on logical correctness, Verus and Lean trap models in persistent syntactic and semantic barriers. All data and evaluation code can be found at https://github.com/haoyuzhao123/algoveri."
  },
  {
    "date": "2026-02-10",
    "title": "SpotAgent: Grounding Visual Geo-localization in Large Vision-Language Models through Agentic Reasoning",
    "authors": "Furong Jia, Ling Dai, Wenjin Deng, Fan Zhang, Chen Hu, Daxin Jiang, Yu Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09463v1",
    "source": "arXiv",
    "abstract": "Large Vision-Language Models (LVLMs) have demonstrated strong reasoning capabilities in geo-localization, yet they often struggle in real-world scenarios where visual cues are sparse, long-tailed, and highly ambiguous. Previous approaches, bound by internal knowledge, often fail to provide verifiable results, yielding confident but ungrounded predictions when faced with confounded evidence. To address these challenges, we propose SpotAgent, a framework that formalizes geo-localization into an agentic reasoning process that leverages expert-level reasoning to synergize visual interpretation with tool-assisted verification. SpotAgent actively explores and verifies visual cues by leveraging external tools (e.g., web search, maps) through a ReAct diagram. We introduce a 3-stage post-training pipeline starting with a Supervised Fine-Tuning (SFT) stage for basic alignment, followed by an Agentic Cold Start phase utilizing high-quality trajectories synthesized via a Multi-Agent framework, aiming to instill tool-calling expertise. Subsequently, the model's reasoning capabilities are refined through Reinforcement Learning. We propose a Spatially-Aware Dynamic Filtering strategy to enhance the efficiency of the RL stage by prioritizing learnable samples based on spatial difficulty. Extensive experiments on standard benchmarks demonstrate that SpotAgent achieves state-of-the-art performance, effectively mitigating hallucinations while delivering precise and verifiable geo-localization."
  },
  {
    "date": "2026-02-10",
    "title": "P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads",
    "authors": "Yun Luo, Futing Wang, Qianjia Cheng, Fangchen Yu, Haodi Lei, Jianhao Yan, Chenxi Li, Jiacheng Chen, Yufeng Zhao, Haiyuan Wan, Yuchen Zhang, Shenghe Zheng, Junchi Yao, Qingyang Zhang, Haonan He, Wenxuan Zeng, Li Sheng, Chengxing Xie, Yuxin Zuo, Yizhuo Li, Yulun Wu, Rui Huang, Dongzhan Zhou, Kai Chen, Yu Qiao, Lei Bai, Yu Cheng, Ning Ding, Bowen Zhou, Peng Ye, Ganqu Cui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09443v1",
    "source": "arXiv",
    "abstract": "The transition from symbolic manipulation to science-grade reasoning represents a pivotal frontier for Large Language Models (LLMs), with physics serving as the critical test anchor for binding abstract logic to physical reality. Physics demands that a model maintain physical consistency with the laws governing the universe, a task that fundamentally requires multimodal perception to ground abstract logic in reality. At the Olympiad level, diagrams are often constitutive rather than illustrative, containing essential constraints, such as boundary conditions and spatial symmetries, that are absent from the text. To bridge this visual-logical gap, we introduce P1-VL, a family of open-source vision-language models engineered for advanced scientific reasoning. Our method harmonizes Curriculum Reinforcement Learning, which employs progressive difficulty expansion to stabilize post-training, with Agentic Augmentation, enabling iterative self-verification at inference. Evaluated on HiPhO, a rigorous benchmark of 13 exams from 2024-2025, our flagship P1-VL-235B-A22B becomes the first open-source Vision-Language Model (VLM) to secure 12 gold medals and achieves the state-of-the-art performance in the open-source models. Our agent-augmented system achieves the No.2 overall rank globally, trailing only Gemini-3-Pro. Beyond physics, P1-VL demonstrates remarkable scientific reasoning capacity and generalizability, establishing significant leads over base models in STEM benchmarks. By open-sourcing P1-VL, we provide a foundational step toward general-purpose physical intelligence to better align visual perceptions with abstract physical laws for machine scientific discovery."
  },
  {
    "date": "2026-02-10",
    "title": "LLMAC: A Global and Explainable Access Control Framework with Large Language Model",
    "authors": "Sharif Noor Zisad, Ragib Hasan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09392v1",
    "source": "arXiv",
    "abstract": "Today's business organizations need access control systems that can handle complex, changing security requirements that go beyond what traditional methods can manage. Current approaches, such as Role-Based Access Control (RBAC), Attribute-Based Access Control (ABAC), and Discretionary Access Control (DAC), were designed for specific purposes. They cannot effectively manage the dynamic, situation-dependent workflows that modern systems require. In this research, we introduce LLMAC, a new unified approach using Large Language Models (LLMs) to combine these different access control methods into one comprehensive, understandable system. We used an extensive synthetic dataset that represents complex real-world scenarios, including policies for ownership verification, version management, workflow processes, and dynamic role separation. Using Mistral 7B, our trained LLM model achieved outstanding results with 98.5% accuracy, significantly outperforming traditional methods (RBAC: 14.5%, ABAC: 58.5%, DAC: 27.5%) while providing clear, human readable explanations for each decision. Performance testing shows that the system can be practically deployed with reasonable response times and computing resources."
  },
  {
    "date": "2026-02-10",
    "title": "Auditing Multi-Agent LLM Reasoning Trees Outperforms Majority Vote and LLM-as-Judge",
    "authors": "Wei Yang, Shixuan Li, Heng Ping, Peiyu Zhang, Paul Bogdan, Jesse Thomason",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09341v1",
    "source": "arXiv",
    "abstract": "Multi-agent systems (MAS) can substantially extend the reasoning capacity of large language models (LLMs), yet most frameworks still aggregate agent outputs with majority voting. This heuristic discards the evidential structure of reasoning traces and is brittle under the confabulation consensus, where agents share correlated biases and converge on the same incorrect rationale. We introduce AgentAuditor, which replaces voting with a path search over a Reasoning Tree that explicitly represents agreements and divergences among agent traces. AgentAuditor resolves conflicts by comparing reasoning branches at critical divergence points, turning global adjudication into efficient, localized verification. We further propose Anti-Consensus Preference Optimization (ACPO), which trains the adjudicator on majority-failure cases and rewards evidence-based minority selections over popular errors. AgentAuditor is agnostic to MAS setting, and we find across 5 popular settings that it yields up to 5% absolute accuracy improvement over a majority vote, and up to 3% over using LLM-as-Judge."
  },
  {
    "date": "2026-02-10",
    "title": "On A Parameterized Theory of Dynamic Logic for Operationally-based Programs",
    "authors": "Yuanrui Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09307v1",
    "source": "arXiv",
    "abstract": "Applying dynamic logics to program verifications is a challenge, because their axiomatic rules for regular expressions can be difficult to be adapted to different program models. We present a novel dynamic logic, called DLp, which supports reasoning based on programs' operational semantics. For those programs whose transitional behaviours are their standard or natural semantics, DLp makes their verifications easier since one can directly apply the program transitions for reasoning, without the need of re-designing and validating new rules as in most other dynamic logics. DLp is parametric. It provides a model-independent framework consisting of a relatively small set of inference rules, which depends on a given set of trustworthy rules for the operational semantics. These features of DLp let multiple models easily compared in its framework and makes it compatible with existing dynamic-logic theories. DLp supports cyclic reasoning, providing an incremental derivation process for recursive programs, making it more convenient to reason about without prior program transformations. We analyze and prove the soundness and completeness of DLp under certain conditions. Several case studies illustrate the features of DLp and fully demonstrate its potential usage."
  },
  {
    "date": "2026-02-10",
    "title": "X-Mark: Saliency-Guided Robust Dataset Ownership Verification for Medical Imaging",
    "authors": "Pranav Kulkarni, Junfeng Guo, Heng Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09284v1",
    "source": "arXiv",
    "abstract": "High-quality medical imaging datasets are essential for training deep learning models, but their unauthorized use raises serious copyright and ethical concerns. Medical imaging presents a unique challenge for existing dataset ownership verification methods designed for natural images, as static watermark patterns generated in fixed-scale images scale poorly dynamic and high-resolution scans with limited visual diversity and subtle anatomical structures, while preserving diagnostic quality. In this paper, we propose X-Mark, a sample-specific clean-label watermarking method for chest x-ray copyright protection. Specifically, X-Mark uses a conditional U-Net to generate unique perturbations within salient regions of each sample. We design a multi-component training objective to ensure watermark efficacy, robustness against dynamic scaling processes while preserving diagnostic quality and visual-distinguishability. We incorporate Laplacian regularization into our training objective to penalize high-frequency perturbations and achieve watermark scale-invariance. Ownership verification is performed in a black-box setting to detect characteristic behaviors in suspicious models. Extensive experiments on CheXpert verify the effectiveness of X-Mark, achieving WSR of 100% and reducing probability of false positives in Ind-M scenario by 12%, while demonstrating resistance to potential adaptive attacks."
  },
  {
    "date": "2026-02-09",
    "title": "How to Classically Verify a Quantum Cat without Killing It",
    "authors": "Yael Tauman Kalai, Dakshita Khurana, Justin Raizes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09282v1",
    "source": "arXiv",
    "abstract": "Existing protocols for classical verification of quantum computation (CVQC) consume the prover's witness state, requiring a new witness state for each invocation. Because QMA witnesses are not generally clonable, destroying the input witness means that amplifying soundness and completeness via repetition requires many copies of the witness. Building CVQC with low soundness error that uses only *one* copy of the witness has remained an open problem so far. We resolve this problem by constructing a CVQC that uses a single copy of the QMA witness, has negligible completeness and soundness errors, and does *not* destroy its witness. The soundness of our CVQC is based on the post-quantum Learning With Errors (LWE) assumption. To obtain this result, we define and construct two primitives (under the post-quantum LWE assumption) for non-destructively handling superpositions of classical data, which we believe are of independent interest: - A *state preserving* classical argument for NP. - Dual-mode trapdoor functions with *state recovery*."
  },
  {
    "date": "2026-02-09",
    "title": "Global Protocols under Rendezvous Synchrony: From Realizability to Type Checking",
    "authors": "Elaine Li, Felix Stutz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09197v1",
    "source": "arXiv",
    "abstract": "Global protocol specifications are the starting point of top-down verification methodologies, and serve as a blueprint for synthesizing local specifications that guarantee the correctness of distributed implementations. In this work, we study global protocol specifications targeting distributed processes that communicate via rendezvous synchrony. We obtain the following positive results for the synchronous realizability problem: (a) realizability is decidable for global protocols over a transitive concurrency alphabet in 2-EXPTIME in the size of the protocol, and in 3-EXPTIME in the size of the alphabet, and (b) realizability is decidable in EXPTIME for global protocols that unambiguously represent their trace language. Unambiguous global protocols encompass fragments of directed and sender-driven choice protocols studied in prior work. Further, our reductions admit the corollary that the synchronous verification problem is solvable with the same complexity, where a candidate realization is included as part of the input. We then prove a negative result stating that synchronous realizability is undecidable in general. Finally, we propose a type system to check pi-calculus processes against local specifications in the form of synchronous communicating state machines. Our type system is the first to support processes with local mixed choice in the presence of session interleaving and~delegation."
  },
  {
    "date": "2026-02-09",
    "title": "Boundary bound states and integrable Wilson loops in ABJM",
    "authors": "Diego H. Correa, Maximiliano G. Ferro, Victor I. Giraldo-Rivera, Nicolas A. Ivanovich",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09195v1",
    "source": "arXiv",
    "abstract": "We derive an integrable reflection matrix for the scattering of excitations from a boundary with a degree of freedom when the reflection process preserves an $SU(1|2)$ symmetry. As this residual symmetry is not sufficient to fully determine the reflection matrix, we use the boundary remnant of the Yangian symmetry invariance and obtain a family of integrable solutions. A concrete realization of this setup is found when studying insertions in the 1/2 BPS Wilson loop in ABJM theory. The boundary degree of freedom appears as a boundary bound state due to poles in the dressing phase of the reflection matrix. We also compare our results with those obtained from the boundary bound state bootstrap procedure. The ABJM Wilson loop example enables us to perform perturbative verifications of our results."
  },
  {
    "date": "2026-02-09",
    "title": "Spectral response of SPHEREx",
    "authors": "Howard Hui, James J. Bock, Samuel Condon, C. Darren Dowell, Woong-Seob Jeong, Young-soo Jo, Phillip M. Korngut, Kenneth Manatt, Chi Nguyen, Hien Nguyen, Stephen Padin, Sung-Joon Park, Jeonghyun Pyo, Yujin Yang, Matthew L. N. Ashby, Yoonsoo P. Bach, Yi-Kuan Chiang, Asantha Cooray, Brendan P. Crill, Ari J. Cukierman, Andreas L. Faisst, Jae Hwan Kang, Carey M. Lisse, Daniel C. Masters, Roberta Paladini, Zafar Rustamkulov, Volker Tolls, Michael W. Werner, Michael Zemcov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.09139v1",
    "source": "arXiv",
    "abstract": "The Spectro Photometer for the History of the Universe, Epoch of Reionization, and Ices Explorer (SPHEREx) is conducting the first all-sky near infrared spectral survey spanning 0.75 to 5.0um with resolving power R~35 to 130. Linear variable filters mounted in front of six H2RG detectors produce a position dependent spectral response across the focal plane. This paper presents the ground-based spectral calibration of SPHEREx, including the cryogenic apparatus, optical configuration, measurement strategy, analysis pipeline, and resulting calibration products. Monochromatic wavelength scans are used to derive the spectral response function, band center, and resolving power for every pixel. Band centers are measured to better than 1nm for Bands 1 through 4 (0.75 to 3.82um) and better than 10nm for Bands 5 and 6 (3.82 to 5.0um). Out-of-band leakage is negligible for detectors above 1.64um and is present at the percent level below this wavelength. The resolving power is measured to within 5% and agrees with design expectations to within 10%. An on-sky spectrum of the Cat's Eye Nebula (NGC 6543) constructed from repeated observations provides in-flight verification and shows agreement between ground calibrated response and astrophysical emission features. Calibration products, including per-pixel band center and resolving power maps, are released through IPAC to support community use of SPHEREx data. The absolute spectral calibration will continue to improve through in-flight measurements, with further reductions in uncertainty expected for the longest-wavelength bands."
  },
  {
    "date": "2026-2-10",
    "title": "CID4IoT: IoT-Oriented Command Injection Vulnerability Detection Based on Critical Code Extraction and LLM-Analysis_supp1-3662325.pdf",
    "authors": "Zhenji Zhou",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/jiot.2026.3662325/mm1",
    "source": "IEEE",
    "abstract": "The Internet of Things (IoT) devices have brought invaluable convenience to our daily lives. However, they also introduce significant security challenges. Common vulnerabilities in numerous IoT devices predominantly reside in their web services. Unfortunately, existing vulnerability detection methods either incur heavy execution overhead or produce excessive false positives/negatives. This significantly hinders the efficient analysis of vulnerabilities in web services. This paper proposes CID4IoT, a novel static automated vulnerability detection approach designed to effectively detect command injection vulnerabilities in web services provided by IoT devices. Inspired by the concept of taint analysis, CID4IoT first analyzes vulnerability reports to identify taint source functions and sink functions. Then, CID4IoT extracts pseudocode between taint source functions and sink functions to form critical code snippets. Subsequently, it utilizes LLM to analyze these critical code snippets for vulnerability detection.We implemented a prototype of CID4IoT and evaluated it on real firmware devices. CID4IoT discovered 54 previously unknown vulnerabilities, of which 39 are confirmed by CVE. Compared with state-of-the-art tools KARONTE and SaTC, it identified significantly more vulnerabilities in the test set while achieving notable improvements in analysis efficiency. The results demonstrate that CID4IoT is effective in detecting flaws in IoT devices"
  },
  {
    "date": "2026-2-10",
    "title": "DecentraBot: An Intent-Aware LLM-Powered Conversational Agent With What-Next Prompting for Decentraland Users_supp1-3656955.pdf",
    "authors": "Raju Halder",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/tcss.2026.3656955/mm1",
    "source": "IEEE",
    "abstract": "The rapid growth of Decentraland has crafted a new frontier for digital asset investment. However, navigating and understanding this platform pose a significant challenge, especially for nonexpert users. The key obstacles include understanding market trends and price forecasting of the virtual assets, interpreting social media sentiment, and analyzing the impact of various economic factors. Furthermore, there is a lack of comprehensible, user-friendly tools to guide both the novice and experienced users in this complex, fast-evolving markets. To address this research gap, this article introduces <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">DecentraBot</i>, a domain specific conversational AI framework designed specifically for guiding users in making informed decisions on possible land investment and trading opportunities within Decentraland. By leveraging a systematic approach, which integrates fine-tuning methods, predictive and forecasting models, real-time data utilization, and novel prompt engineering techniques; we enable the open-domain large language models (LLMs) to transform into a domain-specific assistant capable of handling conversational, explanatory, and analytical queries effectively. To support users lacking prompting expertise, we introduce What-Next prompting; an efficient strategy that aims to minimize interaction barriers, making AI-based conversations more accessible and inclusive. Extensive experimental evaluation of DecentraBot over our proposed comprehensive fine-tune datasets demonstrates a significant performance improvement in terms of both quality and relevance of the responses to a broad spectrum of domain-specific queries. To the best of our knowledge, this is the first initiative of its kind in the realm of user-centric AI assistance within the metaverse ecosystem."
  },
  {
    "date": "2026-2-10",
    "title": "MemAscend: System Memory Optimization for SSD-Offloaded LLM Fine-Tuning",
    "authors": "Yong-Cheng Liaw, Shuo-Han Chen",
    "publish": "IEEE Transactions on Emerging Topics in Computing",
    "url": "https://doi.org/10.1109/tetc.2026.3661468",
    "source": "IEEE",
    "abstract": "Owing to the huge success of generative artificial intelligence (AI), large language models (LLMs) have emerged as a core subclass, powering applications such as question answering, text generation, and code completion. While fine-tuning these models on domain-specific data can yield significant performance gains, it also poses daunting computational challenges, especially for researchers and organizations with limited hardware resources. Although SSD offloading (i.e., ZeRO-Infinity) has emerged as a viable strategy to overcome the GPU memory barrier via leveraging both system memory (i.e., CPU DRAM) and storage space (i.e., solid-state devices, SSDs), its design primarily targets model-centric performance issues. As a result, key system-level issues, including system memory fragmentation, inefficient pinned buffer allocation, peak system memory usage spikes, and file system overhead, remain unaddressed, limiting scalability and inflating costs. Such an observation motivates this paper to introduce MemAscend, a framework that systematically tackles the underexplored system memory bottlenecks in SSD-offloaded LLM training, with a focus on resource-constrained environments. By streamlining pinned-memory allocation, eradicating fragmentation, and mitigating peak system memory usage, MemAscend reclaims a substantial system memory budget, enabling larger models, longer context windows, and higher batch sizes without exceeding modest hardware limits. Across diverse LLM benchmarks, MemAscend reduces peak system-memory consumption by an average of 55.7% compared with state-of-the-art SSD offloading techniques, lowering the hardware barrier for fine-tuning and unlocking new possibilities for cost-effective large-scale training on limited-resource machines."
  },
  {
    "date": "2026-2-10",
    "title": "Formal Reasoning Meets LLMs: Toward AI for Mathematics and Verification",
    "authors": "Kaiyu Yang, Gabriel Poesia, Jingxuan He, Wenda Li, Kristin Lauter, Swarat Chaudhuri, Dawn Song",
    "publish": "Communications of the ACM",
    "url": "https://doi.org/10.1145/3750038",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-10",
    "title": "Logits-Level Balanced Machine Unlearning for LLM-Based Recommendation System",
    "authors": "Chenchen Tan, Xinghao Li, Youyang Qu, Cunjian Chen, Shujie Cui, Longxiang Gao",
    "publish": "IEEE Transactions on Neural Networks and Learning Systems",
    "url": "https://doi.org/10.1109/tnnls.2026.3660137",
    "source": "IEEE",
    "abstract": "As recommendation systems have become foundational to digital platforms, the integration of large language models (LLMs) into these systems offers transformative potential. In LLM-based recommendation (LLMRec) systems, LLMs excel at capturing nuanced user pReferences, greatly enhancing personalization and recommendation accuracy. However, LLMRec systems face data governance issues, such as data privacy, outdated data, poisoned data, and copyrighted data. All these data government scenarios require the removal of data and its impact from large models like LLMRec. This poses significant challenges as existing solutions struggle to accurately delete target data from such complex systems. Motivated by this, we propose an LLMRec unlearning system based on adapter-driven logits modification in this work. This mechanism addresses the unique characteristics of LLMRec’s complex parameters and network structure, enabling precise and effective unlearning while maintaining recommendation performance. Our approach offers several key advantages: 1) using adapters reduces training costs during the unlearning process; 2) a knowledge distillation (KD)-powered logits modification mechanism ensures that the model can still engage in effective reasoning after unlearning, leveraging its existing knowledge logic to maintain high-quality recommendations; and 3) an additional adapter-based general knowledge retention module is incorporated to preserve the core language capabilities of the LLMRec system, ensuring that its foundational performance remains intact. Extensive experimental results show the effectiveness and efficiency of the proposed system. The code is released at: <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://anonymous.4open.science/r/llmrecunlearning-1CB3</uri>"
  },
  {
    "date": "2026-2-10",
    "title": "DHT-Backed Ancestor-Assisted Merkle Verification for Scalable and Real-Time Log Integrity in Cloud Data Lakes",
    "authors": "Vayuphak Saengthong, Theme Mantharngkul, Chatdanai Wongsuwan, Korarit Ritthaisong, Somchart Fugkaew",
    "publish": "IEEE Open Journal of the Computer Society",
    "url": "https://doi.org/10.1109/ojcs.2026.3663463",
    "source": "IEEE",
    "abstract": "Cloud data lakes accumulate massive volumes of append-only, high-frequency logs from web servers, gateways, security appliances, and databases. Ensuring their integrity is challenging because existing blockchain-assisted auditing schemes are primarily optimized for static or periodically updated data and provide limited support for continuous ingestion, real-time verification, and auditor access control. These limitations lead to high recomputation overhead, delayed tamper detection, and the lack of reusable proofs required for scalable log publishing.This paper introduces a verifiable log publishing framework based on a newly proposed ancestor-assisted Merkle Tree with stride-based checkpoints for efficient verification of encrypted logs. Each log record is canonically formatted, AEAD-encrypted with metadata binding, and producer-attested prior to storage. Parent-node records and ancestor certificates are distributed via a private Distributed Hash Table (DHT) to enable proof reuse, while only an epoch-level root-of-roots is anchored on a public blockchain to provide tamper-evident integrity guarantees. The framework further supports auditor authorization using certification-authority-issued tokens and incorporates micro-root commitments for near real-time verification. Experimental results demonstrate substantial performance improvements: single-record verification is significantly faster than the strongest baseline, verification throughput is markedly higher, commit latency is greatly reduced, and on-chain storage remains constant across all evaluated epoch sizes. These results confirm that the proposed architecture enables scalable, low-latency, and compliance-aware log integrity verification suitable for modern cloud data lake environments."
  }
]