[
  {
    "date": "2026-02-12",
    "title": "Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment",
    "authors": "Jacky Kwok, Xilun Zhang, Mengdi Xu, Yuejiang Liu, Azalia Mirhoseini, Chelsea Finn, Marco Pavone",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.12281v1",
    "source": "arXiv",
    "abstract": "The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the \"intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce \"boot-time compute\" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate."
  },
  {
    "date": "2026-02-12",
    "title": "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling",
    "authors": "Leon Liangyu Chen, Haoyu Ma, Zhipeng Fan, Ziqi Huang, Animesh Sinha, Xiaoliang Dai, Jialiang Wang, Zecheng He, Jianwei Yang, Chunyuan Li, Junzhe Sun, Chu Wang, Serena Yeung-Levy, Felix Juefei-Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.12279v1",
    "source": "arXiv",
    "abstract": "Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models."
  },
  {
    "date": "2026-02-12",
    "title": "Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision",
    "authors": "Xiaohan He, Shiyang Feng, Songtao Huang, Lei Bai, Bin Wang, Bo Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.12164v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE."
  },
  {
    "date": "2026-02-12",
    "title": "3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting",
    "authors": "Wancai Zheng, Hao Chen, Xianlong Lu, Linlin Ou, Xinyi Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.12159v1",
    "source": "arXiv",
    "abstract": "Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/"
  },
  {
    "date": "2026-02-12",
    "title": "Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning",
    "authors": "Xiang Liu, Sen Cui, Guocai Yao, Zhong Cao, Jingheng Ma, Min Zhang, Changshui Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.12065v1",
    "source": "arXiv",
    "abstract": "Training robotic policies directly in the real world is expensive and unscalable. Although generative simulation enables large-scale data synthesis, current approaches often fail to generate logically coherent long-horizon tasks and struggle with dynamic physical uncertainties due to open-loop execution. To address these challenges, we propose Affordance-Graphed Task Worlds (AGT-World), a unified framework that autonomously constructs interactive simulated environments and corresponding robot task policies based on real-world observations. Unlike methods relying on random proposals or static replication, AGT-World formalizes the task space as a structured graph, enabling the precise, hierarchical decomposition of complex goals into theoretically grounded atomic primitives. Furthermore, we introduce a Self-Evolution mechanism with hybrid feedback to autonomously refine policies, combining Vision-Language Model reasoning and geometric verification. Extensive experiments demonstrate that our method significantly outperforms in success rates and generalization, achieving a self-improving cycle of proposal, execution, and correction for scalable robot learning."
  },
  {
    "date": "2026-02-12",
    "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments",
    "authors": "Xinyu Yang, Chenlong Deng, Tongyu Wen, Binyu Xie, Zhicheng Dou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.12056v1",
    "source": "arXiv",
    "abstract": "Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent ."
  },
  {
    "date": "2026-02-12",
    "title": "The Cylinder Simplicial DG Ring",
    "authors": "Amnon Yekutieli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11943v1",
    "source": "arXiv",
    "abstract": "Given a DG ring $B$ and an integer $q \\geq 0$, we construct the $q$-th cylinder DG ring $Cyl_q(B)$. For $q = 1$ this is just Keller's cylinder DG ring, sometimes called the path object of $B$, which encodes homotopies between DG ring homomorphisms $A \\to B$. As $q$ changes the cylinder DG rings form a simplicial DG ring $Cyl(B)$. Hence, given another DG ring $A$, the DG ring homomorphisms $A \\to Cyl(B)$ form a simplicial set $Hom(A,Cyl(B))$. Our main theorem states that when $A$ is a semi-free DG ring, the simplicial set $Hom(A,Cyl(B))$ is a Kan complex. For the verification of the Kan condition we introduce a new construction, which may be of independent interest. Given a horn $Y$, we define the DG ring $N(Y,B)$, and we prove that $N(Y,B)$ represents this horn in the simplicial set $Hom(A,Cyl(B))$. In this way the Kan condition is implemented intrinsically in the category of DG rings, thus facilitating calculations. Presumably all the above can be extended, with little change, from DG rings to (small) DG categories. That would enable easy constructions and explicit calculations of some simplicial aspects of DG categories."
  },
  {
    "date": "2026-02-12",
    "title": "LLM-based Triplet Extraction from Financial Reports",
    "authors": "Dante Wesslund, Ville Stenström, Pontus Linde, Alexander Holmberg",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11886v1",
    "source": "arXiv",
    "abstract": "Corporate financial reports are a valuable source of structured knowledge for Knowledge Graph construction, but the lack of annotated ground truth in this domain makes evaluation difficult. We present a semi-automated pipeline for Subject-Predicate-Object triplet extraction that uses ontology-driven proxy metrics, specifically Ontology Conformance and Faithfulness, instead of ground-truth-based evaluation. We compare a static, manually engineered ontology against a fully automated, document-specific ontology induction approach across different LLMs and two corporate annual reports. The automatically induced ontology achieves 100% schema conformance in all configurations, eliminating the ontology drift observed with the manual approach. We also propose a hybrid verification strategy that combines regex matching with an LLM-as-a-judge check, reducing apparent subject hallucination rates from 65.2% to 1.6% by filtering false positives caused by coreference resolution. Finally, we identify a systematic asymmetry between subject and object hallucinations, which we attribute to passive constructions and omitted agents in financial prose."
  },
  {
    "date": "2026-02-12",
    "title": "Thinking with Drafting: Optical Decompression via Logical Reconstruction",
    "authors": "Jingxuan Wei, Honghao He, Caijun Jia, Siyuan Li, Zheng Sun, Yuhang Xu, Yuanyuan Lin, Linzhuang Sun, Yuchen Wu, Bihui Yu, Xiangxiang Zhang, Cheng Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11731v1",
    "source": "arXiv",
    "abstract": "Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation. However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology, while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression-the process of reconstructing latent logical structures from compressed visual tokens. Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark. Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning."
  },
  {
    "date": "2026-02-12",
    "title": "LLM-Driven 3D Scene Generation of Agricultural Simulation Environments",
    "authors": "Arafa Yoncalik, Wouter Jansen, Nico Huebel, Mohammad Hasan Rahmani, Jan Steckel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11706v1",
    "source": "arXiv",
    "abstract": "Procedural generation techniques in 3D rendering engines have revolutionized the creation of complex environments, reducing reliance on manual design. Recent approaches using Large Language Models (LLMs) for 3D scene generation show promise but often lack domain-specific reasoning, verification mechanisms, and modular design. These limitations lead to reduced control and poor scalability. This paper investigates the use of LLMs to generate agricultural synthetic simulation environments from natural language prompts, specifically to address the limitations of lacking domain-specific reasoning, verification mechanisms, and modular design. A modular multi-LLM pipeline was developed, integrating 3D asset retrieval, domain knowledge injection, and code generation for the Unreal rendering engine using its API. This results in a 3D environment with realistic planting layouts and environmental context, all based on the input prompt and the domain knowledge. To enhance accuracy and scalability, the system employs a hybrid strategy combining LLM optimization techniques such as few-shot prompting, Retrieval-Augmented Generation (RAG), finetuning, and validation. Unlike monolithic models, the modular architecture enables structured data handling, intermediate verification, and flexible expansion. The system was evaluated using structured prompts and semantic accuracy metrics. A user study assessed realism and familiarity against real-world images, while an expert comparison demonstrated significant time savings over manual scene design. The results confirm the effectiveness of multi-LLM pipelines in automating domain-specific 3D scene generation with improved reliability and precision. Future work will explore expanding the asset hierarchy, incorporating real-time generation, and adapting the pipeline to other simulation domains beyond agriculture."
  },
  {
    "date": "2026-02-12",
    "title": "ANML: Attribution-Native Machine Learning with Guaranteed Robustness",
    "authors": "Oliver Zahn, Matt Beton, Simran Chana",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11690v1",
    "source": "arXiv",
    "abstract": "Frontier AI systems increasingly train on specialized expert data, from clinical records to proprietary research to curated datasets, yet current training pipelines treat all samples identically. A Nobel laureate's contribution receives the same weight as an unverified submission. We introduce ANML (Attribution-Native Machine Learning), a framework that weights training samples by four quality factors: gradient-based consistency (q), verification status (v), contributor reputation (r), and temporal relevance (T). By combining what the model observes (gradient signals) with what the system knows about data provenance (external signals), ANML produces per-contributor quality weights that simultaneously improve model performance and enable downstream attribution. Across 5 datasets (178-32,561 samples), ANML achieves 33-72% error reduction over gradient-only baselines. Quality-weighted training is data-efficient: 20% high-quality data outperforms 100% uniformly weighted data by 47%. A Two-Stage Adaptive gating mechanism guarantees that ANML never underperforms the best available baseline, including under strategic joint attacks combining credential faking with gradient alignment. When per-sample detection fails against subtle corruption, contributor-level attribution provides 1.3-5.3x greater improvement than sample-level methods, with the advantage growing as corruption becomes harder to detect."
  },
  {
    "date": "2026-02-12",
    "title": "DMind-3: A Sovereign Edge--Local--Cloud AI System with Controlled Deliberation and Correction-Based Tuning for Safe, Low-Latency Transaction Execution",
    "authors": "Enhao Huang, Frank Li, Tony Lin, Lowes Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11651v1",
    "source": "arXiv",
    "abstract": "This paper introduces DMind-3, a sovereign Edge-Local-Cloud intelligence stack designed to secure irreversible financial execution in Web3 environments against adversarial risks and strict latency constraints. While existing cloud-centric assistants compromise privacy and fail under network congestion, and purely local solutions lack global ecosystem context, DMind-3 resolves these tensions by decomposing capability into three cooperating layers: a deterministic signing-time intent firewall at the edge, a private high-fidelity reasoning engine on user hardware, and a policy-governed global context synthesizer in the cloud. We propose policy-driven selective offloading to route computation based on privacy sensitivity and uncertainty, supported by two novel training objectives: Hierarchical Predictive Synthesis (HPS) for fusing time-varying macro signals, and Contrastive Chain-of-Correction Supervised Fine-Tuning (C$^3$-SFT) to enhance local verification reliability. Extensive evaluations demonstrate that DMind-3 achieves a 93.7% multi-turn success rate in protocol-constrained tasks and superior domain reasoning compared to general-purpose baselines, providing a scalable framework where safety is bound to the edge execution primitive while maintaining sovereignty over sensitive user intent."
  },
  {
    "date": "2026-02-12",
    "title": "Analytical Search",
    "authors": "Yiteng Tu, Shuo Miao, Weihang Su, Yiqun Liu, Qingyao Ai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11581v1",
    "source": "arXiv",
    "abstract": "Analytical information needs, such as trend analysis and causal impact assessment, are prevalent across various domains including law, finance, science, and much more. However, existing information retrieval paradigms, whether based on relevance-oriented document ranking or retrieval-augmented generation (RAG) with large language models (LLMs), often struggle to meet the end-to-end requirements of such tasks at the corpus scale. They either emphasize information finding rather than end-to-end problem solving, or simply treat everything as naive question answering, offering limited control over reasoning, evidence usage, and verifiability. As a result, they struggle to support analytical queries that have diverse utility concepts and high accountability requirements. In this paper, we propose analytical search as a distinct and emerging search paradigm designed to fulfill these analytical information needs. Analytical search reframes search as an evidence-governed, process-oriented analytical workflow that explicitly models analytical intent, retrieves evidence for fusion, and produces verifiable conclusions through structured, multi-step inference. We position analytical search in contrast to existing paradigms, and present a unified system framework that integrates query understanding, recall-oriented retrieval, reasoning-aware fusion, and adaptive verification. We also discuss potential research directions for the construction of analytical search engines. In this way, we highlight the conceptual significance and practical importance of analytical search and call on efforts toward the next generation of search engines that support analytical information needs."
  },
  {
    "date": "2026-02-12",
    "title": "Benchmarking for Single Feature Attribution with Microarchitecture Cliffs",
    "authors": "Hao Zhen, Qingxuan Kang, Yungang Bao, Trevor E. Carlson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11580v1",
    "source": "arXiv",
    "abstract": "Architectural simulators play a critical role in early microarchitectural exploration due to their flexibility and high productivity. However, their effectiveness is often constrained by fidelity: simulators may deviate from the behavior of the final RTL, leading to unreliable performance estimates. Consequently, model calibration, which aligns simulator behavior with the RTL as the ground-truth microarchitecture, becomes essential for achieving accurate performance modeling. To facilitate model calibration accuracy, we propose Microarchitecture Cliffs, a benchmark generation methodology designed to expose mismatches in microarchitectural behavior between the simulator and RTL. After identifying the key architectural components that require calibration, the Cliff methodology enables precise attribution of microarchitectural differences to a single microarchitectural feature through a set of benchmarks. In addition, we develop a set of automated tools to improve the efficiency of the Cliff workflow. We apply the Cliff methodology to calibrate the XiangShan version of gem5 (XS-GEM5) against the XiangShan open-source CPU (XS-RTL). We reduce the performance error of XS-GEM5 from 59.2% to just 1.4% on the Cliff benchmarks. Meanwhile, the calibration guided by Cliffs effectively reduces the relative error of a representative tightly coupled microarchitectural feature by 48.03%. It also substantially lowers the absolute performance error, with reductions of 15.1% and 21.0% on SPECint2017 and SPECfp2017, respectively."
  },
  {
    "date": "2026-02-12",
    "title": "PRIME: A Process-Outcome Alignment Benchmark for Verifiable Reasoning in Mathematics and Engineering",
    "authors": "Xiangfeng Wang, Hangyu Guo, Yanlin Lai, Mitt Huang, Liang Zhao, Chengyuan Yao, Yinmin Zhang, Qi Han, Xiaoxiao Ren, Chun Yuan, Tong Xu, Zheng Ge, Xiangyu Zhang, Daxin Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11570v1",
    "source": "arXiv",
    "abstract": "While model-based verifiers are essential for scaling Reinforcement Learning with Verifiable Rewards (RLVR), current outcome-centric verification paradigms primarily focus on the consistency between the final result and the ground truth, often neglecting potential errors in the derivation process. This leads to assigning positive rewards to correct answers produced from incorrect derivations. To bridge this gap, we introduce PRIME, a benchmark for evaluating verifiers on Process-Outcome Alignment verification in Mathematics and Engineering. Curated from a comprehensive collection of college-level STEM problems, PRIME comprises 2,530 high-difficulty samples through a consistency-based filtering pipeline. Through extensive evaluation, we find that current verifiers frequently fail to detect derivation flaws. Furthermore, we propose a process-aware RLVR training paradigm utilizing verifiers selected via PRIME. This approach substantially outperforms the outcome-only verification baseline, achieving absolute performance gains of 8.29%, 9.12%, and 7.31% on AIME24, AIME25, and Beyond-AIME, respectively, for the Qwen3-14B-Base model. Finally, we demonstrate a strong linear correlation ($R^2 > 0.92$) between verifier accuracy on PRIME and RLVR training effectiveness, validating PRIME as a reliable predictor for verifier selection."
  },
  {
    "date": "2026-02-12",
    "title": "Human-Inspired Continuous Learning of Internal Reasoning Processes: Learning How to Think for Adaptive AI Systems",
    "authors": "Hong Su",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11516v1",
    "source": "arXiv",
    "abstract": "Learning internal reasoning processes is crucial for developing AI systems capable of sustained adaptation in dynamic real-world environments. However, most existing approaches primarily emphasize learning task-specific outputs or static knowledge representations, while overlooking the continuous refinement of internal reasoning structures, action scheduling policies, and learning mechanisms themselves. In this paper, we propose a human-inspired continuous learning framework that unifies reasoning, action, reflection, and verification within a sequential reasoning model enhanced by parallel learning. The framework explicitly treats internal thinking processes as primary learning objects. It systematically records internal reasoning trajectories and environmental interactions as structured learning material, enabling the system to optimize not only task-level content but also the organization, scheduling, and evolution of reasoning activities. This design realizes learning alongside processing, allowing cognitive structures to improve during execution. Furthermore, the framework supports controlled replacement of predefined logic with learned procedures and introduces a hierarchical learning-to-learn mechanism that jointly adapts task-level parameters and learning strategies. As a result, the system progressively evolves its internal cognitive architecture while preserving operational stability. Experimental results on a temperature sensor abnormality detection task show that incorporating internal-process learning reduces average runtime by 23.9%."
  },
  {
    "date": "2026-02-12",
    "title": "Data-driven modelling of low-dimensional dynamical structures underlying complex full-body human movement",
    "authors": "Ryota Takamido, Chiharu Suzuki, Hiroki Nakamoto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11492v1",
    "source": "arXiv",
    "abstract": "One of the central challenges in the study of human motor control and learning is the degrees-of-freedom problem. Although the dynamical systems approach (DSA) has provided valuable insights into addressing this issue, its application has largely been confined to cyclic or simplified motor movements. To overcome this limitation, the present study employs neural ordinary differential equations (NODEs) to model the time evolution of non-cyclic full-body movements as a low-dimensional latent dynamical system. Given the temporal complexity full-body kinematic chains, baseball pitching was selected as a representative target movement to examine whether DSA could be extended to more complex, ecologically valid human movements. Results of the verification experiment demonstrated that the time evolution of a complex pitching motion could be accurately predicted (R^2 > 0.45) using the NODE-based dynamical model. Notably, approximately 50% of the variance in the latter half of the pitching motion was explained using only the initial ~8% of the temporal sequence, underscoring how subsequent movement evolves from initial conditions according to ODE-defined dynamics in latent space. These findings indicate the potential to extend the DSA to more complex and ecologically valid forms of human movement."
  },
  {
    "date": "2026-02-11",
    "title": "Surface impedance inference via neural fields and sparse acoustic data obtained by a compact array",
    "authors": "Yuanxin Xia, Xinyan Li, Matteo Calafà, Allan P. Engsig-Karup, Cheol-Ho Jeong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11425v1",
    "source": "arXiv",
    "abstract": "Standardized laboratory characterizations for absorbing materials rely on idealized sound field assumptions, which deviate largely from real-life conditions. Consequently, \\emph{in-situ} acoustic characterization has become essential for accurate diagnosis and virtual prototyping. We propose a physics-informed neural field that reconstructs local, near-surface broadband sound fields from sparse pressure samples to directly infer complex surface impedance. A parallel, multi-frequency architecture enables a broadband impedance retrieval within runtimes on the order of seconds to minutes. To validate the method, we developed a compact microphone array with low hardware complexity. Numerical verifications and laboratory experiments demonstrate accurate impedance retrieval with a small number of sensors under realistic conditions. We further showcase the approach in a vehicle cabin to provide practical guidance on measurement locations that avoid strong interference. Here, we show that this approach offers a robust means of characterizing \\emph{in-situ} boundary conditions for architectural and automotive acoustics."
  },
  {
    "date": "2026-02-11",
    "title": "When Visibility Outpaces Verification: Delayed Verification and Narrative Lock-in in Agentic AI Discourse",
    "authors": "Hanjing Shi, Dominic DiFranzo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11412v1",
    "source": "arXiv",
    "abstract": "Agentic AI systems-autonomous entities capable of independent planning and execution-reshape the landscape of human-AI trust. Long before direct system exposure, user expectations are mediated through high-stakes public discourse on social platforms. However, platform-mediated engagement signals (e.g., upvotes) may inadvertently function as a ``credibility proxy,'' potentially stifling critical evaluation. This paper investigates the interplay between social proof and verification timing in online discussions of agentic AI. Analyzing a longitudinal dataset from two distinct Reddit communities with contrasting interaction cultures-r/OpenClaw and r/Moltbook-we operationalize verification cues via reproducible lexical rules and model the ``time-to-first-verification'' using a right-censored survival analysis framework. Our findings reveal a systemic ``Popularity Paradox'': high-visibility discussions in both subreddits experience significantly delayed or entirely absent verification cues compared to low-visibility threads. This temporal lag creates a critical window for ``Narrative Lock-in,'' where early, unverified claims crystallize into collective cognitive biases before evidence-seeking behaviors emerge. We discuss the implications of this ``credibility-by-visibility'' effect for AI safety and propose ``epistemic friction'' as a design intervention to rebalance engagement-driven platforms."
  },
  {
    "date": "2026-02-11",
    "title": "Modelling Trust and Trusted Systems: A Category Theoretic Approach",
    "authors": "Ian Oliver, Pekka Kuure",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.11376v1",
    "source": "arXiv",
    "abstract": "We introduces a category-theoretic framework for modelling trust as applied to trusted computation systems and remote attestation. By formalizing elements, claims, results, and decisions as objects within a category, and the processes of attestation, verification, and decision-making as morphisms, the framework provides a rigorous approach to understanding trust establishment and provides a well-defined semantics for terms such as `trustworthiness' and 'justification'/forensics. The trust decision space is formalized using a Heyting Algebra, allowing nuanced trust levels that extend beyond binary trusted/untrusted states. We then present additional structures and in particular utilise exponentiation in a category theoretic sense to define compositions of attestation operations and provide the basis of a measurement for the expressibility of an attestation environment. We present a number of worked examples including boot-run-shutdown sequences, Evil Maid attacks and the specification of an attestation environment based upon this model. We then address challenges in modelling dynamic and larger systems made of multiple compositions."
  },
  {
    "date": "2026-2-12",
    "title": "Towards Refining Developer Questions using LLM-Based Named Entity Recognition for Developer Chatroom Conversations_supp1-3663599.pdf",
    "authors": "Pouya Fathollahzadeh",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/tse.2026.3663599/mm1",
    "source": "IEEE",
    "abstract": "In software engineering chatrooms, communication is often hindered by imprecise questions that cannot be answered. Recognizing key entities (e.g., programming languages and libraries) and user intent (e.g., learning or requesting a review) can be essential for improving question clarity and facilitating better exchange. However, existing research using natural language processing techniques often overlooks these softwarespecific nuances. In this paper, we introduce <underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">S</u>oftwar<underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">E</u>-specific <underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">N</u>amed entity recognition, <underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">I</u>ntent detection, and <underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">R</u>esolution classification (SENIR), a labelling approach that leverages a Large Language Model to annotate entities, intents, and resolution status in developer chatroom conversations. To offer quantitative guidance for improving question clarity and resolvability, we build a resolution prediction model that leverages SENIR’s entity and intent labels along with additional predictive features. We evaluate SENIR on the DISCO dataset using a subset of annotated chatroom dialogues. SENIR achieves an 86% F-score for entity recognition, a 71% F-score for intent detection, and an 89% F-score for resolution status classification. Furthermore, our resolution prediction model, tested with various sampling strategies (random undersampling and oversampling with SMOTE) and evaluation methods (5-fold cross-validation, 10-fold cross-validation, and bootstrapping), demonstrates AUC values ranging from 0.7 to 0.8. Key factors influencing resolution include positive sentiment and entities such as <monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Programming Language</monospace> and <monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">User Variable</monospace> across multiple intents, while diagnostic entities (e.g., <monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Error Name</monospace>) are more relevant in error-related questions. Moreover, resolution rates vary significantly by intent: questions about <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">API Usage</i> and <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">API Change</i> achieve higher resolution rates, whereas <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Discrepancy</i> and <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Review</i> have lower resolution rates. A Chi-Square analysis confirms the statistical significance of these differences."
  },
  {
    "date": "2026-2-12",
    "title": "Game Plot Design With an LLM-Powered Assistant: An Empirical Study With Game Designers_supp1-3663566.pdf",
    "authors": "Seyed Hossein Alavi",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/tg.2026.3663566/mm1",
    "source": "IEEE",
    "abstract": ""
  },
  {
    "date": "2026-2-12",
    "title": "LLM-Guided Multi-Agent Collaboration for Complex Task Automation",
    "authors": "Vishal Bharadwaj Meruga",
    "publish": "2025 5th International Conference on Emerging Research in Electronics, Computer Science and Technology (ICERECT)",
    "url": "https://doi.org/10.1109/icerect65215.2025.11377466",
    "source": "IEEE",
    "abstract": "The combination of multi-agent systems and Large Language Models (LLMs) has become an exciting new paradigm capable of the real-time automation of complex tasks. In this paper, we introduce a framework of LLM-Guided Multi-Agent Collaboration that utilizes LLMs as high-level reasoning engines to coordinate, optimize and adjust the interactions between multiple autonomous agents. The proposed framework builds on almost zero task decomposition and intent interpretation in multitasking and resolution of conflict that is provided by the natural language understanding and decision support capability of the LLMs. Agents that have domain-specific knowledge will work in cooperation, under LLM supervision to deliver an agent-centric task execution that is scalable, explainable and adaptive. We consider the framework against the disparate domains of process automation, data-driven decision-making, and cybersecurity incident response. In the experimental results, better efficiency, resource use, and flexibility were observed in respect to dedicated multi-agent models. This paper indicates the promise that LLM-based coordination may hold to turn multi-agent collaboration into a more intelligent, context-aware, and robust paradigm of automating complex tasks in the real world."
  },
  {
    "date": "2026-2-12",
    "title": "SpinOut: Enhanced Rotation-based Quantization for LLM by Outlier Injection",
    "authors": "Sangki Park, Ki-Seok Chung",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3664084",
    "source": "IEEE",
    "abstract": "Quantization is a crucial technique for deploying Large Language Models (LLMs) in resource-constrained environments. However, minimizing performance degradation due to outliers in activation distributions remains a significant challenge, especially in low-precision quantization. Rotation-based quantization methods have emerged as promising approaches to mitigate outlier effects by transforming the distribution of weights and activations. However, existing methods either suffer from high performance variance due to random rotations or performance degradation when the calibration sample is not sufficient. In this paper, we propose SpinOut, a novel method that enhances rotation-matrix training for LLM quantization by selectively injecting outliers into outlier-sensitive layers.We introduce a method to score layer sensitivity that quantitatively measures each layer’s responsiveness to outliers using Kurtosis and performance metrics, and propose a search algorithm to determine the best subset of layers for outlier injection. By intentionally injecting artificial outliers during training, SpinOut makes rotation matrices more robust to outliers, leading to improved quantization performance. Experimental results on the Llama-2 7B and the Llama-3.2 1B/3B models demonstrate that SpinOut outperforms existing rotation-based quantization methods across various bit configurations. In the W4A4KV4 quantization setting, SpinOut achieves 0.09, 0.83, and 0.12 lower WikiText2 perplexity compared to widely-known SpinQuant, QuaRot, and AMXFP4, respectively, on Llama-2 7B. Furthermore, SpinOut reduces the required number of training samples and the iteration counts by 75% and 50% compared to SpinQuant while achieving a lower performance variance (0.23 vs. 0.3), demonstrating both efficiency and stability. Our method achieves state-of-the-art performance in most experimental settings, including W4A4KV16 quantization, and in the W4A8KV16 configuration, it even surpasses weight-only quantization methods."
  },
  {
    "date": "2026-2-12",
    "title": "LLM-Guided Multimodal Scene Captioning via Prompt-Based Fusion of Visual and Auditory Descriptions",
    "authors": "Md. Asraful Islam Khan",
    "publish": "2025 IEEE 2nd International Conference on Computing, Applications and Systems (COMPAS)",
    "url": "https://doi.org/10.1109/compas67506.2025.11381619",
    "source": "IEEE",
    "abstract": "Understanding complex scenes in real world environments often demands more than visual analysis alone it requires the integration of both visual and auditory cues. This study investigates whether prompt-based fusion using large language models (LLMs) can effectively combine modality specific outputs for zero-shot scene captioning. We propose a modular framework that leverages BLIP-2 for visual captioning, Whisper for audio transcription, and FLAN-T5 for prompt-driven fusion. To simulate multimodal caption pairs, we augment the COCO image caption dataset with text-to-speech (TTS) generated audio and incorporate filtered real-world audio-image samples. Unlike prior approaches requiring joint training or architectural modification, our pipeline operates entirely in zero-shot mode with no model retraining. Evaluation using BLEU, ROUGE-L, and cosine-based semantic similarity reveals that our fusion strategy, despite its simplicity, achieves semantically coherent captions across modalities. This work demonstrates the feasibility of LLM-guided fusion for assistive AI and offers a reproducible, low-resource solution for applications such as smart narration, AR/VR accessibility, and navigation aids for visually impaired users."
  },
  {
    "date": "2026-2-12",
    "title": "MCP-Secure: A Runtime Access Control Layer for Privilege-Aware LLM Agent Tooling",
    "authors": "Gamini Singh, Vijay K. Madisetti",
    "publish": "IEEE Open Journal of the Computer Society",
    "url": "https://doi.org/10.1109/ojcs.2026.3664314",
    "source": "IEEE",
    "abstract": "Tool-enabled language-model agents introduce new security risks because their behavior evolves over multi-step workflows, yet existing defenses primarily rely on static allowlists or infrastructure isolation. This paper presents MCP-Secure, a lightweight, host-side enforcement layer for the Model Context Protocol (MCP) that applies scoped access, read-only defaults, and approval-gated privilege elevation at runtime. MCP-Secure tracks permissions through a session-level state machine and mediates every tool invocation without modifying agents or MCP servers. We evaluate the framework across 1,080 executions spanning multiple models, tasks, and adversarial simulations. Results show that scoped access alone blocks most unsafe behaviors, read-only enforcement reliably neutralizes all mutating attack vectors, and approval-gated elevation maintains strong safety while enabling controlled write operations. Across configurations, the wrapper also shapes agent planning, reducing unsafe attempts as policies tighten. These findings demonstrate that MCP-Secure provides a practical, reproducible mechanism for enforcing least-privilege constraints in tool-enabled LLM systems, offering strong adversarial resistance with interpretable safety-utility trade-offs."
  },
  {
    "date": "2026-2-12",
    "title": "Minimizing Response Latency in LLM-Based Agent Systems: A Comprehensive Survey",
    "authors": "Gyeongmuk Park, Seonghyeon Lee, Yeonsu Park",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3664226",
    "source": "IEEE",
    "abstract": "The advent of Large Language Model (LLM)-based agent systems represents a significant paradigm shift in Artificial Intelligence, enabling unprecedented capabilities in autonomous reasoning, planning, and interaction. However, the transformative potential of these agents is fundamentally constrained by a critical operational challenge: high response latency. This latency, which impairs usability, restricts real-time applicability, and challenges economic viability, is a paramount barrier to their widespread adoption in complex, real-world scenarios. This survey provides a comprehensive and structured analysis of the multifaceted latency problem in LLM-based agent systems. We present a structured taxonomy that deconstructs end-to-end latency into its constituent sources, offering a holistic view of the entire agent stack. Our review spans four primary layers of optimization: (1) Core LLM Inference, covering techniques to accelerate the foundational model, including quantization, pruning, efficient attention mechanisms, and speculative decoding; (2) Agent-Level Frameworks, detailing strategies to refine the agent’s cognitive loop, such as accelerating planning cycles, optimizing tool use, and implementing latency-aware memory management; (3) System-Level and Infrastructure, encompassing optimizations for the underlying deployment environment, including advanced serving systems, hardware acceleration, dynamic resource allocation, and distributed architectures; and (4) Multi-Agent Systems, addressing specialized methods for mitigating communication and coordination overhead in collaborative agent ensembles. We identify key unresolved challenges and outline promising future research directions—including hardware-software co-design, novel agent architectures, and AI-driven system orchestration—to guide the ongoing quest for ultra-low latency intelligent systems."
  },
  {
    "date": "2026-2-12",
    "title": "A Dual-Mode LLM Framework for Medical and General Language Translation for Breaking Barriers in Healthcare Communication",
    "authors": "Intishar Rahman Anindo, Md. Ashiq Ul Islam Sajid, Mohammad Sakib Mahmood, Nayeyan Prottush, Md Kishor Morol",
    "publish": "2025 IEEE 2nd International Conference on Computing, Applications and Systems (COMPAS)",
    "url": "https://doi.org/10.1109/compas67506.2025.11381760",
    "source": "IEEE",
    "abstract": "Effective communication between healthcare providers and patients is frequently hindered by the complexity of medical language, contributing to misinterpretations and reduced health literacy. This study presents a robust, dual-mode translation framework powered by large language models (LLMs), combining neural architectures with rule-based safety layers to enable bidirectional translation between medical and general language. In addition to simplifying clinical language for patients, our system accurately reconstructs layperson descriptions into medically precise terms—empowering providers with clearer symptom narratives. We significantly enhance prior work by introducing domain-specific evaluation metrics (e.g., drug name preservation, dosage accuracy, ambiguity detection), conducting human-in-the-loop clinical validation, and benchmarking against specialized medical models such as MedPaLM, BioBERT, ClinicalBERT, and GPT-4 with medical prompting. Our curated dataset exceeds 60,000 annotated pairs across 15 specialties, ensuring generalizability across healthcare contexts. Clinical trials in outpatient settings demonstrate a 35% improvement in patient comprehension and high physician satisfaction (8.7/10), with zero safety incidents recorded. The system architecture supports real-world deployment via FHIR-compatible APIs and complies with regulatory frameworks such as HIPAA and FDA 510(k). These results indicate the model’s potential to meaningfully bridge the communication gap in healthcare while setting a new standard for safe, transparent, and clinically grounded AI translation tools."
  },
  {
    "date": "2026-2-12",
    "title": "Area- and Utilization-Efficient LLM Accelerator With Fused Speculative Decoding for Edge-Side Inference",
    "authors": "Kaiqi Chen, Zikang Zhou, Yaqi Chen, Jun Han",
    "publish": "IEEE Transactions on Very Large Scale Integration (VLSI) Systems",
    "url": "https://doi.org/10.1109/tvlsi.2026.3659893",
    "source": "IEEE",
    "abstract": "The inference of large language models (LLMs) on edge devices has always been a challenge, the autoregressive inference and enormous number of parameters result in long inference latency. Although speculative decoding is proposed for inference acceleration, it poses challenges for hardware accelerator design, as the differing computational characteristics of the drafting and verification stages make it difficult to optimize both chip area and hardware utilization. This brief introduces fused speculative decoding (FSD) to optimize LLM inference on edge devices by unifying all the operations to general matrix multiplications during inference. The proposed FSD-Infer algorithm fuses the drafting and verification phases of conventional speculative decoding and enables weight sharing, reducing off-chip memory access, and inference latency without requiring retraining or fine-tuning. For hardware, we introduce FSD-Acc, an area- and utilization-efficient hardware accelerator that efficiently executes the fused operations enabled by FSD-Infer. Experimental results show that compared with autoregressive inference, FSD-Infer reduces EMA by up to 26.11%, enhances arithmetic intensity by <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$10.26\\times $</tex-math> </inline-formula>, and speeds up GPU inference by up to <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$1.38\\times $</tex-math> </inline-formula>. When deployed on Xilinx ZCU102 FPGA board at 200 MHz working frequency, FSD-Acc achieves the best area efficiency and energy efficiency, outperforming the state-of-the-art LLM accelerator for edge inference by <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$2.53\\times $</tex-math> </inline-formula>(TPS/kDSP), <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$5.90\\times $</tex-math> </inline-formula>(TPS/kLUT) and <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$2.02\\times $</tex-math> </inline-formula>, respectively."
  },
  {
    "date": "2026-2-12",
    "title": "A Web-Based Blockchain Framework to Prevent Counterfeit Medicines via QR Code Verification",
    "authors": "Md. Samiul Alom, Rukaiya Taha, Sharmin Sultana Akhi, Anamika Rani Nath",
    "publish": "2025 IEEE 2nd International Conference on Computing, Applications and Systems (COMPAS)",
    "url": "https://doi.org/10.1109/compas67506.2025.11381717",
    "source": "IEEE",
    "abstract": "Counterfeit medicines continue to pose a severe global health threat, particularly in developing countries where regulatory infrastructures are often under-resourced. Existing authentication methods—such as barcodes and RFID—fall short in providing end-to-end traceability and tamper resistance. This paper presents a blockchain-powered medicine verification system that integrates QR code technology to ensure secure registration, transparent tracking, and real-time consumer validation. The proposed framework allows manufacturers to register each medicine batch on a permissioned blockchain, where metadata such as batch number, production date, expiration date, and certification ID are stored immutably. A unique QR code is generated for each registered batch and attached to the physical product. Consumers can verify product authenticity by scanning the QR code or entering its hash manually, enabling immediate access to blockchain-verified details and the detection of reused or expired products through scan count tracking. The system enhances trust, reduces health risks, and demonstrates a scalable solution for pharmaceutical supply chains, especially within resource-constrained settings like Bangladesh."
  },
  {
    "date": "2026-2-12",
    "title": "Federated Intelligence for Secure Electoral Systems: A Privacy-Enhancing Smart Voting Architecture with Decentralized Biometric Verification and Blockchain-Based Auditability",
    "authors": "Swatha J, Gopika Shree A. S., Athyul Thomas V S, Dinesh Prabu M, Mithra K, Deepika L",
    "publish": "2025 5th International Conference on Emerging Research in Electronics, Computer Science and Technology (ICERECT)",
    "url": "https://doi.org/10.1109/icerect65215.2025.11377879",
    "source": "IEEE",
    "abstract": "To address critical vulnerabilities in traditional electoral systems, including data tampering and voter impersonation, this paper introduces a novel Smart Voting System (SVS). Our architecture ensures voter privacy, security, and transparency by integrating Federated Learning (FL), Edge AI, and blockchain technology. The system is designed for low-power edge devices like the Raspberry Pi and Jetson Nano, performing all biometric verification locally to prevent raw data transmission.Our methodology employs an adaptive ensemble of facial recognition models, optimized by AutoML, which achieves up to 98.6% verification accuracy under variable lighting conditions. We integrated MediaPipe Face Mesh for robust liveness detection, successfully preventing 100% of tested spoofing attacks. The FL framework enhanced the average model accuracy from a baseline of 87% to 90.3% by aggregating encrypted model updates from edge devices, preserving user privacy while improving performance. Each verified vote is immutably recorded on a private blockchain using SHA-256 hashing, guaranteeing a transparent and tamper-proof audit trail. This work presents a comprehensive, scalable, and secure digital voting infrastructure validated through rigorous experimentation"
  }
]