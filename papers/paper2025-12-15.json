[
  {
    "date": "2018-09-03",
    "title": "Deductive Verification of Unmodified Linux Kernel Library Functions",
    "authors": "Denis Efremov, Mikhail Mandrykin, Alexey Khoroshilov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1809.00626v1",
    "source": "arXiv",
    "abstract": "This paper presents results from the development and evaluation of a deductive verification benchmark consisting of 26 unmodified Linux kernel library functions implementing conventional memory and string operations. The formal contract of the functions was extracted from their source code and was represented in the form of preconditions and postconditions. The correctness of 23 functions was completely proved using AstraVer toolset, although success for 11 functions was achieved using 2 new specification language constructs. Another 2 functions were proved after a minor modification of their source code, while the final one cannot be completely proved using the existing memory model. The benchmark can be used for the testing and evaluation of deductive verification tools and as a starting point for verifying other parts of the Linux kernel."
  },
  {
    "date": "2025-12-08",
    "title": "PRO-V-R1: Reasoning Enhanced Programming Agent for RTL Verification",
    "authors": "Yujie Zhao, Zhijing Wu, Boqin Yuan, Zhongming Yu, Hejia Zhang, Wentao Ni, Chia-Tung Ho, Haoxing Ren, Jishen Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2506.12200v4",
    "source": "arXiv",
    "abstract": "Register-Transfer Level (RTL) verification is a primary bottleneck, consuming 60-70% of development time. While Large Language Models (LLMs) show promise for RTL automation, their performance and research focus have overwhelmingly centered on RTL generation rather than verification. Current methods for RTL verification rely on large scale proprietary models (e.g., GPT-4o) to generate Python-based functional references, incurring a high cost and raising data-privacy risks. To date, an end-to-end open-source solution for autonomous verification remains absent. We introduce PRO-V-R1, the first trainable open-source agentic framework for autonomous RTL verification. Our contributions are threefold: (1) we design PRO-V sys, a modular agentic system that couples LLM-based reasoning with programmatic tool use for RTL verification; (2) we establish a data construction pipeline that leverages existing RTL datasets to build simulation-validated, expert-level trajectories tailored for supervised fine-tuning (SFT) RTL verification agents; and (3) we implement an efficient reinforcement learning (RL) algorithm that uses verification-specific rewards derived from program-tool feedback to optimize the end-to-end verification workflow. Our empirical evaluation demonstrates PRO-V-R1 achieves a 57.7% functional correctness rate and 34.0% in robust fault detection, significantly outperforming the base model's 25.7% and 21.8% (respectively) from the state-of-the-art (SOTA) automatic verification system. This configuration also outperforms large-scale proprietary LLMs in functional correctness and shows comparable robustness for fault detection."
  },
  {
    "date": "2024-07-17",
    "title": "RTL Verification for Secure Speculation Using Contract Shadow Logic",
    "authors": "Qinhan Tan, Yuheng Yang, Thomas Bourgeat, Sharad Malik, Mengjia Yan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2407.12232v1",
    "source": "arXiv",
    "abstract": "Modern out-of-order processors face speculative execution attacks. Despite various proposed software and hardware mitigations to prevent such attacks, new attacks keep arising from unknown vulnerabilities. Thus, a formal and rigorous evaluation of the ability of hardware designs to deal with speculative execution attacks is urgently desired. This paper proposes a formal verification technique called Contract Shadow Logic that can considerably improve RTL verification scalability while being applicable to different defense mechanisms. In this technique, we leverage computer architecture design insights to improve verification performance for checking security properties formulated as software-hardware contracts for secure speculation. Our verification scheme is accessible to computer architects and requires minimal formal-method expertise. We evaluate our technique on multiple RTL designs, including three out-of-order processors. The experimental results demonstrate that our technique exhibits a significant advantage in finding attacks on insecure designs and deriving complete proofs on secure designs, when compared to the baseline and two state-of-the-art verification schemes, LEAVE and UPEC."
  },
  {
    "date": "2024-09-03",
    "title": "AIvril: AI-Driven RTL Generation With Verification In-The-Loop",
    "authors": "Mubashir ul Islam, Humza Sami, Pierre-Emmanuel Gaillardon, Valerio Tenace",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2409.11411v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are computational models capable of performing complex natural language processing tasks. Leveraging these capabilities, LLMs hold the potential to transform the entire hardware design stack, with predictions suggesting that front-end and back-end tasks could be fully automated in the near future. Currently, LLMs show great promise in streamlining Register Transfer Level (RTL) generation, enhancing efficiency, and accelerating innovation. However, their probabilistic nature makes them prone to inaccuracies - a significant drawback in RTL design, where reliability and precision are essential. To address these challenges, this paper introduces AIvril, an advanced framework designed to enhance the accuracy and reliability of RTL-aware LLMs. AIvril employs a multi-agent, LLM-agnostic system for automatic syntax correction and functional verification, significantly reducing - and in many cases, completely eliminating - instances of erroneous code generation. Experimental results conducted on the VerilogEval-Human dataset show that our framework improves code quality by nearly 2x when compared to previous works, while achieving an 88.46% success rate in meeting verification objectives. This represents a critical step toward automating and optimizing hardware design workflows, offering a more dependable methodology for AI-driven RTL design."
  },
  {
    "date": "2023-09-28",
    "title": "Using LLMs to Facilitate Formal Verification of RTL",
    "authors": "Marcelo Orenes-Vera, Margaret Martonosi, David Wentzlaff",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2309.09437v2",
    "source": "arXiv",
    "abstract": "Formal property verification (FPV) has existed for decades and has been shown to be effective at finding intricate RTL bugs. However, formal properties, such as those written as SystemVerilog Assertions (SVA), are time-consuming and error-prone to write, even for experienced users. Prior work has attempted to lighten this burden by raising the abstraction level so that SVA is generated from high-level specifications. However, this does not eliminate the manual effort of reasoning and writing about the detailed hardware behavior. Motivated by the increased need for FPV in the era of heterogeneous hardware and the advances in large language models (LLMs), we set out to explore whether LLMs can capture RTL behavior and generate correct SVA properties. First, we design an FPV-based evaluation framework that measures the correctness and completeness of SVA. Then, we evaluate GPT4 iteratively to craft the set of syntax and semantic rules needed to prompt it toward creating better SVA. We extend the open-source AutoSVA framework by integrating our improved GPT4-based flow to generate safety properties, in addition to facilitating their existing flow for liveness properties. Lastly, our use cases evaluate (1) the FPV coverage of GPT4-generated SVA on complex open-source RTL and (2) using generated SVA to prompt GPT4 to create RTL from scratch. Through these experiments, we find that GPT4 can generate correct SVA even for flawed RTL, without mirroring design errors. Particularly, it generated SVA that exposed a bug in the RISC-V CVA6 core that eluded the prior work's evaluation."
  },
  {
    "date": "2025-05-14",
    "title": "AssertionForge: Enhancing Formal Verification Assertion Generation with Structured Representation of Specifications and RTL",
    "authors": "Yunsheng Bai, Ghaith Bany Hamad, Syed Suhaib, Haoxing Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2503.19174v2",
    "source": "arXiv",
    "abstract": "Generating SystemVerilog Assertions (SVAs) from natural language specifications remains a major challenge in formal verification (FV) due to the inherent ambiguity and incompleteness of specifications. Existing LLM-based approaches, such as AssertLLM, focus on extracting information solely from specification documents, often failing to capture essential internal signal interactions and design details present in the RTL code, leading to incomplete or incorrect assertions. We propose a novel approach that constructs a Knowledge Graph (KG) from both specifications and RTL, using a hardware-specific schema with domain-specific entity and relation types. We create an initial KG from the specification and then systematically fuse it with information extracted from the RTL code, resulting in a unified, comprehensive KG. This combined representation enables a more thorough understanding of the design and allows for a multi-resolution context synthesis process which is designed to extract diverse verification contexts from the KG. Experiments on four designs demonstrate that our method significantly enhances SVA quality over prior methods. This structured representation not only improves FV but also paves the way for future research in tasks like code generation and design understanding."
  },
  {
    "date": "2007-10-25",
    "title": "Common Reusable Verification Environment for BCA and RTL Models",
    "authors": "Giuseppe Falconeri, Walid Naifer, Nizar Romdhane",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/0710.4851v1",
    "source": "arXiv",
    "abstract": "This paper deals with a common verification methodology and environment for SystemC BCA and RTL models. The aim is to save effort by avoiding the same work done twice by different people and to reuse the same environment for the two design views. Applying this methodology the verification task starts as soon as the functional specification is signed off and it runs in parallel to the models and design development. The verification environment is modeled with the aid of dedicated verification languages and it is applied to both the models. The test suite is exactly the same and thus it's possible to verify the alignment between the two models. In fact the final step is to check the cycle-by-cycle match of the interface behavior. A regression tool and a bus analyzer have been developed to help the verification and the alignment process. The former is used to automate the testbench generation and to run the two test suites. The latter is used to verify the alignment between the two models comparing the waveforms obtained in each run. The quality metrics used to validate the flow are full functional coverage and full alignment at each IP port."
  },
  {
    "date": "2020-09-29",
    "title": "Formal Verification of Arithmetic RTL: Translating Verilog to C++ to ACL2",
    "authors": "David M. Russinoff",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2009.13761v1",
    "source": "arXiv",
    "abstract": "We present a methodology for formal verification of arithmetic RTL designs that combines sequential logic equivalence checking with interactive theorem proving. An intermediate model of a Verilog module is hand-coded in Restricted Algorithmic C (RAC), a primitive subset of C augmented by the integer and fixed-point register class templates of Algorithmic C. The model is designed to be as abstract and compact as possible, but sufficiently faithful to the RTL to allow efficient equivalence checking with a commercial tool. It is then automatically translated to the logic of ACL2, enabling a mechanically checked proof of correctness with respect to a formal architectural specification. In this paper, we describe the RAC language, the translation process, and some techniques that facilitate formal analysis of the resulting ACL2 code."
  },
  {
    "date": "2014-08-06",
    "title": "Early Development of UVM based Verification Environment of Image Signal Processing Designs using TLM Reference Model of RTL",
    "authors": "Abhishek Jain, Dr. Hima Gupta, Sandeep Jana, Krishna Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1408.1150v1",
    "source": "arXiv",
    "abstract": "With semiconductor industry trend of smaller the better, from an idea to a final product, more innovation on product portfolio and yet remaining competitive and profitable are few criteria which are culminating into pressure and need for more and more innovation for CAD flow, process management and project execution cycle. Project schedules are very tight and to achieve first silicon success is key for projects. This necessitates quicker verification with better coverage matrix. Quicker Verification requires early development of the verification environment with wider test vectors without waiting for RTL to be available. In this paper, we are presenting a novel approach of early development of reusable multi-language verification flow, by addressing four major activities of verification like Early creation of Executable Specification, Early creation of Verification Environment, Early development of test vectors and Better and increased Re-use of blocks. Although this paper focuses on early development of UVM based Verification Environment of Image Signal Processing designs using TLM Reference Model of RTL, same concept can be extended for non-image signal processing designs. Main Keywords are SystemVerilog, SystemC, Transaction Level Modeling, Universal Verification Methodology (UVM), Processor model, Universal Verification Component (UVC), Reference Model."
  },
  {
    "date": "2024-05-31",
    "title": "Towards LLM-Powered Verilog RTL Assistant: Self-Verification and Self-Correction",
    "authors": "Hanxian Huang, Zhenghan Lin, Zixuan Wang, Xin Chen, Ke Ding, Jishen Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2406.00115v1",
    "source": "arXiv",
    "abstract": "We explore the use of Large Language Models (LLMs) to generate high-quality Register-Transfer Level (RTL) code with minimal human interference. The traditional RTL design workflow requires human experts to manually write high-quality RTL code, which is time-consuming and error-prone. With the help of emerging LLMs, developers can describe their requirements to LLMs which then generate corresponding code in Python, C, Java, and more. Adopting LLMs to generate RTL design in hardware description languages is not trivial, given the complex nature of hardware design and the generated design has to meet the timing and physical constraints. We propose VeriAssist, an LLM-powered programming assistant for Verilog RTL design workflow. VeriAssist takes RTL design descriptions as input and generates high-quality RTL code with corresponding test benches. VeriAssist enables the LLM to self-correct and self-verify the generated code by adopting an automatic prompting system and integrating RTL simulator in the code generation loop. To generate an RTL design, VeriAssist first generates the initial RTL code and corresponding test benches, followed by a self-verification step that walks through the code with test cases to reason the code behavior at different time steps, and finally it self-corrects the code by reading the compilation and simulation results and generating final RTL code that fixes errors in compilation and simulation. This design fully leverages the LLMs' capabilities on multi-turn interaction and chain-of-thought reasoning to improve the quality of the generated code. We evaluate VeriAssist with various benchmark suites and find it significantly improves both syntax and functionality correctness over existing LLM implementations, thus minimizing human intervention and making RTL design more accessible to novice designers."
  },
  {
    "date": "2021-04-08",
    "title": "AutoSVA: Democratizing Formal Verification of RTL Module Interactions",
    "authors": "Marcelo Orenes-Vera, Aninda Manocha, David Wentzlaff, Margaret Martonosi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2104.04003v1",
    "source": "arXiv",
    "abstract": "Modern SoC design relies on the ability to separately verify IP blocks relative to their own specifications. Formal verification (FV) using SystemVerilog Assertions (SVA) is an effective method to exhaustively verify blocks at unit-level. Unfortunately, FV has a steep learning curve and requires engineering effort that discourages hardware designers from using it during RTL module development. We propose AutoSVA, a framework to automatically generate FV testbenches that verify liveness and safety of control logic involved in module interactions. We demonstrate AutoSVA's effectiveness and efficiency on deadlock-critical modules of widely-used open-source hardware projects."
  },
  {
    "date": "2024-07-26",
    "title": "VeriCHERI: Exhaustive Formal Security Verification of CHERI at the RTL",
    "authors": "Anna Lena Duque Antón, Johannes Müller, Philipp Schmitz, Tobias Jauch, Alex Wezel, Lucas Deutschmann, Mohammad Rahmani Fadiheh, Dominik Stoffel, Wolfgang Kunz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2407.18679v1",
    "source": "arXiv",
    "abstract": "Protecting data in memory from attackers continues to be a concern in computing systems. CHERI is a promising approach to achieve such protection, by providing and enforcing fine-grained memory protection directly in the hardware. Creating trust for the entire system stack, however, requires a gap-free verification of CHERI's hardware-based protection mechanisms. Existing verification methods for CHERI target the abstract ISA model rather than the underlying hardware implementation. Fully ensuring the CHERI security guarantees for a concrete RTL implementation is a challenge in previous flows and demands high manual efforts. This paper presents VeriCHERI, a novel approach to security verification. It is conceptionally different from previous works in that it does not require any ISA specification. Instead of checking compliance with a golden ISA model, we check against well-established global security objectives of confidentiality and integrity. Fully covering these objectives, VeriCHERI uses as few as four unbounded properties to exhaustively prove or disprove any vulnerability. We demonstrate the effectiveness and scalability of VeriCHERI on a RISC-V based processor implementing a CHERI variant."
  },
  {
    "date": "2019-01-23",
    "title": "Partial Verification as a Substitute for Money",
    "authors": "Sofia Ceppi, Ian Kash, Rafael Frongillo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1812.07312v2",
    "source": "arXiv",
    "abstract": "Recent work shows that we can use partial verification instead of money to implement truthful mechanisms. In this paper we develop tools to answer the following question. Given an allocation rule that can be made truthful with payments, what is the minimal verification needed to make it truthful without them? Our techniques leverage the geometric relationship between the type space and the set of possible allocations."
  },
  {
    "date": "2025-06-17",
    "title": "Comprehensive Verilog Design Problems: A Next-Generation Benchmark Dataset for Evaluating Large Language Models and Agents on RTL Design and Verification",
    "authors": "Nathaniel Pinckney, Chenhui Deng, Chia-Tung Ho, Yun-Da Tsai, Mingjie Liu, Wenfei Zhou, Brucek Khailany, Haoxing Ren",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2506.14074v1",
    "source": "arXiv",
    "abstract": "We present the Comprehensive Verilog Design Problems (CVDP) benchmark, a new dataset and infrastructure to advance LLM and agent research in hardware design and verification. CVDP includes 783 problems across 13 task categories, covering RTL generation, verification, debugging, specification alignment, and technical Q&A authored by experienced hardware engineers. Problems are offered in both non-agentic and agentic formats. The benchmark introduces more realistic and challenging contexts than prior work, with state-of-the-art models achieving no more than 34% pass@1 on code generation. Agentic tasks$\\unicode{x2013}$especially those involving RTL reuse and verification$\\unicode{x2013}$are particularly difficult. Evaluation uses open-source tools and model scoring infrastructure, with comprehension tasks assessed via BLEU and LLM-based judging. CVDP reveals substantial gaps in current model capabilities, underscoring the need for continued research toward robust, real-world hardware design automation."
  },
  {
    "date": "2024-11-25",
    "title": "UVLLM: An Automated Universal RTL Verification Framework using LLMs",
    "authors": "Yuchen Hu, Junhao Ye, Ke Xu, Jialin Sun, Shiyue Zhang, Xinyao Jiao, Dingrong Pan, Jie Zhou, Ning Wang, Weiwei Shan, Xinwei Fang, Xi Wang, Nan Guan, Zhe Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2411.16238v1",
    "source": "arXiv",
    "abstract": "Verifying hardware designs in embedded systems is crucial but often labor-intensive and time-consuming. While existing solutions have improved automation, they frequently rely on unrealistic assumptions. To address these challenges, we introduce a novel framework, UVLLM, which combines Large Language Models (LLMs) with the Universal Verification Methodology (UVM) to relax these assumptions. UVLLM significantly enhances the automation of testing and repairing error-prone Register Transfer Level (RTL) codes, a critical aspect of verification development. Unlike existing methods, UVLLM ensures that all errors are triggered during verification, achieving a syntax error fix rate of 86.99% and a functional error fix rate of 71.92% on our proposed benchmark. These results demonstrate a substantial improvement in verification efficiency. Additionally, our study highlights the current limitations of LLM applications, particularly their reliance on extensive training data. We emphasize the transformative potential of LLMs in hardware design verification and suggest promising directions for future research in AI-driven hardware design methodologies. The Repo. of dataset and code: https://anonymous.4open.science/r/UVLLM/."
  },
  {
    "date": "2025-03-19",
    "title": "OpenLLM-RTL: Open Dataset and Benchmark for LLM-Aided Design RTL Generation",
    "authors": "Shang Liu, Yao Lu, Wenji Fang, Mengming Li, Zhiyao Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2503.15112v1",
    "source": "arXiv",
    "abstract": "The automated generation of design RTL based on large language model (LLM) and natural language instructions has demonstrated great potential in agile circuit design. However, the lack of datasets and benchmarks in the public domain prevents the development and fair evaluation of LLM solutions. This paper highlights our latest advances in open datasets and benchmarks from three perspectives: (1) RTLLM 2.0, an updated benchmark assessing LLM's capability in design RTL generation. The benchmark is augmented to 50 hand-crafted designs. Each design provides the design description, test cases, and a correct RTL code. (2) AssertEval, an open-source benchmark assessing the LLM's assertion generation capabilities for RTL verification. The benchmark includes 18 designs, each providing specification, signal definition, and correct RTL code. (3) RTLCoder-Data, an extended open-source dataset with 80K instruction-code data samples. Moreover, we propose a new verification-based method to verify the functionality correctness of training data samples. Based on this technique, we further release a dataset with 7K verified high-quality samples. These three studies are integrated into one framework, providing off-the-shelf support for the development and evaluation of LLMs for RTL code generation and verification. Finally, extensive experiments indicate that LLM performance can be boosted by enlarging the training dataset, improving data quality, and improving the training scheme."
  },
  {
    "date": "2006-09-29",
    "title": "Verification, Validation and Integrity of Distributed and Interchanged Rule Based Policies and Contracts in the Semantic Web",
    "authors": "Adrian Paschke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/cs/0609119v2",
    "source": "arXiv",
    "abstract": "Rule-based policy and contract systems have rarely been studied in terms of their software engineering properties. This is a serious omission, because in rule-based policy or contract representation languages rules are being used as a declarative programming language to formalize real-world decision logic and create IS production systems upon. This paper adopts an SE methodology from extreme programming, namely test driven development, and discusses how it can be adapted to verification, validation and integrity testing (V&V&I) of policy and contract specifications. Since, the test-driven approach focuses on the behavioral aspects and the drawn conclusions instead of the structure of the rule base and the causes of faults, it is independent of the complexity of the rule language and the system under test and thus much easier to use and understand for the rule engineer and the user."
  },
  {
    "date": "2025-08-20",
    "title": "From Concept to Practice: an Automated LLM-aided UVM Machine for RTL Verification",
    "authors": "Junhao Ye, Yuchen Hu, Ke Xu, Dingrong Pan, Qichun Chen, Jie Zhou, Shuai Zhao, Xinwei Fang, Xi Wang, Nan Guan, Zhe Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2504.19959v3",
    "source": "arXiv",
    "abstract": "Verification presents a major bottleneck in Integrated Circuit (IC) development, consuming nearly 70% of the total development effort. While the Universal Verification Methodology (UVM) is widely used in industry to improve verification efficiency through structured and reusable testbenches, constructing these testbenches and generating sufficient stimuli remain challenging. These challenges arise from the considerable manual coding effort required, repetitive manual execution of multiple EDA tools, and the need for in-depth domain expertise to navigate complex designs.Here, we present UVM^2, an automated verification framework that leverages Large Language Models (LLMs) to generate UVM testbenches and iteratively refine them using coverage feedback, significantly reducing manual effort while maintaining rigorous verification standards.To evaluate UVM^2, we introduce a benchmark suite comprising Register Transfer Level (RTL) designs of up to 1.6K lines of code.The results show that UVM^2 reduces testbench setup time by up to UVM^2 compared to experienced engineers, and achieve average code and function coverage of 87.44% and 89.58%, outperforming state-of-the-art solutions by 20.96% and 23.51%, respectively."
  },
  {
    "date": "2015-09-16",
    "title": "Coverage-Driven Verification - An approach to verify code for robots that directly interact with humans",
    "authors": "Dejanira Araiza-Illan, David Western, Anthony Pipe, Kerstin Eder",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1509.04852v1",
    "source": "arXiv",
    "abstract": "Collaborative robots could transform several industries, such as manufacturing and healthcare, but they present a significant challenge to verification. The complex nature of their working environment necessitates testing in realistic detail under a broad range of circumstances. We propose the use of Coverage-Driven Verification (CDV) to meet this challenge. By automating the simulation-based testing process as far as possible, CDV provides an efficient route to coverage closure. We discuss the need, practical considerations, and potential benefits of transferring this approach from microelectronic design verification to the field of human-robot interaction. We demonstrate the validity and feasibility of the proposed approach by constructing a custom CDV testbench and applying it to the verification of an object handover task."
  },
  {
    "date": "2020-12-01",
    "title": "Towards Probabilistic Verification of Machine Unlearning",
    "authors": "David Marco Sommer, Liwei Song, Sameer Wagh, Prateek Mittal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2003.04247v2",
    "source": "arXiv",
    "abstract": "The right to be forgotten, also known as the right to erasure, is the right of individuals to have their data erased from an entity storing it. The status of this long held notion was legally solidified recently by the General Data Protection Regulation (GDPR) in the European Union. Consequently, there is a need for mechanisms whereby users can verify if service providers comply with their deletion requests. In this work, we take the first step in proposing a formal framework to study the design of such verification mechanisms for data deletion requests -- also known as machine unlearning -- in the context of systems that provide machine learning as a service (MLaaS). Our framework allows the rigorous quantification of any verification mechanism based on standard hypothesis testing. Furthermore, we propose a novel backdoor-based verification mechanism and demonstrate its effectiveness in certifying data deletion with high confidence, thus providing a basis for quantitatively inferring machine unlearning. We evaluate our approach over a range of network architectures such as multi-layer perceptrons (MLP), convolutional neural networks (CNN), residual networks (ResNet), and long short-term memory (LSTM), as well as over 5 different datasets. We demonstrate that our approach has minimal effect on the ML service's accuracy but provides high confidence verification of unlearning. Our proposed mechanism works even if only a handful of users employ our system to ascertain compliance with data deletion requests. In particular, with just 5% of users participating, modifying half their data with a backdoor, and with merely 30 test queries, our verification mechanism has both false positive and false negative ratios below $10^{-3}$. We also show the effectiveness of our approach by testing it against an adaptive adversary that uses a state-of-the-art backdoor defense method."
  },
  {
    "date": "2024-11-02",
    "title": "AMREx: AMR for Explainable Fact Verification",
    "authors": "Chathuri Jayaweera, Sangpil Youm, Bonnie Dorr",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2411.01343v1",
    "source": "arXiv",
    "abstract": "With the advent of social media networks and the vast amount of information circulating through them, automatic fact verification is an essential component to prevent the spread of misinformation. It is even more useful to have fact verification systems that provide explanations along with their classifications to ensure accurate predictions. To address both of these requirements, we implement AMREx, an Abstract Meaning Representation (AMR)-based veracity prediction and explanation system for fact verification using a combination of Smatch, an AMR evaluation metric to measure meaning containment and textual similarity, and demonstrate its effectiveness in producing partially explainable justifications using two community standard fact verification datasets, FEVER and AVeriTeC. AMREx surpasses the AVeriTec baseline accuracy showing the effectiveness of our approach for real-world claim verification. It follows an interpretable pipeline and returns an explainable AMR node mapping to clarify the system's veracity predictions when applicable. We further demonstrate that AMREx output can be used to prompt LLMs to generate natural-language explanations using the AMR mappings as a guide to lessen the probability of hallucinations."
  },
  {
    "date": "2022-10-14",
    "title": "Zonotope Domains for Lagrangian Neural Network Verification",
    "authors": "Matt Jordan, Jonathan Hayase, Alexandros G. Dimakis, Sewoong Oh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2210.08069v1",
    "source": "arXiv",
    "abstract": "Neural network verification aims to provide provable bounds for the output of a neural network for a given input range. Notable prior works in this domain have either generated bounds using abstract domains, which preserve some dependency between intermediate neurons in the network; or framed verification as an optimization problem and solved a relaxation using Lagrangian methods. A key drawback of the latter technique is that each neuron is treated independently, thereby ignoring important neuron interactions. We provide an approach that merges these two threads and uses zonotopes within a Lagrangian decomposition. Crucially, we can decompose the problem of verifying a deep neural network into the verification of many 2-layer neural networks. While each of these problems is provably hard, we provide efficient relaxation methods that are amenable to efficient dual ascent procedures. Our technique yields bounds that improve upon both linear programming and Lagrangian-based verification techniques in both time and bound tightness."
  },
  {
    "date": "2020-06-20",
    "title": "fault: A Python Embedded Domain-Specific Language For Metaprogramming Portable Hardware Verification Components",
    "authors": "Lenny Truong, Steven Herbst, Rajsekhar Setaluri, Makai Mann, Ross Daly, Keyi Zhang, Caleb Donovick, Daniel Stanley, Mark Horowitz, Clark Barrett, Pat Hanrahan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2006.11669v1",
    "source": "arXiv",
    "abstract": "While hardware generators have drastically improved design productivity, they have introduced new challenges for the task of verification. To effectively cover the functionality of a sophisticated generator, verification engineers require tools that provide the flexibility of metaprogramming. However, flexibility alone is not enough; components must also be portable in order to encourage the proliferation of verification libraries as well as enable new methodologies. This paper introduces fault, a Python embedded hardware verification language that aims to empower design teams to realize the full potential of generators."
  },
  {
    "date": "2018-12-14",
    "title": "Specification-Guided Safety Verification for Feedforward Neural Networks",
    "authors": "Weiming Xiang, Hoang-Dung Tran, Taylor T. Johnson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1812.06161v1",
    "source": "arXiv",
    "abstract": "This paper presents a specification-guided safety verification method for feedforward neural networks with general activation functions. As such feedforward networks are memoryless, they can be abstractly represented as mathematical functions, and the reachability analysis of the neural network amounts to interval analysis problems. In the framework of interval analysis, a computationally efficient formula which can quickly compute the output interval sets of a neural network is developed. Then, a specification-guided reachability algorithm is developed. Specifically, the bisection process in the verification algorithm is completely guided by a given safety specification. Due to the employment of the safety specification, unnecessary computations are avoided and thus the computational cost can be reduced significantly. Experiments show that the proposed method enjoys much more efficiency in safety verification with significantly less computational cost."
  },
  {
    "date": "2020-07-19",
    "title": "Optimal verification of stabilizer states",
    "authors": "Ninnat Dangniam, Yun-Guang Han, Huangjun Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2007.09713v1",
    "source": "arXiv",
    "abstract": "Statistical verification of a quantum state aims to certify whether a given unknown state is close to the target state with confidence. So far, sample-optimal verification protocols based on local measurements have been found only for disparate groups of states: bipartite pure states, GHZ states, and antisymmetric basis states. In this work, we investigate systematically optimal verification of entangled stabilizer states using Pauli measurements. First, we provide a lower bound on the sample complexity of any verification protocol based on separable measurements, which is independent of the number of qubits and the specific stabilizer state. Then we propose a simple algorithm for constructing optimal protocols based on Pauli measurements. Our calculations suggest that optimal protocols based on Pauli measurements can saturate the above bound for all entangled stabilizer states, and this claim is verified explicitly for states up to seven qubits. Similar results are derived when each party can choose only two measurement settings, say X and Z. Furthermore, by virtue of the chromatic number, we provide an upper bound for the minimum number of settings required to verify any graph state, which is expected to be tight. For experimentalists, optimal protocols and protocols with the minimum number of settings are explicitly provided for all equivalent classes of stabilizer states up to seven qubits. For theorists, general results on stabilizer states (including graph states in particular) and related structures derived here may be of independent interest beyond quantum state verification."
  },
  {
    "date": "2025-05-11",
    "title": "RTL++: Graph-enhanced LLM for RTL Code Generation",
    "authors": "Mohammad Akyash, Kimia Azar, Hadi Kamali",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2505.13479v1",
    "source": "arXiv",
    "abstract": "As hardware design complexity escalates, there is an urgent need for advanced automation in electronic design automation (EDA). Traditional register transfer level (RTL) design methods are manual, time-consuming, and prone to errors. While commercial (instruction-tuned) large language models (LLMs) shows promising performance for automation, they pose security and privacy concerns. Open-source models offer alternatives; however, they frequently fall short in quality/correctness, largely due to limited, high-quality RTL code data essential for effective training and generalization. This paper proposes RTL++, a first-of-its-kind LLM-assisted method for RTL code generation that utilizes graph representations of code structures to enhance the quality of generated code. By encoding RTL code into a textualized control flowgraphs (CFG) and data flow graphs (DFG), RTL++ captures the inherent hierarchy, dependencies, and relationships within the code. This structured graph-based approach enhances the context available to LLMs, enabling them to better understand and generate instructions. By focusing on data generation through graph representations, RTL++ addresses the limitations of previous approaches that rely solely on code and suffer from lack of diversity. Experimental results demonstrate that RTL++ outperforms state-of-the-art models fine-tuned for RTL generation, as evaluated using the VerilogEval benchmark's Pass@1/5/10 metric, as well as the RTLLM1.1 model, which highlight the effectiveness of graph-enhanced context in advancing the capabilities of LLM-assisted RTL code generation."
  },
  {
    "date": "2024-05-27",
    "title": "RTL-Repo: A Benchmark for Evaluating LLMs on Large-Scale RTL Design Projects",
    "authors": "Ahmed Allam, Mohamed Shalan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2405.17378v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated potential in assisting with Register Transfer Level (RTL) design tasks. Nevertheless, there remains to be a significant gap in benchmarks that accurately reflect the complexity of real-world RTL projects. To address this, this paper presents RTL-Repo, a benchmark specifically designed to evaluate LLMs on large-scale RTL design projects. RTL-Repo includes a comprehensive dataset of more than 4000 Verilog code samples extracted from public GitHub repositories, with each sample providing the full context of the corresponding repository. We evaluate several state-of-the-art models on the RTL-Repo benchmark, including GPT-4, GPT-3.5, Starcoder2, alongside Verilog-specific models like VeriGen and RTLCoder, and compare their performance in generating Verilog code for complex projects. The RTL-Repo benchmark provides a valuable resource for the hardware design community to assess and compare LLMs' performance in real-world RTL design scenarios and train LLMs specifically for Verilog code generation in complex, multi-file RTL projects. RTL-Repo is open-source and publicly available on Github."
  },
  {
    "date": "2025-11-17",
    "title": "Think with Self-Decoupling and Self-Verification: Automated RTL Design with Backtrack-ToT",
    "authors": "Zhiteng Chao, Yonghao Wang, Xinyu Zhang, Jiaxin Zhou, Tenghui Hua, Husheng Han, Tianmeng Yang, Jianan Mu, Bei Yu, Rui Zhang, Jing Ye, Huawei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.13139v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) hold promise for automating integrated circuit (IC) engineering using register transfer level (RTL) hardware description languages (HDLs) like Verilog. However, challenges remain in ensuring the quality of Verilog generation. Complex designs often fail in a single generation due to the lack of targeted decoupling strategies, and evaluating the correctness of decoupled sub-tasks remains difficult. While the chain-of-thought (CoT) method is commonly used to improve LLM reasoning, it has been largely ineffective in automating IC design workflows, requiring manual intervention. The key issue is controlling CoT reasoning direction and step granularity, which do not align with expert RTL design knowledge. This paper introduces VeriBToT, a specialized LLM reasoning paradigm for automated Verilog generation. By integrating Top-down and design-for-verification (DFV) approaches, VeriBToT achieves self-decoupling and self-verification of intermediate steps, constructing a Backtrack Tree of Thought with formal operators. Compared to traditional CoT paradigms, our approach enhances Verilog generation while optimizing token costs through flexible modularity, hierarchy, and reusability."
  },
  {
    "date": "2024-08-16",
    "title": "Case Study: Runtime Safety Verification of Neural Network Controlled System",
    "authors": "Frank Yang, Sinong Simon Zhan, Yixuan Wang, Chao Huang, Qi Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2408.08592v1",
    "source": "arXiv",
    "abstract": "Neural networks are increasingly used in safety-critical applications such as robotics and autonomous vehicles. However, the deployment of neural-network-controlled systems (NNCSs) raises significant safety concerns. Many recent advances overlook critical aspects of verifying control and ensuring safety in real-time scenarios. This paper presents a case study on using POLAR-Express, a state-of-the-art NNCS reachability analysis tool, for runtime safety verification in a Turtlebot navigation system using LiDAR. The Turtlebot, equipped with a neural network controller for steering, operates in a complex environment with obstacles. We developed a safe online controller switching strategy that switches between the original NNCS controller and an obstacle avoidance controller based on the verification results. Our experiments, conducted in a ROS2 Flatland simulation environment, explore the capabilities and limitations of using POLAR-Express for runtime verification and demonstrate the effectiveness of our switching strategy."
  },
  {
    "date": "2024-05-31",
    "title": "Verification of Neural Network Control Systems in Continuous Time",
    "authors": "Ali ArjomandBigdeli, Andrew Mata, Stanley Bak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2406.00157v1",
    "source": "arXiv",
    "abstract": "Neural network controllers are currently being proposed for use in many safety-critical tasks. Most analysis methods for neural network control systems assume a fixed control period. In control theory, higher frequency usually improves performance. However, for current analysis methods, increasing the frequency complicates verification. In the limit, when actuation is performed continuously, no existing neural network control systems verification methods are able to analyze the system. In this work, we develop the first verification method for continuously-actuated neural network control systems. We accomplish this by adding a level of abstraction to model the neural network controller. The abstraction is a piecewise linear model with added noise to account for local linearization error. The soundness of the abstraction can be checked using open-loop neural network verification tools, although we demonstrate bottlenecks in existing tools when handling the required specifications. We demonstrate the approach's efficacy by applying it to a vision-based autonomous airplane taxiing system and compare with a fixed frequency analysis baseline."
  },
  {
    "date": "2013-07-12",
    "title": "Parameterized Verification of Asynchronous Shared-Memory Systems",
    "authors": "Javier Esparza, Pierre Ganty, Rupak Majumdar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1304.1185v2",
    "source": "arXiv",
    "abstract": "We characterize the complexity of the safety verification problem for parameterized systems consisting of a leader process and arbitrarily many anonymous and identical contributors. Processes communicate through a shared, bounded-value register. While each operation on the register is atomic, there is no synchronization primitive to execute a sequence of operations atomically. We analyze the complexity of the safety verification problem when processes are modeled by finite-state machines, pushdown machines, and Turing machines. The problem is coNP-complete when all processes are finite-state machines, and is PSPACE-complete when they are pushdown machines. The complexity remains coNP-complete when each Turing machine is allowed boundedly many interactions with the register. Our proofs use combinatorial characterizations of computations in the model, and in case of pushdown-systems, some language-theoretic constructions of independent interest."
  },
  {
    "date": "2025-01-06",
    "title": "RTLSquad: Multi-Agent Based Interpretable RTL Design",
    "authors": "Bowei Wang, Qi Xiong, Zeqing Xiang, Lei Wang, Renzhi Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2501.05470v1",
    "source": "arXiv",
    "abstract": "Optimizing Register-Transfer Level (RTL) code is crucial for improving hardware PPA performance. Large Language Models (LLMs) offer new approaches for automatic RTL code generation and optimization. However, existing methods often lack decision interpretability (sufficient, understandable justification for decisions), making it difficult for hardware engineers to trust the generated results, thus preventing these methods from being integrated into the design process. To address this, we propose RTLSquad, a novel LLM-Based Multi-Agent system for interpretable RTL code generation. RTLSquad divides the design process into exploration, implementation, and verification & evaluation stages managed by specialized agent squads, generating optimized RTL code through inter-agent collaboration, and providing decision interpretability through the communication process. Experiments show that RTLSquad excels in generating functionally correct RTL code and optimizing PPA performance, while also having the capability to provide decision paths, demonstrating the practical value of our system."
  },
  {
    "date": "2024-04-02",
    "title": "Unifying Qualitative and Quantitative Safety Verification of DNN-Controlled Systems",
    "authors": "Dapeng Zhi, Peixin Wang, Si Liu, Luke Ong, Min Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2404.01769v1",
    "source": "arXiv",
    "abstract": "The rapid advance of deep reinforcement learning techniques enables the oversight of safety-critical systems through the utilization of Deep Neural Networks (DNNs). This underscores the pressing need to promptly establish certified safety guarantees for such DNN-controlled systems. Most of the existing verification approaches rely on qualitative approaches, predominantly employing reachability analysis. However, qualitative verification proves inadequate for DNN-controlled systems as their behaviors exhibit stochastic tendencies when operating in open and adversarial environments. In this paper, we propose a novel framework for unifying both qualitative and quantitative safety verification problems of DNN-controlled systems. This is achieved by formulating the verification tasks as the synthesis of valid neural barrier certificates (NBCs). Initially, the framework seeks to establish almost-sure safety guarantees through qualitative verification. In cases where qualitative verification fails, our quantitative verification method is invoked, yielding precise lower and upper bounds on probabilistic safety across both infinite and finite time horizons. To facilitate the synthesis of NBCs, we introduce their $k$-inductive variants. We also devise a simulation-guided approach for training NBCs, aiming to achieve tightness in computing precise certified lower and upper bounds. We prototype our approach into a tool called $\\textsf{UniQQ}$ and showcase its efficacy on four classic DNN-controlled systems."
  },
  {
    "date": "2013-04-05",
    "title": "Verification of Artifact-Centric Systems: Decidability and Modeling Issues",
    "authors": "Dmitry Solomakhin, Marco Montali, Sergio Tessaris, Riccardo De Masellis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1304.1697v1",
    "source": "arXiv",
    "abstract": "Artifact-centric business processes have recently emerged as an approach in which processes are centred around the evolution of business entities, called artifacts, giving equal importance to control-flow and data. The recent Guard-State-Milestone (GSM) approach provides means for specifying business artifacts lifecycles in a declarative manner, using constructs that match how executive-level stakeholders think about their business. However, it turns out that formal verification of GSM is undecidable even for very simple propositional temporal properties. We attack this challenging problem by translating GSM into a well-studied formal framework. We exploit this translation to isolate an interesting class of state-bounded GSM models for which verification of sophisticated temporal properties is decidable. We then introduce some guidelines to turn an arbitrary GSM model into a state-bounded, verifiable model."
  },
  {
    "date": "2022-05-29",
    "title": "Verification of colorable hypergraph states with stabilizer test",
    "authors": "Hong Tao, Xiaoqian Zhang, Lei Shao, Xiaoqing Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2203.09989v2",
    "source": "arXiv",
    "abstract": "Many-body quantum states, as a matter of fact, are extremely essential to solve certain mathematical problems or simulate quantum systems in measurement-based quantum computation. However, how to verify large scale quantum states, such as hypergraph states, is an exceedingly hard task for multi-body quantum systems. Here, we propose a novel fault-tolerant solution for verification of colorable hypergraph states by using stabilizer test. Compared with the adaptive stabilizer test, our protocol is dramatically facilitating by making only Pauli-X and Pauli-Z measurement. As to appliance, it will be also applied to blind quantum computing."
  },
  {
    "date": "2013-01-30",
    "title": "A Framework for the Verification of Certifying Computations",
    "authors": "Eyad Alkassar, Sascha Böhme, Kurt Mehlhorn, Christine Rizkallah",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1301.7462v1",
    "source": "arXiv",
    "abstract": "Formal verification of complex algorithms is challenging. Verifying their implementations goes beyond the state of the art of current automatic verification tools and usually involves intricate mathematical theorems. Certifying algorithms compute in addition to each output a witness certifying that the output is correct. A checker for such a witness is usually much simpler than the original algorithm - yet it is all the user has to trust. The verification of checkers is feasible with current tools and leads to computations that can be completely trusted. We describe a framework to seamlessly verify certifying computations. We use the automatic verifier VCC for establishing the correctness of the checker and the interactive theorem prover Isabelle/HOL for high-level mathematical properties of algorithms. We demonstrate the effectiveness of our approach by presenting the verification of typical examples of the industrial-level and widespread algorithmic library LEDA."
  },
  {
    "date": "2025-10-09",
    "title": "Faver: Boosting LLM-based RTL Generation with Function Abstracted Verifiable Middleware",
    "authors": "Jianan Mu, Mingyu Shi, Yining Wang, Tianmeng Yang, Bin Sun, Xing Hu, Jing Ye, Huawei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2510.08664v1",
    "source": "arXiv",
    "abstract": "LLM-based RTL generation is an interesting research direction, as it holds the potential to liberate the least automated stage in the current chip design. However, due to the substantial semantic gap between high-level specifications and RTL, coupled with limited training data, existing models struggle with generation accuracy. Drawing on human experience, design with verification helps improving accuracy. However, as the RTL testbench data are even more scarce, it is not friendly for LLMs. Although LLMs excel at higher-level languages like Python/C, they have a huge semantic gap from RTL. When implementing the same functionality, Python/C code and hardware code differ significantly in the spatiotemporal granularity, requiring the LLM not only to consider high-level functional semantics but also to ensure the low-level details align with the circuit code. It is not an easy task. In this paper, we propose a function abstracted verifiable middleware (Faver) that streamlines RTL verification in LLM-based workflows. By mixing LLM-friendly code structures with a rule-based template, Faver decouples the details of circuit verification, allowing the LLM to focus on the functionality itself. In our experiments on the SFT model and open-source models, Faver improved the model's generation accuracy by up to 14%."
  },
  {
    "date": "2024-12-10",
    "title": "MAGE: A Multi-Agent Engine for Automated RTL Code Generation",
    "authors": "Yujie Zhao, Hejia Zhang, Hanxian Huang, Zhongming Yu, Jishen Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2412.07822v1",
    "source": "arXiv",
    "abstract": "The automatic generation of RTL code (e.g., Verilog) through natural language instructions has emerged as a promising direction with the advancement of large language models (LLMs). However, producing RTL code that is both syntactically and functionally correct remains a significant challenge. Existing single-LLM-agent approaches face substantial limitations because they must navigate between various programming languages and handle intricate generation, verification, and modification tasks. To address these challenges, this paper introduces MAGE, the first open-source multi-agent AI system designed for robust and accurate Verilog RTL code generation. We propose a novel high-temperature RTL candidate sampling and debugging system that effectively explores the space of code candidates and significantly improves the quality of the candidates. Furthermore, we design a novel Verilog-state checkpoint checking mechanism that enables early detection of functional errors and delivers precise feedback for targeted fixes, significantly enhancing the functional correctness of the generated RTL code. MAGE achieves a 95.7% rate of syntactic and functional correctness code generation on VerilogEval-Human 2 benchmark, surpassing the state-of-the-art Claude-3.5-sonnet by 23.3 %, demonstrating a robust and reliable approach for AI-driven RTL design workflows."
  },
  {
    "date": "2018-07-14",
    "title": "Timing Driven C-Slow Retiming on RTL for MultiCores on FPGAs",
    "authors": "Tobias Strauch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1807.05446v1",
    "source": "arXiv",
    "abstract": "In this paper C-Slow Retiming (CSR) on RTL is discussed. CSR multiplies the functionality of cores by adding the same number of registers into each path. The technique is ideal for FPGAs with their already existing registers. Previously publications are limited to adding registers on netlist level, which generates a lot of system verification problems and which is assumed to be the major drawback to use this technology in the modern multicore times. The paper shows how CSR can efficiently be done with timing driven automatic RTL modification. The methodology provided with this paper can be used as guidance for using CSR in high level synthesis (HLS). The paper shows the results of a CSR-ed complex RISC core on RTL implemented on FPGAs."
  },
  {
    "date": "2025-08-04",
    "title": "GSIM: Accelerating RTL Simulation for Large-Scale Designs",
    "authors": "Lu Chen, Dingyi Zhao, Zihao Yu, Ninghui Sun, Yungang Bao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2508.02236v1",
    "source": "arXiv",
    "abstract": "Register Transfer Level (RTL) simulation is widely used in design space exploration, verification, debugging, and preliminary performance evaluation for hardware design. Among various RTL simulation approaches, software simulation is the most commonly used due to its flexibility, low cost, and ease of debugging. However, the slow simulation of complex designs has become the bottleneck in design flow. In this work, we explore the sources of computation overhead of RTL simulation and conclude them into four factors. To optimize these factors, we propose several techniques at the supernode level, node level, and bit level. Finally, we implement these techniques in a novel RTL simulator GSIM. GSIM succeeds in simulating XiangShan, the state-of-the-art open-source RISC-V processor. Besides, compared to Verilator, GSIM can achieve speedup of 7.34x for booting Linux on XiangShan, and 19.94x for running CoreMark on Rocket."
  },
  {
    "date": "2025-09-01",
    "title": "RIROS: A Parallel RTL Fault SImulation FRamework with TwO-Dimensional Parallelism and Unified Schedule",
    "authors": "Jiaping Tang, Jianan Mu, Zizhen Liu, Ge Yu, Tenghui Hua, Bin Sun, Silin Liu, Jing Ye, Huawei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2508.16376v2",
    "source": "arXiv",
    "abstract": "With the rapid development of safety-critical applications such as autonomous driving and embodied intelligence, the functional safety of the corresponding electronic chips becomes more critical. Ensuring chip functional safety requires performing a large number of time-consuming RTL fault simulations during the design phase, significantly increasing the verification cycle. To meet time-to-market demands while ensuring thorough chip verification, parallel acceleration of RTL fault simulation is necessary. Due to the dynamic nature of fault propagation paths and varying fault propagation capabilities, task loads in RTL fault simulation are highly imbalanced, making traditional singledimension parallel methods, such as structural-level parallelism, ineffective. Through an analysis of fault propagation paths and task loads, we identify two types of tasks in RTL fault simulation: tasks that are few in number but high in load, and tasks that are numerous but low in load. Based on this insight, we propose a two-dimensional parallel approach that combines structurallevel and fault-level parallelism to minimize bubbles in RTL fault simulation. Structural-level parallelism combining with workstealing mechanism is used to handle the numerous low-load tasks, while fault-level parallelism is applied to split the high-load tasks. Besides, we deviate from the traditional serial execution model of computation and global synchronization in RTL simulation by proposing a unified computation/global synchronization scheduling approach, which further eliminates bubbles. Finally, we implemented a parallel RTL fault simulation framework, RIROS. Experimental results show a performance improvement of 7.0 times and 11.0 times compared to the state-of-the-art RTL fault simulation and a commercial tool."
  },
  {
    "date": "2023-10-20",
    "title": "Manticore: Hardware-Accelerated RTL Simulation with Static Bulk-Synchronous Parallelism",
    "authors": "Mahyar Emami, Sahand Kashani, Keisuke Kamahori, Mohammad Sepehr Pourghannad, Ritik Raj, James R. Larus",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2301.09413v4",
    "source": "arXiv",
    "abstract": "The demise of Moore's Law and Dennard Scaling has revived interest in specialized computer architectures and accelerators. Verification and testing of this hardware depend heavily upon cycle-accurate simulation of register-transfer-level (RTL) designs. The fastest software RTL simulators can simulate designs at 1--1000 kHz, i.e., more than three orders of magnitude slower than hardware. Improved simulators can increase designers' productivity by speeding design iterations and permitting more exhaustive exploration. One possibility is to exploit low-level parallelism, as RTL expresses considerable fine-grain concurrency. Unfortunately, state-of-the-art RTL simulators often perform best on a single core since modern processors cannot effectively exploit fine-grain parallelism. This work presents Manticore: a parallel computer designed to accelerate RTL simulation. Manticore uses a static bulk-synchronous parallel (BSP) execution model to eliminate fine-grain synchronization overhead. It relies entirely on a compiler to schedule resources and communication, which is feasible since RTL code contains few divergent execution paths. With static scheduling, communication and synchronization no longer incur runtime overhead, making fine-grain parallelism practical. Moreover, static scheduling dramatically simplifies processor implementation, significantly increasing the number of cores that fit on a chip. Our 225-core FPGA implementation running at 475 MHz outperforms a state-of-the-art RTL simulator running on desktop and server computers in 8 out of 9 benchmarks."
  },
  {
    "date": "2025-07-06",
    "title": "Multimedia Verification Through Multi-Agent Deep Research Multimodal Large Language Models",
    "authors": "Huy Hoan Le, Van Sy Thinh Nguyen, Thi Le Chi Dang, Vo Thanh Khang Nguyen, Truong Thanh Hung Nguyen, Hung Cao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2507.04410v1",
    "source": "arXiv",
    "abstract": "This paper presents our submission to the ACMMM25 - Grand Challenge on Multimedia Verification. We developed a multi-agent verification system that combines Multimodal Large Language Models (MLLMs) with specialized verification tools to detect multimedia misinformation. Our system operates through six stages: raw data processing, planning, information extraction, deep research, evidence collection, and report generation. The core Deep Researcher Agent employs four tools: reverse image search, metadata analysis, fact-checking databases, and verified news processing that extracts spatial, temporal, attribution, and motivational context. We demonstrate our approach on a challenge dataset sample involving complex multimedia content. Our system successfully verified content authenticity, extracted precise geolocation and timing information, and traced source attribution across multiple platforms, effectively addressing real-world multimedia verification scenarios."
  },
  {
    "date": "2020-07-15",
    "title": "Overview of CheckThat! 2020: Automatic Identification and Verification of Claims in Social Media",
    "authors": "Alberto Barron-Cedeno, Tamer Elsayed, Preslav Nakov, Giovanni Da San Martino, Maram Hasanain, Reem Suwaileh, Fatima Haouari, Nikolay Babulkov, Bayan Hamdan, Alex Nikolov, Shaden Shaar, Zien Sheikh Ali",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2007.07997v1",
    "source": "arXiv",
    "abstract": "We present an overview of the third edition of the CheckThat! Lab at CLEF 2020. The lab featured five tasks in two different languages: English and Arabic. The first four tasks compose the full pipeline of claim verification in social media: Task 1 on check-worthiness estimation, Task 2 on retrieving previously fact-checked claims, Task 3 on evidence retrieval, and Task 4 on claim verification. The lab is completed with Task 5 on check-worthiness estimation in political debates and speeches. A total of 67 teams registered to participate in the lab (up from 47 at CLEF 2019), and 23 of them actually submitted runs (compared to 14 at CLEF 2019). Most teams used deep neural networks based on BERT, LSTMs, or CNNs, and achieved sizable improvements over the baselines on all tasks. Here we describe the tasks setup, the evaluation results, and a summary of the approaches used by the participants, and we discuss some lessons learned. Last but not least, we release to the research community all datasets from the lab as well as the evaluation scripts, which should enable further research in the important tasks of check-worthiness estimation and automatic claim verification."
  },
  {
    "date": "2006-05-29",
    "title": "Fast and Generalized Polynomial Time Memory Consistency Verification",
    "authors": "Amitabha Roy, Stephan Zeisset, Charles J. Fleckenstein, John C. Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/cs/0605039v4",
    "source": "arXiv",
    "abstract": "The problem of verifying multi-threaded execution against the memory consistency model of a processor is known to be an NP hard problem. However polynomial time algorithms exist that detect almost all failures in such execution. These are often used in practice for microprocessor verification. We present a low complexity and fully parallelized algorithm to check program execution against the processor consistency model. In addition our algorithm is general enough to support a number of consistency models without any degradation in performance. An implementation of this algorithm is currently used in practice to verify processors in the post silicon stage for multiple architectures."
  },
  {
    "date": "2024-11-21",
    "title": "EDA-Aware RTL Generation with Large Language Models",
    "authors": "Mubashir ul Islam, Humza Sami, Pierre-Emmanuel Gaillardon, Valerio Tenace",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2412.04485v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have become increasingly popular for generating RTL code. However, producing error-free RTL code in a zero-shot setting remains highly challenging for even state-of-the-art LLMs, often leading to issues that require manual, iterative refinement. This additional debugging process can dramatically increase the verification workload, underscoring the need for robust, automated correction mechanisms to ensure code correctness from the start. In this work, we introduce AIvril2, a self-verifying, LLM-agnostic agentic framework aimed at enhancing RTL code generation through iterative corrections of both syntax and functional errors. Our approach leverages a collaborative multi-agent system that incorporates feedback from error logs generated by EDA tools to automatically identify and resolve design flaws. Experimental results, conducted on the VerilogEval-Human benchmark suite, demonstrate that our framework significantly improves code quality, achieving nearly a 3.4$\\times$ enhancement over prior methods. In the best-case scenario, functional pass rates of 77% for Verilog and 66% for VHDL were obtained, thus substantially improving the reliability of LLM-driven RTL code generation."
  },
  {
    "date": "2021-01-14",
    "title": "Exploring wav2vec 2.0 on speaker verification and language identification",
    "authors": "Zhiyun Fan, Meng Li, Shiyu Zhou, Bo Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2012.06185v2",
    "source": "arXiv",
    "abstract": "Wav2vec 2.0 is a recently proposed self-supervised framework for speech representation learning. It follows a two-stage training process of pre-training and fine-tuning, and performs well in speech recognition tasks especially ultra-low resource cases. In this work, we attempt to extend self-supervised framework to speaker verification and language identification. First, we use some preliminary experiments to indicate that wav2vec 2.0 can capture the information about the speaker and language. Then we demonstrate the effectiveness of wav2vec 2.0 on the two tasks respectively. For speaker verification, we obtain a new state-of-the-art result, Equal Error Rate (EER) of 3.61% on the VoxCeleb1 dataset. For language identification, we obtain an EER of 12.02% on 1 second condition and an EER of 3.47% on full-length condition of the AP17-OLR dataset. Finally, we utilize one model to achieve the unified modeling by the multi-task learning for the two tasks."
  },
  {
    "date": "2024-09-30",
    "title": "Boosting Few-Pixel Robustness Verification via Covering Verification Designs",
    "authors": "Yuval Shapira, Naor Wiesel, Shahar Shabelman, Dana Drachsler-Cohen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2405.10924v3",
    "source": "arXiv",
    "abstract": "Proving local robustness is crucial to increase the reliability of neural networks. While many verifiers prove robustness in $L_\\infty$ $ε$-balls, very little work deals with robustness verification in $L_0$ $ε$-balls, capturing robustness to few pixel attacks. This verification introduces a combinatorial challenge, because the space of pixels to perturb is discrete and of exponential size. A previous work relies on covering designs to identify sets for defining $L_\\infty$ neighborhoods, which if proven robust imply that the $L_0$ $ε$-ball is robust. However, the number of neighborhoods to verify remains very high, leading to a high analysis time. We propose covering verification designs, a combinatorial design that tailors effective but analysis-incompatible coverings to $L_0$ robustness verification. The challenge is that computing a covering verification design introduces a high time and memory overhead, which is intensified in our setting, where multiple candidate coverings are required to identify how to reduce the overall analysis time. We introduce CoVerD, an $L_0$ robustness verifier that selects between different candidate coverings without constructing them, but by predicting their block size distribution. This prediction relies on a theorem providing closed-form expressions for the mean and variance of this distribution. CoVerD constructs the chosen covering verification design on-the-fly, while keeping the memory consumption minimal and enabling to parallelize the analysis. The experimental results show that CoVerD reduces the verification time on average by up to 5.1x compared to prior work and that it scales to larger $L_0$ $ε$-balls."
  },
  {
    "date": "2018-05-22",
    "title": "A Unified View of Piecewise Linear Neural Network Verification",
    "authors": "Rudy Bunel, Ilker Turkaslan, Philip H. S. Torr, Pushmeet Kohli, M. Pawan Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1711.00455v3",
    "source": "arXiv",
    "abstract": "The success of Deep Learning and its potential use in many safety-critical applications has motivated research on formal verification of Neural Network (NN) models. Despite the reputation of learned NN models to behave as black boxes and the theoretical hardness of proving their properties, researchers have been successful in verifying some classes of models by exploiting their piecewise linear structure and taking insights from formal methods such as Satisifiability Modulo Theory. These methods are however still far from scaling to realistic neural networks. To facilitate progress on this crucial area, we make two key contributions. First, we present a unified framework that encompasses previous methods. This analysis results in the identification of new methods that combine the strengths of multiple existing approaches, accomplishing a speedup of two orders of magnitude compared to the previous state of the art. Second, we propose a new data set of benchmarks which includes a collection of previously released testcases. We use the benchmark to provide the first experimental comparison of existing algorithms and identify the factors impacting the hardness of verification problems."
  },
  {
    "date": "2025-03-16",
    "title": "Parendi: Thousand-Way Parallel RTL Simulation",
    "authors": "Mahyar Emami, Thomas Bourgeat, James Larus",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2403.04714v2",
    "source": "arXiv",
    "abstract": "Hardware development critically depends on cycle-accurate RTL simulation. However, as chip complexity increases, conventional single-threaded simulation becomes impractical due to stagnant single-core performance. Parendi is an RTL simulator that addresses this challenge by exploiting the abundant fine-grained parallelism inherent in RTL simulation and efficiently mapping it onto the massively parallel Graphcore IPU (Intelligence Processing Unit) architecture. Parendi scales up to 5888 cores on 4 Graphcore IPU sockets. It allows us to run large RTL designs up to 4$\\times$ faster than the most powerful state-of-the-art x64 multicore systems. To achieve this performance, we developed new partitioning and compilation techniques and carefully quantified the synchronization, communication, and computation costs of parallel RTL simulation: The paper comprehensively analyzes these factors and details the strategies that Parendi uses to optimize them."
  },
  {
    "date": "2025-10-27",
    "title": "Formal Verification of a Token Sale Launchpad: A Compositional Approach in Dafny",
    "authors": "Evgeny Ukhanov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2510.24798v1",
    "source": "arXiv",
    "abstract": "The proliferation of decentralized financial (DeFi) systems and smart contracts has underscored the critical need for software correctness. Bugs in such systems can lead to catastrophic financial losses. Formal verification offers a path to achieving mathematical certainty about software behavior. This paper presents the formal verification of the core logic for a token sale launchpad, implemented and proven correct using the Dafny programming language and verification system. We detail a compositional, bottom-up verification strategy, beginning with the proof of fundamental non-linear integer arithmetic properties, and building upon them to verify complex business logic, including asset conversion, time-based discounts, and capped-sale refund mechanics. The principal contributions are the formal proofs of critical safety and lifecycle properties. Most notably, we prove that refunds in a capped sale can never exceed the user's original deposit amount, and that the precision loss in round-trip financial calculations is strictly bounded. Furthermore, we verify the complete lifecycle logic, including user withdrawals under various sale mechanics and the correctness of post-sale token allocation, vesting, and claiming. This work serves as a comprehensive case study in applying rigorous verification techniques to build high-assurance financial software."
  },
  {
    "date": "2022-06-30",
    "title": "Efficient verification of Affleck-Kennedy-Lieb-Tasaki states",
    "authors": "Tianyi Chen, Yunting Li, Huangjun Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2206.15307v1",
    "source": "arXiv",
    "abstract": "Affleck-Kennedy-Lieb-Tasaki (AKLT) states are an important class of many-body quantum states that are useful in quantum information processing, including measurement-based quantum computation in particular. Here we propose a general approach for constructing efficient verification protocols for AKLT states on arbitrary graphs with local spin measurements. Our verification protocols build on bond verification protocols and matching covers (including edge coloring) of the underlying graphs, which have a simple geometric and graphic picture. We also provide rigorous performance guarantee that is required for practical applications. With our approach, most AKLT states of wide interest, including those defined on 1D and 2D lattices, can be verified with a constant sample cost, which is independent of the system size and is dramatically more efficient than all previous approaches. As an illustration, we construct concrete verification protocols for AKLT states on various lattices and on arbitrary graphs up to five vertices."
  },
  {
    "date": "2017-05-10",
    "title": "Deep Speaker Feature Learning for Text-independent Speaker Verification",
    "authors": "Lantian Li, Yixiang Chen, Ying Shi, Zhiyuan Tang, Dong Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1705.03670v1",
    "source": "arXiv",
    "abstract": "Recently deep neural networks (DNNs) have been used to learn speaker features. However, the quality of the learned features is not sufficiently good, so a complex back-end model, either neural or probabilistic, has to be used to address the residual uncertainty when applied to speaker verification, just as with raw features. This paper presents a convolutional time-delay deep neural network structure (CT-DNN) for speaker feature learning. Our experimental results on the Fisher database demonstrated that this CT-DNN can produce high-quality speaker features: even with a single feature (0.3 seconds including the context), the EER can be as low as 7.68%. This effectively confirmed that the speaker trait is largely a deterministic short-time property rather than a long-time distributional pattern, and therefore can be extracted from just dozens of frames."
  },
  {
    "date": "2025-08-19",
    "title": "Towards Unified Probabilistic Verification and Validation of Vision-Based Autonomy",
    "authors": "Jordan Peper, Yan Miao, Sayan Mitra, Ivan Ruchkin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2508.14181v1",
    "source": "arXiv",
    "abstract": "Precise and comprehensive situational awareness is a critical capability of modern autonomous systems. Deep neural networks that perceive task-critical details from rich sensory signals have become ubiquitous; however, their black-box behavior and sensitivity to environmental uncertainty and distribution shifts make them challenging to verify formally. Abstraction-based verification techniques for vision-based autonomy produce safety guarantees contingent on rigid assumptions, such as bounded errors or known unique distributions. Such overly restrictive and inflexible assumptions limit the validity of the guarantees, especially in diverse and uncertain test-time environments. We propose a methodology that unifies the verification models of perception with their offline validation. Our methodology leverages interval MDPs and provides a flexible end-to-end guarantee that adapts directly to the out-of-distribution test-time conditions. We evaluate our methodology on a synthetic perception Markov chain with well-defined state estimation distributions and a mountain car benchmark. Our findings reveal that we can guarantee tight yet rigorous bounds on overall system safety."
  },
  {
    "date": "2025-07-22",
    "title": "Rethinking LLM-Based RTL Code Optimization Via Timing Logic Metamorphosis",
    "authors": "Zhihao Xu, Bixin Li, Lulu Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2507.16808v1",
    "source": "arXiv",
    "abstract": "Register Transfer Level(RTL) code optimization is crucial for achieving high performance and low power consumption in digital circuit design. However, traditional optimization methods often rely on manual tuning and heuristics, which can be time-consuming and error-prone. Recent studies proposed to leverage Large Language Models(LLMs) to assist in RTL code optimization. LLMs can generate optimized code snippets based on natural language descriptions, potentially speeding up the optimization process. However, existing approaches have not thoroughly evaluated the effectiveness of LLM-Based code optimization methods for RTL code with complex timing logic. To address this gap, we conducted a comprehensive empirical investigation to assess the capability of LLM-Based RTL code optimization methods in handling RTL code with complex timing logic. In this study, we first propose a new benchmark for RTL optimization evaluation. It comprises four subsets, each corresponding to a specific area of RTL code optimization. Then we introduce a method based on metamorphosis to systematically evaluate the effectiveness of LLM-Based RTL code optimization methods.Our key insight is that the optimization effectiveness should remain consistent for semantically equivalent but more complex code. After intensive experiments, we revealed several key findings. (1) LLM-Based RTL optimization methods can effectively optimize logic operations and outperform existing compiler-based methods. (2) LLM-Based RTL optimization methods do not perform better than existing compiler-based methods on RTL code with complex timing logic, particularly in timing control flow optimization and clock domain optimization. This is primarily attributed to the challenges LLMs face in understanding timing logic in RTL code. Based on these findings, we provide insights for further research in leveraging LLMs for RTL code optimization."
  },
  {
    "date": "2024-08-13",
    "title": "LAAG-RV: LLM Assisted Assertion Generation for RTL Design Verification",
    "authors": "Karthik Maddala, Bhabesh Mali, Chandan Karfa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2409.15281v1",
    "source": "arXiv",
    "abstract": "Writing SystemVerilog Assertions (SVA) is an important but complex step in verifying Register Transfer Level (RTL) designs. Conventionally, experts need to understand the design specifications and write the SVA assertions, which is time-consuming and error-prone. However, with the recent advancement of transformer models, the Large Language Models (LLMs) assisted assertion generation for design verification is gaining interest in recent times. Motivated by this, we proposed a novel LLM-based framework, LAAG-RV, to generate SVA from the natural language specifications of the design. Our framework provides a one-time Verilog loop for signal synchronization in the generated SVA to improve the generated assertion quality. For our experiments, we created a custom LLM based on OpenAI GPT-4. Furthermore, we developed test cases to validate the LLM-generated assertions. Initial observations show that some generated assertions contain issues and did not pass all the test cases. However, by iteratively prompting the LLMs using carefully crafted manual prompts derived from test case failures in a simulator, the framework can generate correct SVAs. Our results on OpenTitan designs demonstrate that LLMs significantly simplify the process of generating assertions, making it efficient and less error-prone."
  },
  {
    "date": "2025-10-11",
    "title": "Bridging Neural ODE and ResNet: A Formal Error Bound for Safety Verification",
    "authors": "Abdelrahman Sayed Sayed, Pierre-Jean Meyer, Mohamed Ghazel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2506.03227v2",
    "source": "arXiv",
    "abstract": "A neural ordinary differential equation (neural ODE) is a machine learning model that is commonly described as a continuous-depth generalization of a residual network (ResNet) with a single residual block, or conversely, the ResNet can be seen as the Euler discretization of the neural ODE. These two models are therefore strongly related in a way that the behaviors of either model are considered to be an approximation of the behaviors of the other. In this work, we establish a more formal relationship between these two models by bounding the approximation error between two such related models. The obtained error bound then allows us to use one of the models as a verification proxy for the other, without running the verification tools twice: if the reachable output set expanded by the error bound satisfies a safety property on one of the models, this safety property is then guaranteed to be also satisfied on the other model. This feature is fully reversible, and the initial safety verification can be run indifferently on either of the two models. This novel approach is illustrated on a numerical example of a fixed-point attractor system modeled as a neural ODE."
  },
  {
    "date": "2021-03-23",
    "title": "SoK: Attacks on Industrial Control Logic and Formal Verification-Based Defenses",
    "authors": "Ruimin Sun, Alejandro Mera, Long Lu, David Choffnes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2006.04806v3",
    "source": "arXiv",
    "abstract": "Programmable Logic Controllers (PLCs) play a critical role in the industrial control systems. Vulnerabilities in PLC programs might lead to attacks causing devastating consequences to the critical infrastructure, as shown in Stuxnet and similar attacks. In recent years, we have seen an exponential increase in vulnerabilities reported for PLC control logic. Looking back on past research, we found extensive studies explored control logic modification attacks, as well as formal verification-based security solutions. We performed systematization on these studies, and found attacks that can compromise a full chain of control and evade detection. However, the majority of the formal verification research investigated ad-hoc techniques targeting PLC programs. We discovered challenges in every aspect of formal verification, rising from (1) the ever-expanding attack surface from evolved system design, (2) the real-time constraint during the program execution, and (3) the barrier in security evaluation given proprietary and vendor-specific dependencies on different techniques. Based on the knowledge systematization, we provide a set of recommendations for future research directions, and we highlight the need of defending security issues besides safety issues."
  },
  {
    "date": "2020-05-14",
    "title": "Verification of Quantitative Hyperproperties Using Trace Enumeration Relations",
    "authors": "Shubham Sahai, Rohit Sinha, Pramod Subramanyan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2005.04606v2",
    "source": "arXiv",
    "abstract": "Many important cryptographic primitives offer probabilistic guarantees of security that can be specified as quantitative hyperproperties; these are specifications that stipulate the existence of a certain number of traces in the system satisfying certain constraints. Verification of such hyperproperties is extremely challenging because they involve simultaneous reasoning about an unbounded number of different traces. In this paper, we introduce a technique for verification of quantitative hyperproperties based on the notion of trace enumeration relations. These relations allow us to reduce the problem of trace-counting into one of model-counting of formulas in first-order logic. We also introduce a set of inference rules for machine-checked reasoning about the number of satisfying solutions to first-order formulas (aka model counting). Putting these two components together enables semi-automated verification of quantitative hyperproperties on infinite state systems. We use our methodology to prove confidentiality of access patterns in Path ORAMs of unbounded size, soundness of a simple interactive zero-knowledge proof protocol as well as other applications of quantitative hyperproperties studied in past work."
  },
  {
    "date": "2022-07-28",
    "title": "PHEMEPlus: Enriching Social Media Rumour Verification with External Evidence",
    "authors": "John Dougrez-Lewis, Elena Kochkina, M. Arana-Catania, Maria Liakata, Yulan He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2207.13970v1",
    "source": "arXiv",
    "abstract": "Work on social media rumour verification utilises signals from posts, their propagation and users involved. Other lines of work target identifying and fact-checking claims based on information from Wikipedia, or trustworthy news articles without considering social media context. However works combining the information from social media with external evidence from the wider web are lacking. To facilitate research in this direction, we release a novel dataset, PHEMEPlus, an extension of the PHEME benchmark, which contains social media conversations as well as relevant external evidence for each rumour. We demonstrate the effectiveness of incorporating such evidence in improving rumour verification models. Additionally, as part of the evidence collection, we evaluate various ways of query formulation to identify the most effective method."
  },
  {
    "date": "2025-11-29",
    "title": "TrojanLoC: LLM-based Framework for RTL Trojan Localization",
    "authors": "Weihua Xiao, Zeng Wang, Minghao Shao, Raghu Vamshi Hemadri, Ozgur Sinanoglu, Muhammad Shafique, Johann Knechtel, Siddharth Garg, Ramesh Karri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.00591v1",
    "source": "arXiv",
    "abstract": "Hardware Trojans (HT s) are a persistent threat to integrated circuits, especially when inserted at the register-transfer level (RTL). Existing methods typically first convert the design into a graph, such as a gate-level netlist or an RTL-derived dataflow graph (DFG), and then use a graph neural network (GNN ) to obtain an embedding of that graph, which (i) loses compact RTL semantics, (ii) relies on shallow GNNs with limited receptive field, and (iii) is largely restricted to coarse, module-level binary HT detection. We propose TrojanLoC, an LLM-based framework for RTL-level HT localization. We use an RTL-finetuned LLM to derive module-level and line-level embeddings directly from RTL code, capturing both global design context and local semantics. Next, we train task-specific classifiers on these embeddings to perform module-level Trojan detection, type prediction, and fine-grained line-level localization. We also introduce TrojanInS, a large synthetic dataset of RTL designs with systematically injected Trojans from four effect-based categories, each accompanied by precise line-level annotations. Our experiments show that TrojanLoC achieves strong module-level performance, reaching 0.99 F1-score for Trojan detection, up to 0.68 higher than baseline, and 0.84 macro-F1 for Trojan-type classification. At the line level, TrojanLoc further achieves up to 0.93 macro-F1, enabling fine-grained localization of Trojan-relevant RTL lines"
  },
  {
    "date": "2024-09-04",
    "title": "RTLRewriter: Methodologies for Large Models aided RTL Code Optimization",
    "authors": "Xufeng Yao, Yiwen Wang, Xing Li, Yingzhao Lian, Ran Chen, Lei Chen, Mingxuan Yuan, Hong Xu, Bei Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2409.11414v1",
    "source": "arXiv",
    "abstract": "Register Transfer Level (RTL) code optimization is crucial for enhancing the efficiency and performance of digital circuits during early synthesis stages. Currently, optimization relies heavily on manual efforts by skilled engineers, often requiring multiple iterations based on synthesis feedback. In contrast, existing compiler-based methods fall short in addressing complex designs. This paper introduces RTLRewriter, an innovative framework that leverages large models to optimize RTL code. A circuit partition pipeline is utilized for fast synthesis and efficient rewriting. A multi-modal program analysis is proposed to incorporate vital visual diagram information as optimization cues. A specialized search engine is designed to identify useful optimization guides, algorithms, and code snippets that enhance the model ability to generate optimized RTL. Additionally, we introduce a Cost-aware Monte Carlo Tree Search (C-MCTS) algorithm for efficient rewriting, managing diverse retrieved contents and steering the rewriting results. Furthermore, a fast verification pipeline is proposed to reduce verification cost. To cater to the needs of both industry and academia, we propose two benchmarking suites: the Large Rewriter Benchmark, targeting complex scenarios with extensive circuit partitioning, optimization trade-offs, and verification challenges, and the Small Rewriter Benchmark, designed for a wider range of scenarios and patterns. Our comparative analysis with established compilers such as Yosys and E-graph demonstrates significant improvements, highlighting the benefits of integrating large models into the early stages of circuit design. We provide our benchmarks at https://github.com/yaoxufeng/RTLRewriter-Bench."
  },
  {
    "date": "2016-12-15",
    "title": "A Novel RTL ATPG Model Based on Gate Inherent Faults (GIF-PO) of Complex Gates",
    "authors": "Tobias Strauch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1612.05166v1",
    "source": "arXiv",
    "abstract": "This paper starts with a comprehensive survey on RTL ATPG. It then proposes a novel RTL ATPG model based on \"Gate Inherent Faults\" (GIF). These GIF are extracted from each complex gate (adder, case-statement, etc.) of the RTL source code individually. They are related to the internal logic paths of a complex gate. They are not related to any net/signal in the RTL design. It is observed, that when all GIF on RTL are covered (100%) and the same stimulus is applied, then all gate level stuck-at faults of the netlist are covered (100%) as well. The proposed RTL ATPG model is therefore synthesis independent. This is shown on ITC'99 testcases. The applied semi-automatic test pattern generation process is based on functional simulation."
  },
  {
    "date": "2025-08-23",
    "title": "Products of Recursive Programs for Hypersafety Verification (Extended Version)",
    "authors": "Ruotong Cheng, Azadeh Farzan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2504.10800v2",
    "source": "arXiv",
    "abstract": "We study the problem of automated hypersafety verification of infinite-state recursive programs. We propose an infinite class of product programs, specifically designed with recursion in mind, that reduce the hypersafety verification of a recursive program to standard safety verification. For this, we combine insights from language theory and concurrency theory to propose an algorithmic solution for constructing an infinite class of recursive product programs. One key insight is that, using the simple theory of visibly pushdown languages, one can maintain the recursive structure of syntactic program alignments which is vital to constructing a new product program that can be viewed as a classic recursive program -- that is, one that can be executed on a single stack. Another key insight is that techniques from concurrency theory can be generalized to help define product programs based on the view that the parallel composition of individual recursive programs includes all possible alignments from which a sound set of alignments that faithfully preserve the satisfaction of the hypersafety property can be selected. On the practical side, we formulate a family of parametric canonical product constructions that are intuitive to programmers and can be used as building blocks to specify recursive product programs for the purpose of relational and hypersafety verification, with the idea that the right product program can be verified automatically using existing techniques. We demonstrate the effectiveness of these techniques through an implementation and highly promising experimental results."
  },
  {
    "date": "2024-07-17",
    "title": "Deep Generative Attacks and Countermeasures for Data-Driven Offline Signature Verification",
    "authors": "An Ngo, Rajesh Kumar, Phuong Cao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2312.00987v2",
    "source": "arXiv",
    "abstract": "This study investigates the vulnerabilities of data-driven offline signature verification (DASV) systems to generative attacks and proposes robust countermeasures. Specifically, we explore the efficacy of Variational Autoencoders (VAEs) and Conditional Generative Adversarial Networks (CGANs) in creating deceptive signatures that challenge DASV systems. Using the Structural Similarity Index (SSIM) to evaluate the quality of forged signatures, we assess their impact on DASV systems built with Xception, ResNet152V2, and DenseNet201 architectures. Initial results showed False Accept Rates (FARs) ranging from 0% to 5.47% across all models and datasets. However, exposure to synthetic signatures significantly increased FARs, with rates ranging from 19.12% to 61.64%. The proposed countermeasure, i.e., retraining the models with real + synthetic datasets, was very effective, reducing FARs between 0% and 0.99%. These findings emphasize the necessity of investigating vulnerabilities in security systems like DASV and reinforce the role of generative methods in enhancing the security of data-driven systems."
  },
  {
    "date": "2022-04-11",
    "title": "On the RTL Implementation of FINN Matrix Vector Compute Unit",
    "authors": "Syed Asad Alam, David Gregg, Giulio Gambardella, Thomas Preusser, Michaela Blott",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2201.11409v2",
    "source": "arXiv",
    "abstract": "FPGA-based accelerators are becoming more popular for deep neural network due to the ability to scale performance with increasing degree of specialization with dataflow architectures or custom data types. To reduce the barrier for software engineers and data scientists to adopt FPGAs, C++- and OpenCL-based design entries with high-level synthesis (HLS) have been introduced. They provide higher abstraction compared to register-transfer level (RTL)-based design. HLS offers faster development time, better maintainability and more flexibility in code exploration, when evaluating options for multi-dimension tensors, convolutional layers or parallelism. Thus, HLS has been adopted by DNN accelerator generation frameworks such as FINN and hls4ml. In this paper, we present an alternative backend RTL library for FINN. We investigate and evaluate, across a spectrum of design dimensions, an RTL-based implementation versus the original HLS variant. We show that for smaller design parameters, RTL produces significantly smaller circuits. For larger circuits, however, the look-up table (LUT) count of RTL-based design is slightly higher, up to around $15\\%$. On the other hand, HLS consistently requires more flip-flops (FFs) (orders-of-magnitude increase) and block RAMs (BRAMs) ($2\\times$ more). This also impacts the critical path delay, with RTL producing significantly faster circuits, up to $80\\%$. Furthermore, RTL also benefits from at-least a $10\\times$ reduction in synthesis time. Finally the results were practically validated using a real-world use case of a multi-layer perceptron (MLP) network used in network intrusion detection. Overall, since HLS frameworks code-generate the hardware design, the benefits of the ease in the design entry is less important as compared to synthesis time reduction togther with resource benefits, this might make the RTL abstraction an attractive alternative."
  },
  {
    "date": "2025-11-17",
    "title": "Assessing Large Language Models in Generating RTL Design Specifications",
    "authors": "Hung-Ming Huang, Yu-Hsin Yang, Fu-Chieh Chang, Yun-Chia Hsu, Yin-Yu Lin, Ming-Fang Tsai, Chun-Chih Yang, Pei-Yuan Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.00045v1",
    "source": "arXiv",
    "abstract": "As IC design grows more complex, automating comprehension and documentation of RTL code has become increasingly important. Engineers currently should manually interpret existing RTL code and write specifications, a slow and error-prone process. Although LLMs have been studied for generating RTL from specifications, automated specification generation remains underexplored, largely due to the lack of reliable evaluation methods. To address this gap, we investigate how prompting strategies affect RTL-to-specification quality and introduce metrics for faithfully evaluating generated specs. We also benchmark open-source and commercial LLMs, providing a foundation for more automated and efficient specification workflows in IC design."
  },
  {
    "date": "2025-03-11",
    "title": "SIMT/GPU Data Race Verification using ISCC and Intermediary Code Representations: A Case Study",
    "authors": "Andrew Osterhout, Ganesh Gopalakrishnan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2503.08946v1",
    "source": "arXiv",
    "abstract": "It is often difficult to write code that you can ensure will be executed in the right order when programing for parallel compute tasks. Due to the way that today's parallel compute hardware, primarily Graphical Processing Units (GPUs), allows you to write code. It is easy to write code that may result in one thread reading or modifying data before it should, thus resulting in a data race. It would be useful to have a tool that could verify that the code will execute as expected. However, most static analysis done at the language level has to be completely retooled to work on a different languages. Therefore, it would be of great use to be able to perform verification and analysis on the Memory Model of a parallel compute code, in a lower level intermediary representations that most languages pass through on their way to something that the GPU hardware can understand. This body of work aims to deal with the question of if there is still enough of the information in the intermediary representations to be able to perform memory model verification to check for data races. To determine this we plan to analyze as a case study the GeSpMM Sparse Matrix Multiplication Algorithm, implemented in CUDA C++ with the LLVM compiler and Julia with CUDA.jl."
  },
  {
    "date": "2023-11-09",
    "title": "Verilog-to-PyG -- A Framework for Graph Learning and Augmentation on RTL Designs",
    "authors": "Yingjie Li, Mingju Liu, Alan Mishchenko, Cunxi Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2311.05722v1",
    "source": "arXiv",
    "abstract": "The complexity of modern hardware designs necessitates advanced methodologies for optimizing and analyzing modern digital systems. In recent times, machine learning (ML) methodologies have emerged as potent instruments for assessing design quality-of-results at the Register-Transfer Level (RTL) or Boolean level, aiming to expedite design exploration of advanced RTL configurations. In this presentation, we introduce an innovative open-source framework that translates RTL designs into graph representation foundations, which can be seamlessly integrated with the PyTorch Geometric graph learning platform. Furthermore, the Verilog-to-PyG (V2PYG) framework is compatible with the open-source Electronic Design Automation (EDA) toolchain OpenROAD, facilitating the collection of labeled datasets in an utterly open-source manner. Additionally, we will present novel RTL data augmentation methods (incorporated in our framework) that enable functional equivalent design augmentation for the construction of an extensive graph-based RTL design database. Lastly, we will showcase several using cases of V2PYG with detailed scripting examples. V2PYG can be found at \\url{https://yu-maryland.github.io/Verilog-to-PyG/}."
  },
  {
    "date": "2025-06-27",
    "title": "CAPM: Fast and Robust Verification on Maxpool-based CNN via Dual Network",
    "authors": "Jia-Hau Bai, Chi-Ting Liu, Yu Wang, Fu-Chieh Chang, Pei-Yuan Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2407.09550v3",
    "source": "arXiv",
    "abstract": "This study uses CAPM (Convex Adversarial Polytope for Maxpool-based CNN) to improve the verified bound for general purpose maxpool-based convolutional neural networks (CNNs) under bounded norm adversarial perturbations. The maxpool function is decomposed as a series of ReLU functions to extend the convex relaxation technique to maxpool functions, by which the verified bound can be efficiently computed through a dual network. The experimental results demonstrate that this technique allows the state-of-the-art verification precision for maxpool-based CNNs and involves a much lower computational cost than current verification methods, such as DeepZ, DeepPoly and PRIMA. This method is also applicable to large-scale CNNs, which previous studies show to be often computationally prohibitively expensive. Under certain circumstances, CAPM is 40-times, 20-times or twice as fast and give a significantly higher verification bound (CAPM 98% vs. PRIMA 76%/DeepPoly 73%/DeepZ 8%) as compared to PRIMA/DeepPoly/DeepZ. Furthermore, we additionally present the time complexity of our algorithm as $O(W^2NK)$, where $W$ is the maximum width of the neural network, $N$ is the number of neurons, and $K$ is the size of the maxpool layer's kernel."
  },
  {
    "date": "2025-08-05",
    "title": "Rhea: a Framework for Fast Design and Validation of RTL Cache-Coherent Memory Subsystems",
    "authors": "Davide Zoni, Andrea Galimberti, Adriano Guarisco",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2508.03837v1",
    "source": "arXiv",
    "abstract": "Designing and validating efficient cache-coherent memory subsystems is a critical yet complex task in the development of modern multi-core system-on-chip architectures. Rhea is a unified framework that streamlines the design and system-level validation of RTL cache-coherent memory subsystems. On the design side, Rhea generates synthesizable, highly configurable RTL supporting various architectural parameters. On the validation side, Rhea integrates Verilator's cycle-accurate RTL simulation with gem5's full-system simulation, allowing realistic workloads and operating systems to run alongside the actual RTL under test. We apply Rhea to design MSI-based RTL memory subsystems with one and two levels of private caches and scaling up to sixteen cores. Their evaluation with 22 applications from state-of-the-art benchmark suites shows intermediate performance relative to gem5 Ruby's MI and MOESI models. The hybrid gem5-Verilator co-simulation flow incurs a moderate simulation overhead, up to 2.7 times compared to gem5 MI, but achieves higher fidelity by simulating real RTL hardware. This overhead decreases with scale, down to 1.6 times in sixteen-core scenarios. These results demonstrate Rhea's effectiveness and scalability in enabling fast development of RTL cache-coherent memory subsystem designs."
  },
  {
    "date": "2025-01-05",
    "title": "RTLMarker: Protecting LLM-Generated RTL Copyright via a Hardware Watermarking Framework",
    "authors": "Kun Wang, Kaiyan Chang, Mengdi Wang, Xinqi Zou, Haobo Xu, Yinhe Han, Ying Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2501.02446v1",
    "source": "arXiv",
    "abstract": "Recent advances of large language models in the field of Verilog generation have raised several ethical and security concerns, such as code copyright protection and dissemination of malicious code. Researchers have employed watermarking techniques to identify codes generated by large language models. However, the existing watermarking works fail to protect RTL code copyright due to the significant syntactic and semantic differences between RTL code and software code in languages such as Python. This paper proposes a hardware watermarking framework RTLMarker that embeds watermarks into RTL code and deeper into the synthesized netlist. We propose a set of rule-based Verilog code transformations , ensuring the watermarked RTL code's syntactic and semantic correctness. In addition, we consider an inherent tradeoff between watermark transparency and watermark effectiveness and jointly optimize them. The results demonstrate RTLMarker's superiority over the baseline in RTL code watermarking."
  },
  {
    "date": "2025-07-21",
    "title": "VeriRAG: A Retrieval-Augmented Framework for Automated RTL Testability Repair",
    "authors": "Haomin Qi, Yuyang Du, Lihao Zhang, Soung Chang Liew, Kexin Chen, Yining Du",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2507.15664v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have demonstrated immense potential in computer-aided design (CAD), particularly for automated debugging and verification within electronic design automation (EDA) tools. However, Design for Testability (DFT) remains a relatively underexplored area. This paper presents VeriRAG, the first LLM-assisted DFT-EDA framework. VeriRAG leverages a Retrieval-Augmented Generation (RAG) approach to enable LLM to revise code to ensure DFT compliance. VeriRAG integrates (1) an autoencoder-based similarity measurement model for precise retrieval of reference RTL designs for the LLM, and (2) an iterative code revision pipeline that allows the LLM to ensure DFT compliance while maintaining synthesizability. To support VeriRAG, we introduce VeriDFT, a Verilog-based DFT dataset curated for DFT-aware RTL repairs. VeriRAG retrieves structurally similar RTL designs from VeriDFT, each paired with a rigorously validated correction, as references for code repair. With VeriRAG and VeriDFT, we achieve fully automated DFT correction -- resulting in a 7.72-fold improvement in successful repair rate compared to the zero-shot baseline (Fig. 5 in Section V). Ablation studies further confirm the contribution of each component of the VeriRAG framework. We open-source our data, models, and scripts at https://github.com/yuyangdu01/LLM4DFT."
  },
  {
    "date": "2025-05-10",
    "title": "Extend IVerilog to Support Batch RTL Fault Simulation",
    "authors": "Jiaping Tang, Jianan Mu, Zizhen Liu, Zhiteng Chao, Jing Ye, Huawei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2505.06687v1",
    "source": "arXiv",
    "abstract": "The advancement of functional safety has made RTL-level fault simulation increasingly important to achieve iterative efficiency in the early stages of design and to ensure compliance with functional safety standards. In this paper, we extend IVerilog to support batch RTL fault simulation and integrate the event-driven algorithm and the concurrent fault simulation algorithm. Comparative experiments with a state-of-the-art commercial simulator and an open-source RTL fault simulator demonstrate that our simulator achieves a performance improvement of 2.2$\\times$ and 3.4$\\times$, respectively."
  },
  {
    "date": "2024-09-02",
    "title": "OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection",
    "authors": "Fan Cui, Chenyang Yin, Kexing Zhou, Youwei Xiao, Guangyu Sun, Qiang Xu, Qipeng Guo, Demin Song, Dahua Lin, Xingcheng Zhang, Yun, Liang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2407.16237v2",
    "source": "arXiv",
    "abstract": "Recent studies have demonstrated the significant potential of Large Language Models (LLMs) in generating Register Transfer Level (RTL) code, with notable advancements showcased by commercial models such as GPT-4 and Claude3-Opus. However, these proprietary LLMs often raise concerns regarding privacy and security. While open-source LLMs offer solutions to these concerns, they typically underperform commercial models in RTL code generation tasks, primarily due to the scarcity of high-quality open-source RTL datasets. To address this challenge, we introduce OriGen , a fully open-source framework that incorporates self-reflection capabilities and a novel dataset augmentation methodology for generating high-quality, large-scale RTL code. Our approach employs a code-tocode augmentation technique to enhance the quality of open-source RTL code datasets. Furthermore, OriGen can rectify syntactic errors through a self-reflection process that leverages compiler feedback. Experimental results demonstrate that OriGen significantly outperforms other open-source alternatives in RTL code generation. It surpasses the previous best-performing open-source LLM by 12.8% and even exceeds GPT-4 Turbo in the pass@1 metric on the VerilogEval-Human benchmark. Moreover, OriGen exhibits superior capabilities in self-reflection and error correction, outperforming GPT-4 by 19.9% on a benchmark designed to evaluate self-reflection capabilities."
  },
  {
    "date": "2024-09-09",
    "title": "Unified Fairness for Weak Memory Verification",
    "authors": "Parosh Aziz Abdulla, Mohamed Faouzi Atig, Adwait Godbole, Shankaranarayanan Krishna, Mihir Vahanwala",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2305.17605v2",
    "source": "arXiv",
    "abstract": "We consider the verification of omega-regular linear temporal properties of concurrent programs running under weak memory semantics. We observe that in particular, these properties may enforce liveness clauses, whose verification in this context is seldom studied. The challenge lies in precluding demonic nondeterminism arising due to scheduling, as well as due to multiple possible causes of weak memory consistency. We systematically account for the latter with a generic operational model of programs running under weak memory semantics, which can be instantiated to a host of memory models. This generic model serves as the formal basis for our definitions of fairness to preclude demonic nondeterminism: we provide both language-theoretic and probabilistic versions, and prove them equivalent in the context of the verification of omega-regular linear temporal properties. As a corollary of this proof, we obtain that under our fairness assumptions, both qualitative and quantitative verification Turing-reduce to close variants of control state reachability: a safety-verification problem. A preliminary version of this article titled \"Overcoming Memory Weakness with Unified Fairness\" appeared in the proceedings of CAV 2023."
  },
  {
    "date": "2025-11-26",
    "title": "R3A: Reliable RTL Repair Framework with Multi-Agent Fault Localization and Stochastic Tree-of-Thoughts Patch Generation",
    "authors": "Zizhang Luo, Fan Cui, Kexing Zhou, Runlin Guo, Mile Xia, Hongyuan Hou, Yun Liang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.20090v2",
    "source": "arXiv",
    "abstract": "Repairing RTL bugs is crucial for hardware design and verification. Traditional automatic program repair (APR) methods define dedicated search spaces to locate and fix bugs with program synthesis. However, they heavily rely on fixed templates and can only deal with limited bugs. As an alternative, Large Language Models with the ability to understand code semantics can be explored for RTL repair. However, they suffer from unreliable outcomes due to inherent randomness and long input contexts of RTL code and waveform. To address these challenges, we propose R3A, an LLM-based automatic RTL program repair framework upon the basic model to improve reliability. R3A proposes the stochastic Tree-Of-Thoughts method to control a patch generation agent to explore a validated solution for the bug. The algorithm samples search states according to a heuristic function to balance between exploration and exploitation for a reliable outcome. Besides, R3A proposes a multi-agent fault localization method to find fault candidates as the starting points for the patch generation agent, further increasing the reliability. Experiments show R3A can fix 90.6% of bugs in the RTL-repair dataset within a given time limit, which covers 45% more bugs than traditional methods and other LLM-based approaches, while achieving an 86.7% pass@5 rate on average, showing a high reliability."
  },
  {
    "date": "2011-07-13",
    "title": "Stochatic Perron's method and verification without smoothness using viscosity comparison: the linear case",
    "authors": "Erhan Bayraktar, Mihai Sirbu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1103.0538v4",
    "source": "arXiv",
    "abstract": "We introduce a probabilistic version of the classical Perron's method to construct viscosity solutions to linear parabolic equations associated to stochastic differential equations. Using this method, we construct easily two viscosity (sub and super) solutions that squeeze in between the expected payoff. If a comparison result holds true, then there exists a unique viscosity solution which is a martingale along the solutions of the stochastic differential equation. The unique viscosity solution is actually equal to the expected payoff. This amounts to a verification result (Ito's Lemma) for non-smooth viscosity solutions of the linear parabolic equation. This is the first step in a larger program to prove verification for viscosity solutions and the Dynamic Programming Principle for stochastic control problems and games"
  },
  {
    "date": "2022-03-14",
    "title": "Verification and Validation: the Path to Predictive Scale-Resolving Simulations of Turbulence",
    "authors": "F. S. Pereira, F. F. Grinstein, D. M. Israel, L. Eca",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2103.09899v3",
    "source": "arXiv",
    "abstract": "This work investigates the importance of verification and validation (V&V) to achieve predictive scale-resolving simulations (SRS) of turbulence, i.e., computations capable of resolving a fraction of the turbulent flow scales. Toward this end, we propose a novel but simple V&V strategy based on grid and physical resolution refinement studies that can be used even when the exact initial flow conditions are unknown, or reference data are unavailable. This is particularly relevant for transient and transitional flow problems, as well as for the improvement of turbulence models. We start by presenting a literature survey of results obtained with distinct SRS models for flows past circular cylinders. It confirms the importance of V&V by illustrating a large variability of results, which is independent of the selected mathematical model and Reynolds number. The proposed V&V strategy is then used on three representative problems of practical interest. The results illustrate that it is possible to conduct reliable verification and validation exercises with SRS models, and evidence the importance of V&V to predictive SRS of turbulence. Most notably, the data also confirm the advantages and potential of the proposed V&V strategy: separate assessment of numerical and modeling errors, enhanced flow physics analysis, identification of key flow phenomena, and ability to operate when the exact flow conditions are unknown or reference data are unavailable."
  },
  {
    "date": "2022-12-15",
    "title": "Optimized Symbolic Interval Propagation for Neural Network Verification",
    "authors": "Philipp Kern, Marko Kleine Büning, Carsten Sinz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2212.08567v1",
    "source": "arXiv",
    "abstract": "Neural networks are increasingly applied in safety critical domains, their verification thus is gaining importance. A large class of recent algorithms for proving input-output relations of feed-forward neural networks are based on linear relaxations and symbolic interval propagation. However, due to variable dependencies, the approximations deteriorate with increasing depth of the network. In this paper we present DPNeurifyFV, a novel branch-and-bound solver for ReLU networks with low dimensional input-space that is based on symbolic interval propagation with fresh variables and input-splitting. A new heuristic for choosing the fresh variables allows to ameliorate the dependency problem, while our novel splitting heuristic, in combination with several other improvements, speeds up the branch-and-bound procedure. We evaluate our approach on the airborne collision avoidance networks ACAS Xu and demonstrate runtime improvements compared to state-of-the-art tools."
  },
  {
    "date": "2025-04-23",
    "title": "ERASER: Efficient RTL FAult Simulation Framework with Trimmed Execution Redundancy",
    "authors": "Jiaping Tang, Jianan Mu, Silin Liu, Zizhen Liu, Feng Gu, Xinyu Zhang, Leyan Wang, Shenwen Liang, Jing Ye, Huawei Li, Xiaowei Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2504.16473v1",
    "source": "arXiv",
    "abstract": "As intelligent computing devices increasingly integrate into human life, ensuring the functional safety of the corresponding electronic chips becomes more critical. A key metric for functional safety is achieving a sufficient fault coverage. To meet this requirement, extensive time-consuming fault simulation of the RTL code is necessary during the chip design phase.The main overhead in RTL fault simulation comes from simulating behavioral nodes (always blocks). Due to the limited fault propagation capacity, fault simulation results often match the good simulation results for many behavioral nodes. A key strategy for accelerating RTL fault simulation is the identification and elimination of redundant simulations. Existing methods detect redundant executions by examining whether the fault inputs to each RTL node are consistent with the good inputs. However, we observe that this input comparison mechanism overlooks a significant amount of implicit redundant execution: although the fault inputs differ from the good inputs, the node's execution results remain unchanged. Our experiments reveal that this overlooked redundant execution constitutes nearly half of the total execution overhead of behavioral nodes, becoming a significant bottleneck in current RTL fault simulation. The underlying reason for this overlooked redundancy is that, in these cases, the true execution paths within the behavioral nodes are not affected by the changes in input values. In this work, we propose a behavior-level redundancy detection algorithm that focuses on the true execution paths. Building on the elimination of redundant executions, we further developed an efficient RTL fault simulation framework, Eraser.Experimental results show that compared to commercial tools, under the same fault coverage, our framework achieves a 3.9 $\\times$ improvement in simulation performance on average."
  },
  {
    "date": "2023-04-16",
    "title": "Automatic verification of transparency protocols (extended version)",
    "authors": "Vincent Cheval, José Moreira, Mark Ryan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2303.04500v2",
    "source": "arXiv",
    "abstract": "Transparency protocols are protocols whose actions can be publicly monitored by observers (such observers may include regulators, rights advocacy groups, or the general public). The observed actions are typically usages of private keys such as decryptions, and signings. Examples of transparency protocols include certificate transparency, cryptocurrency, transparent decryption, and electronic voting. These protocols usually pose a challenge for automatic verification, because they involve sophisticated data types that have strong properties, such as Merkle trees, that allow compact proofs of data presence and tree extension. We address this challenge by introducing new features in ProVerif, and a methodology for using them. With our methodology, it is possible to describe the data type quite abstractly, using ProVerif axioms, and prove the correctness of the protocol using those axioms as assumptions. Then, in separate steps, one can define one or more concrete implementations of the data type, and again use ProVerif to show that the implementations satisfy the assumptions that were coded as axioms. This helps make compositional proofs, splitting the proof burden into several manageable pieces. We illustrate the methodology and features by providing the first formal verification of the transparent decryption and certificate transparency protocols with a precise modelling of the Merkle tree data structure."
  },
  {
    "date": "2024-06-18",
    "title": "ROVER: RTL Optimization via Verified E-Graph Rewriting",
    "authors": "Samuel Coward, Theo Drane, George A. Constantinides",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2406.12421v1",
    "source": "arXiv",
    "abstract": "Manual RTL design and optimization remains prevalent across the semiconductor industry because commercial logic and high-level synthesis tools are unable to match human designs. Our experience in industrial datapath design demonstrates that manual optimization can typically be decomposed into a sequence of local equivalence preserving transformations. By formulating datapath optimization as a graph rewriting problem we automate design space exploration in a tool we call ROVER. We develop a set of mixed precision RTL rewrite rules inspired by designers at Intel and an accompanying automated validation framework. A particular challenge in datapath design is to determine a productive order in which to apply transformations as this can be design dependent. ROVER resolves this problem by building upon the e-graph data structure, which compactly represents a design space of equivalent implementations. By applying rewrites to this data structure, ROVER generates a set of efficient and functionally equivalent design options. From the ROVER generated e-graph we select an efficient implementation. To accurately model the circuit area we develop a theoretical cost metric and then an integer linear programming model to extract the optimal implementation. To build trust in the generated design ROVER also produces a back-end verification certificate that can be checked using industrial tools. We apply ROVER to both Intel-provided and open-source benchmarks, and see up to a 63% reduction in circuit area. ROVER is also able to generate a customized library of distinct implementations from a given parameterizable RTL design, improving circuit area across the range of possible instantiations."
  },
  {
    "date": "2023-11-14",
    "title": "MasterRTL: A Pre-Synthesis PPA Estimation Framework for Any RTL Design",
    "authors": "Wenji Fang, Yao Lu, Shang Liu, Qijun Zhang, Ceyu Xu, Lisa Wu Wills, Hongce Zhang, Zhiyao Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2311.08441v1",
    "source": "arXiv",
    "abstract": "In modern VLSI design flow, the register-transfer level (RTL) stage is a critical point, where designers define precise design behavior with hardware description languages (HDLs) like Verilog. Since the RTL design is in the format of HDL code, the standard way to evaluate its quality requires time-consuming subsequent synthesis steps with EDA tools. This time-consuming process significantly impedes design optimization at the early RTL stage. Despite the emergence of some recent ML-based solutions, they fail to maintain high accuracy for any given RTL design. In this work, we propose an innovative pre-synthesis PPA estimation framework named MasterRTL. It first converts the HDL code to a new bit-level design representation named the simple operator graph (SOG). By only adopting single-bit simple operators, this SOG proves to be a general representation that unifies different design types and styles. The SOG is also more similar to the target gate-level netlist, reducing the gap between RTL representation and netlist. In addition to the new SOG representation, MasterRTL proposes new ML methods for the RTL-stage modeling of timing, power, and area separately. Compared with state-of-the-art solutions, the experiment on a comprehensive dataset with 90 different designs shows accuracy improvement by 0.33, 0.22, and 0.15 in correlation for total negative slack (TNS), worst negative slack (WNS), and power, respectively."
  },
  {
    "date": "2025-10-24",
    "title": "REvolution: An Evolutionary Framework for RTL Generation driven by Large Language Models",
    "authors": "Kyungjun Min, Kyumin Cho, Junhwan Jang, Seokhyeong Kang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2510.21407v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are used for Register-Transfer Level (RTL) code generation, but they face two main challenges: functional correctness and Power, Performance, and Area (PPA) optimization. Iterative, feedback-based methods partially address these, but they are limited to local search, hindering the discovery of a global optimum. This paper introduces REvolution, a framework that combines Evolutionary Computation (EC) with LLMs for automatic RTL generation and optimization. REvolution evolves a population of candidates in parallel, each defined by a design strategy, RTL implementation, and evaluation feedback. The framework includes a dual-population algorithm that divides candidates into Fail and Success groups for bug fixing and PPA optimization, respectively. An adaptive mechanism further improves search efficiency by dynamically adjusting the selection probability of each prompt strategy according to its success rate. Experiments on the VerilogEval and RTLLM benchmarks show that REvolution increased the initial pass rate of various LLMs by up to 24.0 percentage points. The DeepSeek-V3 model achieved a final pass rate of 95.5\\%, comparable to state-of-the-art results, without the need for separate training or domain-specific tools. Additionally, the generated RTL designs showed significant PPA improvements over reference designs. This work introduces a new RTL design approach by combining LLMs' generative capabilities with EC's broad search power, overcoming the local-search limitations of previous methods."
  },
  {
    "date": "2025-02-25",
    "title": "DeepCircuitX: A Comprehensive Repository-Level Dataset for RTL Code Understanding, Generation, and PPA Analysis",
    "authors": "Zeju Li, Changran Xu, Zhengyuan Shi, Zedong Peng, Yi Liu, Yunhao Zhou, Lingfeng Zhou, Chengyu Ma, Jianyuan Zhong, Xi Wang, Jieru Zhao, Zhufei Chu, Xiaoyan Yang, Qiang Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2502.18297v1",
    "source": "arXiv",
    "abstract": "This paper introduces DeepCircuitX, a comprehensive repository-level dataset designed to advance RTL (Register Transfer Level) code understanding, generation, and power-performance-area (PPA) analysis. Unlike existing datasets that are limited to either file-level RTL code or physical layout data, DeepCircuitX provides a holistic, multilevel resource that spans repository, file, module, and block-level RTL code. This structure enables more nuanced training and evaluation of large language models (LLMs) for RTL-specific tasks. DeepCircuitX is enriched with Chain of Thought (CoT) annotations, offering detailed descriptions of functionality and structure at multiple levels. These annotations enhance its utility for a wide range of tasks, including RTL code understanding, generation, and completion. Additionally, the dataset includes synthesized netlists and PPA metrics, facilitating early-stage design exploration and enabling accurate PPA prediction directly from RTL code. We demonstrate the dataset's effectiveness on various LLMs finetuned with our dataset and confirm the quality with human evaluations. Our results highlight DeepCircuitX as a critical resource for advancing RTL-focused machine learning applications in hardware design automation.Our data is available at https://zeju.gitbook.io/lcm-team."
  },
  {
    "date": "2024-05-06",
    "title": "Annotating Slack Directly on Your Verilog: Fine-Grained RTL Timing Evaluation for Early Optimization",
    "authors": "Wenji Fang, Shang Liu, Hongce Zhang, Zhiyao Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2403.18453v2",
    "source": "arXiv",
    "abstract": "In digital IC design, compared with post-synthesis netlists or layouts, the early register-transfer level (RTL) stage offers greater optimization flexibility for both designers and EDA tools. However, timing information is typically unavailable at this early stage. Some recent machine learning (ML) solutions propose to predict the total negative slack (TNS) and worst negative slack (WNS) of an entire design at the RTL stage, but the fine-grained timing information of individual registers remains unavailable. In this work, we address the unique challenges of RTL timing prediction and introduce our solution named RTL-Timer. To the best of our knowledge, this is the first fine-grained general timing estimator applicable to any given design. RTL-Timer explores multiple promising RTL representations and proposes customized loss functions to capture the maximum arrival time at register endpoints. RTL-Timer's fine-grained predictions are further applied to guide optimization in a standard synthesis flow. The average results on unknown test designs demonstrate a correlation above 0.89, contributing around 3% WNS and 10% TNS improvement after optimization."
  },
  {
    "date": "2025-07-25",
    "title": "Examining Entropic Unbalanced Optimal Transport and Sinkhorn Divergences for Spatial Forecast Verification",
    "authors": "Jacob J. M. Francis, Colin J. Cotter, Marion P. Mittermaier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2412.16063v3",
    "source": "arXiv",
    "abstract": "An optimal transport (OT) problem seeks to find the cheapest mapping between two distributions with equal total density, given the cost of transporting density from one place to another. Unbalanced OT allows for different total density in each distribution. This is the typical setting for precipitation forecast and observation data, when considering the densities as accumulated rainfall, or intensity. In this work, entropic unbalanced OT and its associated Sinkhorn divergence are examined as a spatial forecast verification method for precipitation data. It offers many attractive features, such as morphing one field into another, defining a distance between fields and providing feature based optimal assignment. It is found that the Sinkhorn divergence is robust against the common double penalty problem (a form of phase error), on average aligns with expert assessments of model performance, and allows for a variety of novel pictorial illustrations of error. It provides informative summary scores, and has few limitations to its application. Combined, these findings place unbalanced entropy regularised optimal transport and the Sinkhorn divergence as an informative method which follows geometric intuition."
  },
  {
    "date": "2025-05-30",
    "title": "TuRTLe: A Unified Evaluation of LLMs for RTL Generation",
    "authors": "Dario Garcia-Gasulla, Gokcen Kestor, Emanuele Parisi, Miquel Albertí-Binimelis, Cristian Gutierrez, Razine Moundir Ghorab, Orlando Montenegro, Bernat Homs, Miquel Moreto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2504.01986v2",
    "source": "arXiv",
    "abstract": "The rapid advancements in LLMs have driven the adoption of generative AI in various domains, including Electronic Design Automation (EDA). Unlike traditional software development, EDA presents unique challenges, as generated RTL code must not only be syntactically correct and functionally accurate but also synthesizable by hardware generators while meeting performance, power, and area constraints. These additional requirements introduce complexities that existing code-generation benchmarks often fail to capture, limiting their effectiveness in evaluating LLMs for RTL generation. To address this gap, we propose TuRTLe, a unified evaluation framework designed to systematically assess LLMs across key RTL generation tasks. TuRTLe integrates multiple existing benchmarks and automates the evaluation process, enabling a comprehensive assessment of LLM performance in syntax correctness, functional correctness, synthesis, PPA optimization, and exact line completion. Using this framework, we benchmark a diverse set of open LLMs and analyze their strengths and weaknesses in EDA-specific tasks. Our results show that reasoning-based models, such as DeepSeek R1, consistently outperform others across multiple evaluation criteria, but at the cost of increased computational overhead and inference latency. Additionally, base models are better suited in module completion tasks, while instruct-tuned models perform better in specification-to-RTL tasks."
  },
  {
    "date": "2022-02-22",
    "title": "An Exhaustive Approach to Detecting Transient Execution Side Channels in RTL Designs of Processors",
    "authors": "Mohammad Rahmani Fadiheh, Alex Wezel, Johannes Mueller, Joerg Bormann, Sayak Ray, Jason M. Fung, Subhasish Mitra, Dominik Stoffel, Wolfgang Kunz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2108.01979v3",
    "source": "arXiv",
    "abstract": "Hardware (HW) security issues have been emerging at an alarming rate in recent years. Transient execution attacks, in particular, pose a genuine threat to the security of modern computing systems. Despite recent advances, understanding the intricate implications of microarchitectural design decisions on processor security remains a great challenge and has caused a number of update cycles in the past. number of update cycles in the past. This papers addresses the need for a new approach to HW sign-off verification which guarantees the security of processors at the Register Transfer Level (RTL). To this end, we introduce a formal definition of security with respect to transient execution attacks, formulated as a HW property. We present a formal proof methodology based on Unique Program Execution Checking (UPEC) which can be used to systematically detect all vulnerabilities to transient execution attacks in RTL designs. UPEC does not exploit any a priori knowledge on known attacks and can therefore detect also vulnerabilities based on new, so far unknown, types of channels. This is demonstrated by two new attack scenarios discovered in our experiments with UPEC. UPEC scales to a wide range of HW designs, including in-order processors (RocketChip), pipelines with out-of-order writeback (Ariane), and processors with deep out-of-order speculative execution (BOOM). To the best of our knowledge, UPEC is the first RTL verification technique that exhaustively covers transient execution side channels in processors of realistic complexity."
  },
  {
    "date": "2023-08-11",
    "title": "Relational Action Bases: Formalization, Effective Safety Verification, and Invariants (Extended Version)",
    "authors": "Silvio Ghilardi, Alessandro Gianola, Marco Montali, Andrey Rivkin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2208.06377v2",
    "source": "arXiv",
    "abstract": "Modeling and verification of dynamic systems operating over a relational representation of states are increasingly investigated problems in AI, Business Process Management, and Database Theory. To make these systems amenable to verification, the amount of information stored in each relational state needs to be bounded, or restrictions are imposed on the preconditions and effects of actions. We introduce the general framework of relational action bases (RABs), which generalizes existing models by lifting both these restrictions: unbounded relational states can be evolved through actions that can quantify both existentially and universally over the data, and that can exploit numerical datatypes with arithmetic predicates. We then study parameterized safety of RABs via (approximated) SMT-based backward search, singling out essential meta-properties of the resulting procedure, and showing how it can be realized by an off-the-shelf combination of existing verification modules of the state-of-the-art MCMT model checker. We demonstrate the effectiveness of this approach on a benchmark of data-aware business processes. Finally, we show how universal invariants can be exploited to make this procedure fully correct."
  },
  {
    "date": "2019-10-11",
    "title": "Verification of Neural Networks: Specifying Global Robustness using Generative Models",
    "authors": "Nathanaël Fijalkow, Mohit Kumar Gupta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1910.05018v1",
    "source": "arXiv",
    "abstract": "The success of neural networks across most machine learning tasks and the persistence of adversarial examples have made the verification of such models an important quest. Several techniques have been successfully developed to verify robustness, and are now able to evaluate neural networks with thousands of nodes. The main weakness of this approach is in the specification: robustness is asserted on a validation set consisting of a finite set of examples, i.e. locally. We propose a notion of global robustness based on generative models, which asserts the robustness on a very large and representative set of examples. We show how this can be used for verifying neural networks. In this paper we experimentally explore the merits of this approach, and show how it can be used to construct realistic adversarial examples."
  },
  {
    "date": "2025-08-26",
    "title": "A Framework for Robust Speaker Verification in Highly Noisy Environments Leveraging Both Noisy and Enhanced Audio",
    "authors": "Adam Katav, Yair Moshe, Israel Cohen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2508.18913v1",
    "source": "arXiv",
    "abstract": "Recent advancements in speaker verification techniques show promise, but their performance often deteriorates significantly in challenging acoustic environments. Although speech enhancement methods can improve perceived audio quality, they may unintentionally distort speaker-specific information, which can affect verification accuracy. This problem has become more noticeable with the increasing use of generative deep neural networks (DNNs) for speech enhancement. While these networks can produce intelligible speech even in conditions of very low signal-to-noise ratio (SNR), they may also severely alter distinctive speaker characteristics. To tackle this issue, we propose a novel neural network framework that effectively combines speaker embeddings extracted from both noisy and enhanced speech using a Siamese architecture. This architecture allows us to leverage complementary information from both sources, enhancing the robustness of speaker verification under severe noise conditions. Our framework is lightweight and agnostic to specific speaker verification and speech enhancement techniques, enabling the use of a wide range of state-of-the-art solutions without modification. Experimental results demonstrate the superior performance of our proposed framework."
  },
  {
    "date": "2016-02-19",
    "title": "Automatic Generation of High-Coverage Tests for RTL Designs using Software Techniques and Tools",
    "authors": "Yu Zhang, Wenlong Feng, Mengxing Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1602.06038v1",
    "source": "arXiv",
    "abstract": "Register Transfer Level (RTL) design validation is a crucial stage in the hardware design process. We present a new approach to enhancing RTL design validation using available software techniques and tools. Our approach converts the source code of a RTL design into a C++ software program. Then a powerful symbolic execution engine is employed to execute the converted C++ program symbolically to generate test cases. To better generate efficient test cases, we limit the number of cycles to guide symbolic execution. Moreover, we add bit-level symbolic variable support into the symbolic execution engine. Generated test cases are further evaluated by simulating the RTL design to get accurate coverage. We have evaluated the approach on a floating point unit (FPU) design. The preliminary results show that our approach can deliver high-quality tests to achieve high coverage."
  },
  {
    "date": "2025-02-22",
    "title": "Machine Learning Framework for Early Power, Performance, and Area Estimation of RTL",
    "authors": "Anindita Chattopadhyay, Vijay Kumar Sutrakar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2502.16203v1",
    "source": "arXiv",
    "abstract": "A critical stage in the evolving landscape of VLSI design is the design phase that is transformed into register-transfer level (RTL), which specifies system functionality through hardware description languages like Verilog. Generally, evaluating the quality of an RTL design demands full synthesis via electronic design automation (EDA) tool is time-consuming process that is not well-suited to rapid design iteration and optimization. Although recent breakthroughs in machine Learning (ML) have brought early prediction models, these methods usually do not provide robust and generalizable solutions with respect to a wide range of RTL designs. This paper proposes a pre-synthesis framework that makes early estimation of power, performance and area (PPA) metrics directly from the hardware description language (HDL) code making direct use of library files instead of toggle files. The proposed framework introduces a bit-level representation referred to as the simple operator graph (SOG), which uses single-bit operators to generate a generalized and flexible structure that closely mirrors the characteristics of post synthesis design. The proposed model bridges the RTL and post-synthesis design, which will help in precisely predicting key metrics. The proposed tree-based ML framework shows superior predictive performance PPA estimation. Validation is carried out on 147 distinct RTL designs. The proposed model with 147 different designs shows accuracy of 98%, 98%, and 90% for WNS, TNS and power, respectively, indicates significant accuracy improvements relative to state-of-the-art methods."
  },
  {
    "date": "2025-08-24",
    "title": "VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation",
    "authors": "Anjiang Wei, Huanmi Tan, Tarun Suresh, Daniel Mendoza, Thiago S. F. X. Teixeira, Ke Wang, Caroline Trippel, Alex Aiken",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2504.15659v2",
    "source": "arXiv",
    "abstract": "Recent advances in Large Language Models (LLMs) have sparked growing interest in applying them to Electronic Design Automation (EDA) tasks, particularly Register Transfer Level (RTL) code generation. While several RTL datasets have been introduced, most focus on syntactic validity rather than functional validation with tests, leading to training examples that compile but may not implement the intended behavior. We present VERICODER, a model for RTL code generation fine-tuned on a dataset validated for functional correctness. This fine-tuning dataset is constructed using a novel methodology that combines unit test generation with feedback-directed refinement. Given a natural language specification and an initial RTL design, we prompt a teacher model (GPT-4o-mini) to generate unit tests and iteratively revise the RTL design based on its simulation results using the generated tests. If necessary, the teacher model also updates the tests to ensure they comply with the natural language specification. As a result of this process, every example in our dataset is functionally validated, consisting of a natural language description, an RTL implementation, and passing tests. Fine-tuned on this dataset of 125,777 examples, VERICODER achieves state-of-the-art metrics in functional correctness on VerilogEval and RTLLM, with relative gains of up to 71.7% and 27.4%, respectively. An ablation study further shows that models trained on our functionally validated dataset outperform those trained on functionally non-validated datasets, underscoring the importance of high-quality datasets in RTL code generation. Our code, data, and models are publicly available at https://github.com/Anjiang-Wei/VeriCoder"
  },
  {
    "date": "2017-01-03",
    "title": "Source Code Verification for Embedded Systems using Prolog",
    "authors": "Frank Flederer, Ludwig Ostermayer, Dietmar Seipel, Sergio Montenegro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1701.00630v1",
    "source": "arXiv",
    "abstract": "System relevant embedded software needs to be reliable and, therefore, well tested, especially for aerospace systems. A common technique to verify programs is the analysis of their abstract syntax tree (AST). Tree structures can be elegantly analyzed with the logic programming language Prolog. Moreover, Prolog offers further advantages for a thorough analysis: On the one hand, it natively provides versatile options to efficiently process tree or graph data structures. On the other hand, Prolog's non-determinism and backtracking eases tests of different variations of the program flow without big effort. A rule-based approach with Prolog allows to characterize the verification goals in a concise and declarative way. In this paper, we describe our approach to verify the source code of a flash file system with the help of Prolog. The flash file system is written in C++ and has been developed particularly for the use in satellites. We transform a given abstract syntax tree of C++ source code into Prolog facts and derive the call graph and the execution sequence (tree), which then are further tested against verification goals. The different program flow branching due to control structures is derived by backtracking as subtrees of the full execution sequence. Finally, these subtrees are verified in Prolog. We illustrate our approach with a case study, where we search for incorrect applications of semaphores in embedded software using the real-time operating system RODOS. We rely on computation tree logic (CTL) and have designed an embedded domain specific language (DSL) in Prolog to express the verification goals."
  },
  {
    "date": "2025-11-27",
    "title": "VeriDispatcher: Multi-Model Dispatching through Pre-Inference Difficulty Prediction for RTL Generation Optimization",
    "authors": "Zeng Wang, Weihua Xiao, Minghao Shao, Raghu Vamshi Hemadri, Ozgur Sinanoglu, Muhammad Shafique, Ramesh Karri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2511.22749v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) show strong performance in RTL generation, but different models excel on different tasks because of architecture and training differences. Prior work mainly prompts or finetunes a single model. What remains not well studied is how to coordinate multiple different LLMs so they jointly improve RTL quality while also reducing cost, instead of running all models and choosing the best output. We define this as the multi-LLM RTL generation problem. We propose VeriDispatcher, a multi-LLM RTL generation framework that dispatches each RTL task to suitable LLMs based on pre-inference difficulty prediction. For each model, we train a compact classifier over semantic embeddings of task descriptions, using difficulty scores derived from benchmark variants that combine syntax, structural similarity, and functional correctness. At inference, VeriDispatcher uses these predictors to route tasks to a selected subset of LLMs. Across 10 diverse LLMs on RTLLM and VerilogEval, VeriDispatcher achieves up to 18% accuracy improvement on RTLLM using only 40% of commercial calls, and on VerilogEval maintains accuracy while reducing commercial usage by 25%, enabling cost-effective, high-quality LLM deployment in hardware design automation."
  },
  {
    "date": "2017-01-03",
    "title": "End-to-End Attention based Text-Dependent Speaker Verification",
    "authors": "Shi-Xiong Zhang, Zhuo Chen, Yong Zhao, Jinyu Li, Yifan Gong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/1701.00562v1",
    "source": "arXiv",
    "abstract": "A new type of End-to-End system for text-dependent speaker verification is presented in this paper. Previously, using the phonetically discriminative/speaker discriminative DNNs as feature extractors for speaker verification has shown promising results. The extracted frame-level (DNN bottleneck, posterior or d-vector) features are equally weighted and aggregated to compute an utterance-level speaker representation (d-vector or i-vector). In this work we use speaker discriminative CNNs to extract the noise-robust frame-level features. These features are smartly combined to form an utterance-level speaker vector through an attention mechanism. The proposed attention model takes the speaker discriminative information and the phonetic information to learn the weights. The whole system, including the CNN and attention model, is joint optimized using an end-to-end criterion. The training algorithm imitates exactly the evaluation process --- directly mapping a test utterance and a few target speaker utterances into a single verification score. The algorithm can automatically select the most similar impostor for each target speaker to train the network. We demonstrated the effectiveness of the proposed end-to-end system on Windows $10$ \"Hey Cortana\" speaker verification task."
  },
  {
    "date": "2023-11-01",
    "title": "Virtual-Peripheral-in-the-Loop : A Hardware-in-the-Loop Strategy to Bridge the VP/RTL Design-Gap",
    "authors": "Sallar Ahmadi-Pour, Pascal Pieper, Rolf Drechsler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2311.00442v1",
    "source": "arXiv",
    "abstract": "Virtual Prototypes act as an executable specification model, offering a unified behavior reference model for SW and HW engineers. However, between the VP and the HW still exists a gap, as the step from an architectural level VP implementation on the Transaction Level Modeling to the Register Transfer Layer implementation is considerably big. Especially when a company wants to focus on their Unique Selling-Point, the HW Design Space Exploration and acceptance tests should start as early as possible. Traditionally, this can only start once the rest of the System-on-Chip is also implemented in the RTL. As SoCs consist of many common subsystems like processors, memories, and peripherals, this may impact the time-to-market considerably. This is avoidable, however: In this paper we propose a Hardware-in-the-Loop strategy that allows to bridge the gap between the VP and RTL design that empowers engineers to focus on their USP while leveraging an existing suite of TLM Intellectual Properties for the common base-system components. We show how VPs and partial RTL implementations of a SoC can be combined in a Hardware-in-the-Loop simulation environment utilizing Field-Programmable Gate Arrays. The proposed approach allows early DSE, validation, and verification of SoC subsystems, which bridges the TLM/RTL gap. We evaluate our approach with a lightweight implementation of the proposed protocol, and three case-studies with real-world peripherals and accelerators on HW. Furthermore, we assess the capabilities of our approach and offer practical considerations for engineers utilizing this HIL approach for SoC design; and finally propose further extensions that can boost the approach for specialized applications like high-performance accelerators and computation."
  },
  {
    "date": "2025-12-15",
    "title": "LLM Tools for Programming",
    "authors": "Michal Čerňanský, Peter Hafner, Iveta Dirgová Luptáková",
    "publish": "2025 International Conference on Emerging eLearning Technologies and Applications (ICETA)",
    "url": "https://doi.org/10.1109/iceta67772.2025.11280153",
    "source": "IEEE",
    "abstract": "The rise of Large Language Model (LLM)– based tools such as ChatGPT, GitHub Copilot, Cursor, and GitHub Copilot Agent is transforming how software is developed. These tools function as intelligent collaborators, capable of generating code, explaining concepts, detecting bugs, and accelerating development workflows. As the software industry increasingly demands graduates who are proficient with modern development environments and tools, ranging from debuggers and version control systems to AI-driven assistants, it becomes essential to incorporate LLM-based tools into computer science education. This article summarizes the most prominent LLM-assisted programming tools. Through selected examples of programming problems, it demonstrates the practical applications of LLM-based assistants and agents. By engaging with these tools, computer science students can prepare for a future in which AI will be an integral part of professional software development."
  },
  {
    "date": "2025-12-15",
    "title": "TACLA: An LLM-Based Multi-Agent Tool for Transactional Analysis Training in Education",
    "authors": "Monika Zamojska, Jarosław A. Chudziak",
    "publish": "2025 IEEE 37th International Conference on Tools with Artificial Intelligence (ICTAI)",
    "url": "https://doi.org/10.1109/ictai66417.2025.00048",
    "source": "IEEE",
    "abstract": "Simulating nuanced human social dynamics with Large Language Models (LLMs) remains a significant challenge, particularly in achieving psychological depth and consistent persona behavior crucial for high-fidelity training tools. This paper introduces TACLA (Transactional Analysis Contextual LLM-based Agents), a novel Multi-Agent architecture designed to overcome these limitations. TACLA integrates core principles of Transactional Analysis (TA) by modeling agents as an orchestrated system of distinct Parent, Adult, and Child ego states, each with its own pattern memory. An Orchestrator Agent prioritizes ego state activation based on contextual triggers and an agent's life script, ensuring psychologically authentic responses. Validated in an educational scenario, TACLA demonstrates realistic ego state shifts in Student Agents, effectively modeling conflict deescalation and escalation based on different teacher intervention strategies. Evaluation shows high conversational credibility and confirms TACLA's capacity to create dynamic, psychologicallygrounded social simulations, advancing the development of effective AI tools for education and beyond."
  },
  {
    "date": "2025-12-15",
    "title": "LLM Powered DeepSeek and BiLSTM Pipeline Used in Aspect Based Sentiment Analysis",
    "authors": "Moemen Said, Nadia Smairi, Houda Abadlia",
    "publish": "2025 IEEE 37th International Conference on Tools with Artificial Intelligence (ICTAI)",
    "url": "https://doi.org/10.1109/ictai66417.2025.00118",
    "source": "IEEE",
    "abstract": "A hybrid approach for aspect-based sentiment analysis, which integrates a large language model driven aspect extractor with a bidirectional deep learning classifier, is presented in this paper. The proposed pipeline employs the DeepSeek Transformer to automatically identify relevant aspect terms from input sentences using prompt-based generation. These extracted aspects are, then, embedded into reformulated sentence-aspect pairs and fed into a Bidirectional Long Short-Term Memory Network to obtain fine-grained sentiment classification. Unlike the traditional pipelines that rely on manual annotations or fixed aspect lists, the introduced method dynamically adapts to diverse sentence structures and domains. The experimental results demonstrate that the system achieved F1-scores of 88.87%, 83.47% and 86.32% when applied on three benchmark datasets (Laptop, Restaurant and a merged corpus), respectively. They also show that better and more accurate aspect-aware sentiment classification can be provided by combining generative aspect extraction with contextual sequence modeling."
  },
  {
    "date": "2025-12-15",
    "title": "LLM-Based Multimodal COVID-19 Detection",
    "authors": "Dereje Senay Merawi, Million Meshesha, Bantamlak Dejene Tegegn, Yibrah Gebrewahd Gebretsadkan",
    "publish": "2025 International Conference on Information and Communication Technology for Development for Africa (ICT4DA)",
    "url": "https://doi.org/10.1109/ict4da67218.2025.11282819",
    "source": "IEEE",
    "abstract": "Global health systems are facing significant challenges as a result of the COVID-19 pandemic, which necessitates rapid and accurate diagnostic techniques. Recently, large language models (LLMs) have become crucial in the medical field, both for COVID-19 detection and for generating diagnostic reports from medical data. Healthcare professionals can use these models to help them make quicker and more accurate decisions by analyzing complex data and detecting patterns. Microsoft BioBERT was used as the text input embedding model in this study to improve the vocabulary used in report generation. Additionally, to combine visual features with textual embeddings, Microsoft BioBERT is fused with VGG16, a pretrained image vectorizer. Next, miniGPT uses the combined features to produce a thorough diagnostic report. In this study, the researchers followed an experimental research design to achieve the objective of the study. There are three major steps in the research method. The first step is data collection and preparation. This is followed by modeling using the necessary packages, and finally the evaluation of model’s performance. Results show that LLMs can achieve a promising detection accuracy of 85.7% for COVID-19 when clinical data is combined with medical imaging. Then, minGPT was used to generate clinical reports and suggestions based on the classification results of the fusion model. There are still difficulties, such as the lack of diversity in the data, hallucinations in text generation, and the interpretability of the model. Future studies should concentrate on creating domain-specific prompt engineering methodologies, including models such as GPT-3, GPT-4, and retrieval-augmented generation (RAG) into clinical processes, and thoroughly assessing how these models affect clinical outcomes. Future research aiming at improving diagnostic accuracy and reliability can benefit from the recommendations provided by this study"
  },
  {
    "date": "2025-12-15",
    "title": "A Novel Translation-Driven Approach to Enhance LLM Performance on Low-Resource Languages",
    "authors": "Moshe Ofer, Orel Zamler, Amos Azaria",
    "publish": "2025 IEEE 37th International Conference on Tools with Artificial Intelligence (ICTAI)",
    "url": "https://doi.org/10.1109/ictai66417.2025.00052",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) excel in highresource languages but struggle with low-resource languages due to limited training data and insufficient representation during pre-training. This disparity creates significant barriers for deploying advanced NLP technologies across diverse linguistic communities. This paper presents TALL (Trainable Architecture for Enhancing LLM Performance in Low-Resource Languages), a novel framework that strategically integrates an LLM with two bilingual translation models to bridge the performance gap between high and low-resource languages. TALL transforms lowresource inputs into high-resource representations through a multi-stage pipeline, leveraging the LLM's robust capabilities while preserving essential linguistic features through carefully designed dimension alignment layers and custom transformer components. The architecture addresses the challenge of integrating models with different hidden dimensions and representation spaces, enabling seamless knowledge transfer across languages. Our comprehensive experiments on Hebrew demonstrate significant improvements over several competitive baselines, including direct LLM use, naive translation approaches, finetuning strategies, and soft prompting techniques. Notably, TALL achieves up to <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{5. 5 9 \\%}$</tex> accuracy compared to <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{2. 9 3 \\%}$</tex> for the next best approach, representing a substantial performance gain. The architecture employs a parameter-efficient strategy, freezing large pre-trained components while training only lightweight adapter modules, effectively balancing computational efficiency with performance gains. This approach makes TALL particularly suitable for resource-constrained environments while maintaining strong cross-lingual transfer capabilities.<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup><sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>Code is available in https://github.com/MosheOfer1/TALL"
  },
  {
    "date": "2025-12-15",
    "title": "LLM-based Multi-class Attack Analysis and Mitigation Framework in IoT/IIoT Networks",
    "authors": "Seif Ikbarieh, Maanak Gupta, Elmahedi Mahalal",
    "publish": "2025 IEEE Global Conference on Artificial Intelligence and Internet of Things (GCAIoT)",
    "url": "https://doi.org/10.1109/gcaiot68269.2025.11275542",
    "source": "IEEE",
    "abstract": "The Internet of Things has expanded rapidly, transforming communication and operations across industries but also increasing the attack surface and security breaches. Artificial Intelligence plays a key role in securing IoT, enabling attack detection, attack behavior analysis, and mitigation suggestion. Despite advancements, evaluations remain purely qualitative, and the lack of a standardized, objective benchmark for quantitatively measuring AI-based attack analysis and mitigation hinders consistent assessment of model effectiveness. In this work, we propose a hybrid framework combining Machine Learning (ML) for multi-class attack detection with Large Language Models (LLMs) for attack behavior analysis and mitigation suggestion. After benchmarking several ML and Deep Learning (DL) classifiers on the Edge-IIoTset and CICIoT2023 datasets, we applied structured role-play prompt engineering with Retrieval-Augmented Generation (RAG) to guide ChatGPT-o3 and DeepSeek-R1 in producing detailed, context-aware responses. We introduce novel evaluation metrics for quantitative assessment to guide us and an ensemble of judge LLMs, namely ChatGPT-4o, DeepSeekV3, Mixtral 8x7B Instruct, Gemini 2.5 Flash, Meta Llama 4, TII Falcon H1 34B Instruct, xAI Grok 3, and Claude 4 Sonnet, to independently evaluate the responses. Results show that Random Forest has the best detection model, and ChatGPT03 outperformed DeepSeek-R1 in attack analysis and mitigation."
  },
  {
    "date": "2025-12-15",
    "title": "SCA-WAL: An Open-Source Framework for Power Side Channel Assessment at RTL and Netlist Level",
    "authors": "Andrija Nešković, Ahmad Kabour, Mohamed Eltantawi, Mladen Berekovic, Rolf Meyer, Saleh Mulhem",
    "publish": "IEEE Embedded Systems Letters",
    "url": "https://doi.org/10.1109/les.2025.3644491",
    "source": "IEEE",
    "abstract": "Side-channel attacks (SCA) exploit data leaks in hardware, and fixing them after chip fabrication is costly. Therefore, security assessments are shifting towards the design phase. However, there is a lack of accurate open-source tools capable of evaluating power side channel information leakage across different abstraction levels. To bridge this gap, we present SCA-WAL: a building block in Electronic Design Automation (EDA) capable of generating input-dependent activity traces from VCD waveforms at different abstraction levels. SCA-WAL allows designers to test leakage assumptions in a flexible framework. Our results indicate that SCA-WAL is matching the state-of-the-art open source frameworks in the generation of activity traces at RTL level, while also supporting activity traces generation at Netlist level. As a use-case , we deploy SCA-WAL to generate activity traces of AES implantation and perform a security evaluation by conformance testing with Test Vector Leakage Assessment (TVLA) and simulating a realistic power SCA with Correlation Power Analysis (CPA). Finally, we verify our findings against a commercial netlist-level power estimation tool."
  },
  {
    "date": "2025-12-15",
    "title": "KDPBert: Efficient Log Classification via Keyword-Guided Dynamic Pooling and LLM-Driven Open-Set Adaptation",
    "authors": "Zhian Zhang, Kening Zhu",
    "publish": "2025 International Conference on Digital Society, Information Science and Risk Management (ICDIR)",
    "url": "https://doi.org/10.1109/icdir66749.2025.11281022",
    "source": "IEEE",
    "abstract": "Log classification plays a vital role in information technology and data analysis by categorizing system-generated log data for operational monitoring, anomaly detection, and root cause analysis. Effective log classification enables engineers to rapidly address service interruptions, anticipate system failures, and optimize performance. In real-world scenarios, log classification systems require low inference latency and high accuracy to support rapid monitoring and response. To this end, we propose KDPBert, a model based on a BERT pre-trained language model that incorporates dynamic pooling and adversarial training to enhance both accuracy and inference efficiency. KDPBert leverages both BERT and keyword information for robust feature extraction and log classification. Furthermore, we introduce an uncertainty-based rejection mechanism during inference, evaluating model confidence via the softmax probability distribution to identify and reject low-confidence samples as unknown. For these out-of-distribution samples, a large language model generates new, semantically relevant category labels, enabling the system to dynamically expand its label space and improve robustness to novel log types. Experimental results on five datasets demonstrate that our approach achieves an average F1 score improvement of 2.46%, while significantly enhancing training efficiency and inference accuracy."
  },
  {
    "date": "2025-12-15",
    "title": "Indian Judgement Prediction Assistant: A LLM Based AI Approach",
    "authors": "Aparna S. Kulkarni, Vidhya Gavali, Lalitkumar Chaudhari, Chaitanya Karale, Hrutik Pisal, Pruthvesh Baitule",
    "publish": "2025 9th International Conference on Computing, Communication, Control and Automation (ICCCBEA)",
    "url": "https://doi.org/10.1109/iccubea65967.2025.11283784",
    "source": "IEEE",
    "abstract": "The volume of crimes and legal cases has been growing exponentially in many countries, and the number of pending legal cases has also been growing exponentially. If a system could augment judges in this process, it would be of immense help and would accelerate the process. In addition, on, if the system provides an explanation for its decision, it would help a judge make a more informed decision about the final result of the case. There is a need to develop-based techniques to generate legal outcomes with explanations. Addressing this need, we introduce the Indian Legal Assistant, a model for predicting case outcomes with explanations. The system users can provide detailed case scenarios that include case facts, keywords, acts, and other relevant information. Our model will process this input and generate the possible outcome with an explanation for the given scenario. The project intends to assist Indian citizens, law students, and legal professionals in comprehending the extensive Indian legal system for their respective use cases. The system demonstrates strong predictive results across different case sets, in addition to providing valuable explanations regarding its judgment process. The outcomes from the Indian legal system demonstrate the effectiveness of this approach in terms of both explanation and judgment prediction."
  },
  {
    "date": "2025-12-15",
    "title": "Resilient LLM-Driven Token-Based MAC Protocols via Zero-Shot Adaptation and Knowledge Distillation",
    "authors": "Yongjun Kim, Jihong Park, Mehdi Bennis, Junil Choi",
    "publish": "IEEE Journal on Selected Areas in Communications",
    "url": "https://doi.org/10.1109/jsac.2025.3644282",
    "source": "IEEE",
    "abstract": "Neural network-based medium access control (MAC) protocol models (NPMs) improve goodput through site-specific operations but are vulnerable to shifts from their training network environments, such as changes in the number of user equipments (UEs) severely degrading goodput. To enhance resilience against such environmental shifts, we propose three novel token-based MAC protocol frameworks empowered by large language models (LLMs). First, we introduce a token-based protocol model (TPM), where an LLM generates MAC signaling messages. By editing LLM instruction prompts, TPM enables instant adaptation, which can be further enhanced by TextGrad, an LLM-based automated prompt optimizer. TPM inference is fast but coarse due to the lack of real interactions with the changed environment, and computationally intensive due to the large size of the LLM. To improve goodput and computation efficiency, we develop T2NPM, which transfers and augments TPM knowledge into an NPM via knowledge distillation (KD). Integrating TPM and T2NPM, we propose T3NPM, which employs TPM in the early phase and switches to T2NPM at a later stage. To optimize this phase switching, we design a novel metric of meta-resilience, which quantifies resilience to unknown target goodput after environmental shifts. Simulations corroborate that T3NPM achieves 20.56% higher meta-resilience than NPM with 19.8× lower computation cost than TPM in FLOPs."
  },
  {
    "date": "2025-12-15",
    "title": "Optimization of Limtations and Reduction of Hallucination in Llm Using Rag: a Performancedriven Framework",
    "authors": "Shruti Dhande, Sagar Shinde, Mukul Shitole, Sunny Dhakane, Yash Zope, Pooja Tambe",
    "publish": "2025 9th International Conference on Computing, Communication, Control and Automation (ICCCBEA)",
    "url": "https://doi.org/10.1109/iccubea65967.2025.11283777",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing but still struggle with reliability issues, notably generating plausible yet incorrect information, or hallucinations. This paper introduces a Retrieval-Augmented Generation (RAG) framework designed to address these shortcomings by combining generative models with retrieval-based methods. The framework uses domain-specific datasets, effective text chunking, and advanced embedding techniques to dynamically integrate external knowledge, influencing the factual accuracy, coherence, and relevancy of the generated content. By incorporating Maximum Marginal Relevance (MMR), the system achieved a 15 % improvement in overall retrieval accuracy and a 20 % boost in context precision compared to baseline models. Evaluations across several metrics-including context precision, recall, entity recall, and relevancedemonstrated significant gains in accuracy and a notable reduction in hallucination rates. These promising results shows the potential of RAG architectures which can improve the reliability and productiveness of LLMs, offering a strong foundation for future advancements and broader applications across various domains."
  },
  {
    "date": "2025-12-15",
    "title": "Personalized LLM Service Updating in Collaborative Edge-Enabled Vehicle Autonomous System",
    "authors": "Dongkun Huo, Jiajie Yin, Hongbo Liu, Yixue Hao, Rui Wang, Long Hu, Yijun Mo",
    "publish": "IEEE Transactions on Consumer Electronics",
    "url": "https://doi.org/10.1109/tce.2025.3644688",
    "source": "IEEE",
    "abstract": "Personalized services are increasingly critical for autonomous systems such as smart vehicles, where Large Language Models (LLMs) enhance the driving experience. However, efficiently deploying and continuously updating these models is challenging due to resource constraints and dynamic environments. Existing approaches often neglect personalization and effective cross-edge collaboration, leading to inconsistent service quality and inefficient resource utilization. To address these gaps, we propose a vehicle-edge-cloud collaborative framework centered on our Intent-Driven Multi-Agent Communication (IDMAC) algorithm. IDMAC intelligently coordinates the LLM update life-cycle. It utilizes an intent encoder to model the short-term goals of each edge server from its trajectory. This explicit intent then guides attention mechanisms to facilitate efficient, goal-aligned communication, reducing network overhead and focusing on relevant information. This allows for the dynamic scheduling and routing of parameter-efficient model patches. In our architecture, lightweight models are deployed on vehicles, edge servers handle specialized fine-tuning, and the cloud periodically aggregates global knowledge to create unified updates. Experimental results show that the proposed framework significantly improves service quality and adaptability. IDMAC also strengthens inter-edge collaboration while reducing latency and energy consumption."
  },
  {
    "date": "2025-12-15",
    "title": "Edge-Aware Federated AI: Scalable LLM Integration for Privacy-Preserving Big Data Networks",
    "authors": "Anil Kumar Jonnalagadda, Gokul Narain Natarajan, Satya Manesh Veerapaneni, Srinivas Vikram",
    "publish": "2025 5th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)",
    "url": "https://doi.org/10.1109/iceccme64568.2025.11277672",
    "source": "IEEE",
    "abstract": "As demand for AI that preserves privacy in real time grows, traditional centralized architectures face challenges in scalability, latency, and data sovereignty. This paper proposes a novel framework called Edge-Aware Federated AI (EAFAI), designed to integrate Large Language Models (LLMs) into edge networks using federated learning principles. EAFAI dynamically distributes AI workloads across edge devices and cloud nodes, enabling adaptive LLM deployment while preserving data locality. The architecture leverages decentralized training, model compression, and selective parameter sharing to address privacy, bandwidth, and computation constraints. We demonstrate the framework’s applicability in healthcare and smart city data ecosystems, showcasing its performance across three dimensions: latency, privacy preservation, and model accuracy. Our results show that EAFAI reduces communication overhead by up to 47% and maintains competitive LLM inference accuracy, proving its potential for scalable, privacy-aligned big data intelligence at the edge."
  },
  {
    "date": "2025-12-15",
    "title": "Large Language Model (LLM) based Question and Answering System (QAS): A systematic literature review",
    "authors": "Yibrah Gebrewahd Gebretsadkan, Bantamlak Dejene Tegegne, Dereje Senay Merawi, Million Meshesha",
    "publish": "2025 International Conference on Information and Communication Technology for Development for Africa (ICT4DA)",
    "url": "https://doi.org/10.1109/ict4da67218.2025.11282707",
    "source": "IEEE",
    "abstract": "This paper presents systematic literature review on LLM based (QAS). The review showed that the factoid type QAS are the most studied problem. Unlike the traditional QAS, the LLM based QAS are general purpose and have the capability of fine-tuned to specific purpose QAS using different techniques. Currently the LLM based pre-trained models are used to develop different QAS. T5, XLM-R, BERT, and SQuaD are the common models used to develop QAS. There are gaps related to those models, including training time, dataset preparation, computational costs, hallucination, biasness, shortage of high-quality datasets are common issues in the existing LLM based QAS. In general the current state of the art of QAS is the application of LLM which has the capability of supporting multimodality depending on the models used and the techniques applied. The Agentic AI is considered as an example of LLM used in QAS. This Agentic AI has the capability of accepting users query, understanding the users query, selecting an AI agent from a list of AI agents that will be responsible for providing answers to the users query, finally the selected AI agents will act based on the query to provide answer for users query. Using such kind of Agentic AI models for QAS will minimize searching time and optimizes QAS efficiency and effectiveness. Future researchers are expected to develop more effective and efficient QAS, in terms of the quality of answers."
  },
  {
    "date": "2025-12-15",
    "title": "ProactiveVA: Proactive Visual Analytics with LLM-Based UI Agent",
    "authors": "Yuheng Zhao, Xueli Shu, Liwen Fan, Lin Gao, Yu Zhang, Siming Chen",
    "publish": "IEEE Transactions on Visualization and Computer Graphics",
    "url": "https://doi.org/10.1109/tvcg.2025.3642628",
    "source": "IEEE",
    "abstract": "Visual analytics (VA) is typically applied to complex data, thus requiring complex tools. While visual analytics empowers analysts in data analysis, analysts may get lost in the complexity occasionally. This highlights the need for intelligent assistance mechanisms. However, even the latest LLM-assisted VA systems only provide help when explicitly requested by the user, making them insufficiently intelligent to offer suggestions when analysts need them the most. We propose a ProactiveVA framework in which LLM-powered UI agent monitors user interactions and delivers context-aware assistance proactively. To design effective proactive assistance, we first conducted a formative study analyzing help-seeking behaviors in user interaction logs, identifying when users need proactive help, what assistance they require, and how the agent should intervene. Based on this analysis, we distilled key design requirements in terms of intent recognition, solution generation, interpretability and controllability. Guided by these requirements, we develop a three-stage UI agent pipeline including perception, reasoning, and acting. The agent autonomously perceives users' needs from VA interaction logs, providing tailored suggestions and intuitive guidance through interactive exploration of the system. We implemented the framework in two representative types of VA systems, demonstrating its generalizability, and evaluated the effectiveness through an algorithm evaluation, case and expert study and a user study. We also discuss current design trade-offs of proactive VA and areas for further exploration."
  },
  {
    "date": "2025-12-15",
    "title": "CaneSpeaker: An LLM-Assisted Speaker for Generating Human-Like Navigation Instructions",
    "authors": "Yuanyu Zheng, Lin Zhang, Yunda Sun, Ying Shen, Shengjie Zhao",
    "publish": "ACM Transactions on Multimedia Computing, Communications, and Applications",
    "url": "https://doi.org/10.1145/3785009",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2025-12-15",
    "title": "From Signs to Speech: An End-to-End Conversational Platform for Deaf and Mute Individuals Using GRU and LLM Integration",
    "authors": "Aryan Chauhan, Abdulqadir Kayamkhani, Atharva Gujar, Mandar Gade, Manisha Kumawat",
    "publish": "2025 9th International Conference on Computing, Communication, Control and Automation (ICCCBEA)",
    "url": "https://doi.org/10.1109/iccubea65967.2025.11284273",
    "source": "IEEE",
    "abstract": "Deaf and mute individuals are often disadvantaged in professional interview settings due to limited verbal communication, despite possessing relevant qualifications. This paper presents an AI-driven system designed to facilitate seamless bidirectional communication through real-time sign language recognition and speech synthesis. A custom dataset of ten technical signs, formulated through surveys in special education institutions were recorded using Mediapipe and OpenCV. A three-layer Gated Recurrent Unit (GRU) model achieved 97% training accuracy and 94% test accuracy, outperforming LSTM and BiGRU architectures. Dropout regularization was applied to mitigate overfitting. A locally hosted Ollama LLM model was employed to enhance grammatical accuracy of sign-to-text-to-voice outputs. The interface, developed using Streamlit, supports user interaction, while Firebase manages backend communication. Precision and recall values of 93 % and 92 % respectively demonstrate the system's reliability. This work proposes a deployable, inclusive solution aimed at improving accessibility and opportunity for deaf-mute individuals in professional environments."
  },
  {
    "date": "2025-12-15",
    "title": "Integrating Fuzzy Evaluation Agents and LLM-Based Robots for Multilingual Interactive Applications",
    "authors": "Chang-Shing Lee, Mei-Hui Wang, Chao-Cyuan Yue, Chun-Han Lin, Sheng-Chi Yang, Yi-Jun Lin, Naoyuki Kubota, Eri Sato-Shimokawara",
    "publish": "2025 International Conference on Fuzzy Theory and Its Applications (iFUZZY)",
    "url": "https://doi.org/10.1109/ifuzzy67152.2025.11287789",
    "source": "IEEE",
    "abstract": "This paper proposes an integrated framework that combines fuzzy evaluation agents and LLM-based language-specific robots to support multilingual interactive learning with humancentered AI (HAI) applications. The core techniques of the LLMbased intelligent fuzzy system include: (1) a multi-modal interactive learning mechanism through human and machine co-learning based on HAI with fuzzy knowledge graph (FKG), (2) a real-time cross languages processing agent with quantum fuzzy inference engine for Taiwanese, English, Japanese and Chinese languages, and (3) a fuzzy retrieval-augmented generation (RAG) mechanism that integrates fuzzy semantic search with a large language model (LLM) reasoning based on Llama 3-TAIDE-70B and Gemma 3-TAIDE-12B-Chat models. The proposed framework is applied to multilingual human-machine co-learning scenarios, where both human learners and LLM-based robots engage in interactive applications. Within this setting, the fuzzy evaluation agents and LLM-based robots collaboratively analyze student learning performance, based on data collected from the co-learning environment and quantum fuzzy inference engine. Experimental results demonstrate that the proposed method is effective and feasible for supporting multilingual, human-centered interactive learning environments."
  },
  {
    "date": "2025-12-15",
    "title": "Silverbullet or Mystery Box – LLM-based Soft Skill Classification in Volunteering",
    "authors": "Johannes Schönböck, Christoph Gassner, Ulrich Bodenhofer, Werner Retschitzegger, Wieland Schwinger, Elisabeth Kapsammer, Birgit Pröll, Marianne Lechner, Christoph Angster",
    "publish": "2025 5th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)",
    "url": "https://doi.org/10.1109/iceccme64568.2025.11277972",
    "source": "IEEE",
    "abstract": "Volunteering is a vital pillar of critical infrastructures (CIs) and sustainable development goals (SDGs), fostering, e.g, civil protection or rescue/health/social services. Whether supporting CIs or SDGs, skill-based volunteering is key. Standardized knowledge about skills viable or necessary for certain volunteering opportunities is beneficial in the pre-engagement phase to enable effective skill use as well as in the post-engagement phase to leverage skill gain. It is unclear, however, in how far existing skill classification approaches - currently solely focusing on job postings on the labor market - can handle the nuanced, taskdriven, and prose-like descriptions of predominantly soft skills typical in volunteering opportunities. This paper addresses this gap by presenting a comparison of existing skill classification approaches, initially developed for labor market job postings, in the context of volunteering opportunities. Based on that, we propose using cache- and retrieval-augmented generation techniques for soft skill classification in volunteering, avoiding the high costs of LLM fine-tuning common in current methods. The effectiveness of these lightweight techniques is evaluated both quantitatively and qualitatively using a novel soft skill dataset with expert-labeled volunteering opportunities from a global volunteering platform."
  },
  {
    "date": "2025-12-15",
    "title": "Visionary Co-Driver: Enhancing Driver Perception of Potential Risks With LLM and HUD",
    "authors": "Wei Xiang, Ziyue Lei, Jie Wang, Yingying Huang, Qi Zheng, Tianyi Zhang, An Zhao, Lingyun Sun",
    "publish": "IEEE Transactions on Intelligent Transportation Systems",
    "url": "https://doi.org/10.1109/tits.2025.3634580",
    "source": "IEEE",
    "abstract": "Drivers’ perception of risky situations has always been a challenge in driving. Existing risk-detection methods excel at identifying collisions but face challenges in assessing the behavior of road users in non-collision situations. This paper introduces Visionary Co-Driver, a system that leverages large language models (LLMs) to identify non-collision roadside risks and alert drivers based on their eye movements. Specifically, the system combines video processing algorithms and LLMs to identify potentially risky road users. These risks are dynamically indicated on an adaptive heads-up display interface to enhance drivers’ attention. A user study with 41 drivers confirms that Visionary Co-Driver improves drivers’ risk perception and supports their recognition of roadside risks."
  },
  {
    "date": "2025-12-15",
    "title": "LLM-Based Dynamic Event-Triggered Communication for Multi-UAV Formation Control in Urban Environments",
    "authors": "Jian Gu, Yin Wang, Wen Ji, Zhongxiang Wei, Jingjing Wang",
    "publish": "IEEE Transactions on Cognitive Communications and Networking",
    "url": "https://doi.org/10.1109/tccn.2025.3644040",
    "source": "IEEE",
    "abstract": "As a typical application of the low-altitude economy, UAV collaborative monitoring contributes to urban management and data collection. The dense distribution of urban buildings leads to limited perception and communication constraints, making it challenging for multi-UAV systems to achieve effective unified situational awareness. Therefore, this paper constructs a dynamic event-triggered communication strategy based on a large language model (LLM) and achieves collaborative control of multiple UAVs through deep reinforcement learning. Firstly, a LLM is used to analyze the environment code to actively understand the state of the UAV and the characteristics of the environment, effectively improving adaptability to complex environments. Then, LLM uses Python code to generate communication trigger conditions through semantic reasoning and makes dynamic adjustments to optimize communication timing and reduce network congestion and resource consumption. In addition, this paper proposes a coder-evaluator framework to solve the problems of high cost, low efficiency and intense subjectivity of the reinforcement learning human feedback (RLHF) method in LLM. In this way, the executable code generated by LLM is optimized to ensure the robustness and efficiency of the communication mechanism. Experiments in the high-fidelity AirSim simulation environment demonstrate significant improvements compared to baseline methods: a 26.58% decrease in communication cost, a 4.92% increase in task success rate, and a 21.43% acceleration in convergence speed."
  },
  {
    "date": "2025-12-15",
    "title": "Comprehensive Survey on Security and Reliability of Smart Contracts: Vulnerabilities, Verification Techniques, and Future Directions",
    "authors": "Muralidhara S, Usha B. A",
    "publish": "2025 First International Conference on Intelligent Computing and Communication Systems (CICCS)",
    "url": "https://doi.org/10.1109/ciccs66437.2025.11280299",
    "source": "IEEE",
    "abstract": "The paper highlights the critical need to ensure the reliability of smart contracts and also security of smart contracts, which are agreements execute on their own and have terms that are directly encoded in the code. Smart contracts have transformed a number of industries by offering automated and secure transaction solutions. However, this innovation brings its own set of challenges, including security vulnerabilities and execution errors leading to serious economic and functional consequences. This survey aims to comprehensively address these issues by examining recent research on smart contract security and correctness verification. To lower the risks associated with smart contracts, the framework incorporates efficient techniques and technologies.The survey categorizes and analyzes key vulnerabilities, evaluates existing verification techniques, and proposes best practices for secure smart contract development. Additionally, it identifies research gaps and future directions to enhance the security of smart contracts. By guiding researchers and practitioners toward building more secure and reliable smart contract systems, this effort not only fortifies the backbone of blockchain technology but also encourages the scalability and resilience of decentralized systems in the fast-paced digital age of today with its wide range of use cases"
  },
  {
    "date": "2025-12-15",
    "title": "Multilingual Signature Verification Using Deep Learning: A Three-Phase Modular Approach",
    "authors": "Rushabh Nitin Mistry, Nilkamal More, Suchitra Patil, Chirag Desai",
    "publish": "2025 9th International Conference on Computing, Communication, Control and Automation (ICCCBEA)",
    "url": "https://doi.org/10.1109/iccubea65967.2025.11283938",
    "source": "IEEE",
    "abstract": "Signature verification is an important aspect of digital security in general and specifically in banking, legal, and administrative transactions, where fraud protection and identity authentication are paramount. Previous signature verification technologies have been trained mainly on English-language documents and thus function with reduced capability in multilingual noisy real-world settings such as in India. Such a language/context mismatch may result in strong operational issues, such as higher false rejection rates and lower overall verification accuracy. These are to be addressed with an effective, modular deep learning-based multilingual signature verification system consisting of three autonomous but interconnected phases: detection, cleaning, and matching. At the detection phase, YOLOv5 is utilized for efficiently localizing signature areas in documents with various scripts, supported by signature form-specific anchor tuning and aspect ratio optimization adaptations. The cleaning step employs unsupervised K-Means clustering to separate foreground signature ink from background noise such as stamps, printed lines, and seals to provide cleaner input for matching. Lastly, the matching step employs a Siamese network with a VGG16 backbone to learn discriminative feature embeddings and compare them by cosine similarity, trained on contrastive loss to enhance intra-class compactness and inter-class separability. Easily accessible experimental evaluation of real-world legal and financial documents shows the efficacy of the system with a mean Average Precision (mAP@0.5) of 92.7."
  },
  {
    "date": "2025-12-15",
    "title": "System Verilog-Based Design and Verification of an Optimized AXI4 Interface for Low-Power FPGA Applications",
    "authors": "Swaroop S Harithsa, Vaishnavi Sankar",
    "publish": "2025 First International Conference on Intelligent Computing and Communication Systems (CICCS)",
    "url": "https://doi.org/10.1109/ciccs66437.2025.11280154",
    "source": "IEEE",
    "abstract": "The proposed work demonstrates the implementation and verification of a power-efficient, high-throughput Advanced eXtensible Interface 4 (AXI4) for FPGA (Field Programmable Gate Array) based system on chip designs. Both the AXI Master and Slave modules have been implemented in Verilog and System Verilog with support for burst mode and aggressive transactions. These modules also incorporate power-saving strategies, such as clock gating and adaptive clocking. Compared to standard AXI IP cores, the design delivers approximately 21% lower total power consumption and 32% lower average latency, highlighting its optimization efficiency. The design is rigorously verified using a constrained-random testbench, achieving over 98% functional and 100% assertion coverage. Standard tools such as Questa Sim and EDA Playground are used for simulation and waveform analysis, which validate low-latency, pipelined data handling and verify protocol compliance. The design is validated using randomized constrained testing in System Verilog and synthesized in Xilinx, making it suitable for high-performance embedded systems, including AI, DSP, and real-time computing domains."
  },
  {
    "date": "2025-12-15",
    "title": "A Hybrid Neuro-Symbolic Reasoning Framework for Automated Factual Verification in Conversational AI",
    "authors": "Wei Hong Chin, Yuchen Guo, Chu Kiong Loo, Naoyuki Kubota",
    "publish": "2025 International Conference on Machine Learning and Cybernetics (ICMLC)",
    "url": "https://doi.org/10.1109/icmlc66258.2025.11280070",
    "source": "IEEE",
    "abstract": "This paper presents a novel framework for automated factual verification in conversational AI systems through the integration of symbolic logic, statistical semantics, and graph-based reasoning. Unlike conventional approaches that rely solely on either rule-based systems or large language models (LLMs), our hybrid methodology combines the formal guarantees of logical verification with the flexibility of neural language understanding. We implement this framework as a comprehensive reasoning engine that can ingest organizational policies as documents and automatically validate LLM-generated responses against these policies. The system exhibits improved alignment with organizational policies through its ability to handle natural language variations, perform numeric threshold validations, and execute multi-hop reasoning over complex rules. We discuss the implications of this work for developing more reliable, trustworthy AI assistants that maintain factual consistency with authoritative knowledge sources while preserving the natural conversational capabilities of modern LLMs."
  },
  {
    "date": "2025-12-15",
    "title": "Experimental Verification of Finite Element Modeling for ICT-type DC High-Voltage Power Supply",
    "authors": "Can Jiang, Fangxiong Deng, Yang Wang, Jun Yang",
    "publish": "IEEE Transactions on Applied Superconductivity",
    "url": "https://doi.org/10.1109/tasc.2025.3644828",
    "source": "IEEE",
    "abstract": "The design of a high-voltage power supply on an Insulated Core Transformer (ICT) is investigated in this research, specifically developed for radiation processing applications with core implementation in electron irradiation accelerators. Leakage flux issues are inevitably introduced by the sectioned magnetic core structure adopted in this design, significantly increasing the complexity of the high-voltage power supply design. To develop high-performance electron accelerators, a simulation model was established using finite element analysis software. Rigorous comparison was performed between the simulation results and experimental data from a prototype, effectively verifying the model's accuracy. The design methodology for ICT-type high voltage power supply is thoroughly examined through modeling with ANSYS software. This methodology has been successfully applied to a 200 kV/20 mA high-voltage power supply system for electron accelerators. Critical insights and a reliable foundation for designing high-rated-power high-voltage power supply are provided. The viability of this methodology in designing ICT-type high-voltage power supply is fully demonstrated by the experimentally validated finite element model"
  },
  {
    "date": "2025-12-15",
    "title": "Systematic Design and Experimental Verification of the Avionics Unit for Mars Quadcopter",
    "authors": "Yachao Dong, Qiquan Quan, Bo Tang, Kaijie Zhu, Dewei Tang, Zongquan Deng",
    "publish": "IEEE Transactions on Aerospace and Electronic Systems",
    "url": "https://doi.org/10.1109/taes.2025.3641916",
    "source": "IEEE",
    "abstract": "Based on the joint exploration of Mars through orbiter, rover and other methods of detection, the US Ingenuity Mars helicopter completed the Mars hovering and flight mission, expanding the methods for Mars exploration. Previously, researchers focused primarily on the feasibility of Mars aircraft concepts, with relatively little attention paid to the design of avionics units. Therefore, this paper designs an avionics unit for the Mars quadcopter and validates its feasibility and effectiveness through experiments. First, according to the quadcopter's mechanical structure, we design the hardware architecture of the avionics unit, complete the device selection, and design the avionics boards. Next, we develop the software architecture and its subordinate guidance, navigation, and control subsystems, and develop modular software programs. Then, we define the communication protocol between subsystems' processors and design the data transmission flow. Finally, flight experiments of the prototype demonstrate the operability and effectiveness of the avionics unit. This paper provides a technical reference for the application of the Mars quadcopter in Mars exploration missions."
  },
  {
    "date": "2025-12-15",
    "title": "Design and Verification of Programmable UART with AXI in Application-Specific Integrated Circuits",
    "authors": "Jagadeesh Basavaiah, Poornima H S, Audre Arlene Anthony, Naveen Kumar H N, Mahadevaswamy Mahadevaswamy, Chandrashekar Mohan Patil",
    "publish": "2025 First International Conference on Intelligent Computing and Communication Systems (CICCS)",
    "url": "https://doi.org/10.1109/ciccs66437.2025.11280043",
    "source": "IEEE",
    "abstract": "Modern embedded systems demand high-speed, reliable communication between IP cores, necessitating the integration of robust bus protocols and interfaces. To meet this need, our work focuses on designing reusable, synthesizable modules that ensure performance and verification completeness. This study presents the design and verification of a programmable UART, and an AXI interface tailored for ASIC-based embedded systems. The UART module supports serial data transmission, while AXI provides high-speed bus communication for SoCs. Functional simulation and waveform analysis validate the successful data transmission of UART, and AXI’s performance is confirmed using write/read transactions with proper handshaking. The verification is conducted using Universal Verification Methodology (UVM), achieving 90% functional coverage and confirming protocol compliance. The proposed work ensures reliable, low-latency communication, suitable for high-performance embedded applications."
  },
  {
    "date": "2025-12-15",
    "title": "Mimi: Dynamically Secure Multi-Keyword Retrieval Scheme with Two-Factor Verification_supp1-3642902.pdf",
    "authors": "Xiaofeng Liao",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/tdsc.2025.3642902/mm1",
    "source": "IEEE",
    "abstract": "Existing privacy-preserving multi-keyword retrieval schemes often suffer from reduced retrieval efficiency, lack robust verification mechanisms in dynamic environments, and are prone to symmetric key leakage issues. To address these shortcomings, we propose a dynamic and secure multi-keyword search scheme with a two-factor verification mechanism, named Mimi. Specifically, Mimi first constructs a dynamic verification tree structure to accelerate the verification of the correctness of returned results. Second, it builds an encrypted searchable index that supports sub-linear search time complexity. Third, Mimi incorporates a secure symmetric key exchange protocol to protect the confidentiality of the symmetric key. Furthermore, Mimi supports multi-user search operations without increasing the index construction costs and accommodates dynamic updates to both user roles and data. Through comprehensive security analysis, we demonstrate that Mimi ensures the security of the encrypted searchable inverted index and maintains query indistinguishability for users. Empirical evaluations show that the Mimi scheme is efficient and effective."
  }
]