[
  {
    "date": "2026-2-18",
    "title": "A Critical Review and Evaluation of LLMs for RTL Generation",
    "authors": "Arun Ravindran, Aditya Patra, Vahid Babaey, Suresh Purini",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3665894",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) are emerging as powerful tools for hardware design, with recent work exploring their ability to generate register-transfer level (RTL) code directly from natural-language specifications. This paper presents a critical review and empirical evaluation of LLM-based RTL generation. We examine thirty-one published efforts, classifying their use of techniques such as fine-tuning, reinforcement learning, retrieval-augmented prompting, and multi-agent orchestration across eight methodological dimensions including debugging support, post-RTL metrics, and benchmark development. Building on this synthesis, we experimentally evaluate frontier commercial and open-weight models—GPT-4.1, GPT-4.1-mini, Claude Sonnet 4, and Llama 4 Maverick —on the VerilogEvalV2 and RTLLMv2.0 benchmarks under both single-shot generation and a lightweight ReAct-style reflection loop, with compilation and simulation performed through Icarus Verilog interfaced via the Model Context Protocol (MCP). Results show that these models achieve up to 89.74% on VerilogEval and 96.08% on RTLLM, matching or exceeding prior domain-specific pipelines without specialized fine-tuning. Detailed failure analysis reveals systematic error modes, including FSM mis-sequencing, handshake drift, blocking vs. non-blocking misuse, and state-space oversimplification. Finally, we outline a forward-looking research roadmap toward natural-language-to-System-on-Chip (SoC) design, emphasizing realistic benchmarks and open flows, richer specification formalisms, AI–human collaborative design environments, and system-level feedback that spans physical design, firmware, and design space exploration. Together, this work provides both a synthesis of recent advances and a baseline evaluation of frontier LLMs, highlighting opportunities and challenges in moving toward AI-native electronic design automation.",
    "title_zh": "对用于RTL生成的大型语言模型的批判性回顾与评估",
    "abstract_zh": "大型语言模型（LLMs）正在成为硬件设计中的强大工具，最近的研究探索了它们从自然语言规范直接生成寄存器传输级（RTL）代码的能力。本文对基于LLM的RTL生成进行了批判性回顾和实证评估。我们审查了三十一项已发表的研究，分类了它们在八个方法维度上使用的技术，如微调、强化学习、检索增强提示和多代理协调，包括调试支持、后RTL指标和基准开发。在此综合的基础上，我们对前沿的商业和开放权重模型——GPT-4.1、GPT-4.1-mini、Claude Sonnet 4和Llama 4 Maverick——在VerilogEvalV2和RTLLMv2.0基准上进行了实验评估，采用单次生成和轻量级ReAct风格反思循环，通过Icarus Verilog与模型上下文协议（MCP）接口进行编译和仿真。结果显示，这些模型在VerilogEval上达到89.74%，在RTLLM上达到96.08%，匹配或超越了先前的领域特定管道而无需专门的微调。详细的失败分析揭示了系统性错误模式，包括有限状态机（FSM）错误排序、握手漂移、阻塞与非阻塞误用以及状态空间过度简化。最后，我们概述了面向自然语言到片上系统（SoC）设计的前瞻性研究路线图，强调现实的基准和开放流程、更丰富的规范形式、AI-人类协作设计环境以及跨越物理设计、固件和设计空间探索的系统级反馈。总之，这项工作提供了对近期进展的综合和对前沿LLM的基准评估，突出了向AI原生电子设计自动化迈进的机遇和挑战。"
  }
]