[
  {
    "date": "2026-01-29",
    "title": "PowerGenie: Analytically-Guided Evolutionary Discovery of Superior Reconfigurable Power Converters",
    "authors": "Jian Gao, Yiwei Zou, Abhishek Pradhan, Wenhao Huang, Yumin Su, Kaiyuan Yang, Xuan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.21984v1",
    "source": "arXiv",
    "abstract": "Discovering superior circuit topologies requires navigating an exponentially large design space-a challenge traditionally reserved for human experts. Existing AI methods either select from predefined templates or generate novel topologies at a limited scale without rigorous verification, leaving large-scale performance-driven discovery underexplored. We present PowerGenie, a framework for automated discovery of higher-performance reconfigurable power converters at scale. PowerGenie introduces: (1) an automated analytical framework that determines converter functionality and theoretical performance limits without component sizing or SPICE simulation, and (2) an evolutionary finetuning method that co-evolves a generative model with its training distribution through fitness selection and uniqueness verification. Unlike existing methods that suffer from mode collapse and overfitting, our approach achieves higher syntax validity, function validity, novelty rate, and figure-of-merit (FoM). PowerGenie discovers a novel 8-mode reconfigurable converter with 23% higher FoM than the best training topology. SPICE simulations confirm average absolute efficiency gains of 10% across 8 modes and up to 17% at a single mode. Code is available at https://github.com/xz-group/PowerGenie.",
    "title_zh": "PowerGenie：通过分析指导的进化发现优越的可重构电力转换器",
    "abstract_zh": "发现优越的电路拓扑需要在一个指数级庞大的设计空间中导航——这一挑战传统上是人类专家的专属领域。现有的人工智能方法要么从预定义的模板中选择，要么在有限的规模上生成新的拓扑结构而没有严格的验证，导致大规模性能驱动的发现仍未被充分探索。我们提出了PowerGenie，一个用于自动发现高性能可重构电力转换器的框架。PowerGenie引入了：(1) 一个自动化分析框架，该框架在不进行组件尺寸调整或SPICE仿真的情况下确定转换器的功能和理论性能极限，以及(2) 一个进化微调方法，通过适应度选择和独特性验证共同进化生成模型及其训练分布。与现有方法因模式崩溃和过拟合而受限不同，我们的方法实现了更高的语法有效性、功能有效性、新颖性率和优值（FoM）。PowerGenie发现了一种新颖的8模式可重构转换器，其FoM比最佳训练拓扑高23%。SPICE仿真确认在8种模式下平均绝对效率提高10%，在单一模式下最高提高17%。代码可在https://github.com/xz-group/PowerGenie获取。"
  },
  {
    "date": "2026-01-29",
    "title": "White-Box Op-Amp Design via Human-Mimicking Reasoning",
    "authors": "Zihao Chen, Jiayin Wang, Ziyi Sun, Ji Zhuang, Jinyi Shen, Xiaoyue Ke, Li Shang, Xuan Zeng, Fan Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.21321v1",
    "source": "arXiv",
    "abstract": "This brief proposes \\emph{White-Op}, an interpretable operational amplifier (op-amp) parameter design framework based on the human-mimicking reasoning of large-language-model agents. We formalize the implicit human reasoning mechanism into explicit steps of \\emph{\\textbf{introducing hypothetical constraints}}, and develop an iterative, human-like \\emph{\\textbf{hypothesis-verification-decision}} workflow. Specifically, the agent is guided to introduce hypothetical constraints to derive and properly regulate positions of symbolically tractable poles and zeros, thus formulating a closed-form mathematical optimization problem, which is then solved programmatically and verified via simulation. Theory-simulation result analysis guides the decision-making for refinement. Experiments on 9 op-amp topologies show that, unlike the uninterpretable black-box baseline which finally fails in 5 topologies, White-Op achieves reliable, interpretable behavioral-level designs with only 8.52\\% theoretical prediction error and the design functionality retains after transistor-level mapping for all topologies. White-Op is open-sourced at \\textcolor{blue}{https://github.com/zhchenfdu/whiteop}.",
    "title_zh": "通过模拟人类推理进行白盒运算放大器设计",
    "abstract_zh": "本文提出了一种名为\\emph{White-Op}的可解释运算放大器（op-amp）参数设计框架，该框架基于大型语言模型代理的模拟人类推理。我们将隐含的人类推理机制形式化为明确的步骤，即\\emph{\\textbf{引入假设约束}}，并开发了一种迭代的、类似人类的\\emph{\\textbf{假设-验证-决策}}工作流程。具体而言，代理被引导引入假设约束，以推导并适当调节符号上可处理的极点和零点的位置，从而形成一个封闭形式的数学优化问题，然后通过编程解决并通过仿真验证。理论-仿真结果分析指导决策以进行优化。在9种运算放大器拓扑结构的实验中，与最终在5种拓扑结构中失败的不可解释黑盒基线不同，White-Op实现了可靠的、可解释的行为级设计，理论预测误差仅为8.52%，并且在所有拓扑结构中，设计功能在晶体管级映射后仍然保持。White-Op已在\\textcolor{blue}{https://github.com/zhchenfdu/whiteop}开源。"
  }
]