[
  {
    "date": "2025-12-29",
    "title": "Analysis of kinetic-diffusion Monte Carlo simulation and source term estimation scheme in nuclear fusion applications",
    "authors": "Zhirui Tang, Julian Koellermeier, Emil Løvbak, Giovanni Samaey",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23580v1",
    "source": "arXiv",
    "abstract": "In plasma edge simulations, the behavior of neutral particles is often described by a Boltzmann--BGK equation. Solving this kinetic equation and estimating the moments of its solution are essential tasks, typically carried out using Monte Carlo (MC) methods. However, for large-sized reactors, like ITER and DEMO, high collision rates lead to a substantial computational cost. To accelerate the calculation, an asymptotic-preserving kinetic-diffusion Monte Carlo (KDMC) simulation method (Mortier et al., SIAM J. Sci. Comput., 2022) and a corresponding fluid estimation technique (Mortier et al., Contrib. Plasma Phys., 2022) have recently been proposed. In this work, we present a comprehensive analysis of the convergence of KDMC combined with the associated fluid estimation. The analysis consists of proving theoretical upper bounds for both KDMC and the fluid estimation, and numerical verifications of these bounds. In addition, we compare the analyzed algorithm with a purely fluid-based method using the fully kinetic MC method as a reference. The algorithm consistently achieves lower error than the fluid-based method, and even one order of magnitude lower in a fusion-relevant test case. Moreover, the algorithm exhibits a significant speedup compared to the reference kinetic MC method. Overall, our analysis confirms the effectiveness of KDMC with the associated fluid estimation in nuclear fusion applications."
  },
  {
    "date": "2025-12-29",
    "title": "Clauser-Horne-Shimony-Holt Bell-inequality Violability with the Full Poincaré-Bloch Sphere",
    "authors": "Carlos Cardoso-Isidoro, Enrique J. Galvez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23550v1",
    "source": "arXiv",
    "abstract": "Linearly polarized projections are the tacit means for performing Clauser-Horne-Shimony-Holt (CHSH) Bell-inequality tests using polarization-entangled photon pairs. The inequality is valid for all states on the Poincaré-Bloch sphere, but few laboratory studies have investigated violations with the full sphere. In this article, we explore the experimental verifications of the predicted violations of the CHSH inequality with Bell and non-Bell states with same and different linear and elliptically polarized basis states for each photon. We find that Bell states violate CHSH when using the same basis for both photons, regardless of their ellipticity, whereas they show no violations for photon projections in different bases. We found non-Bell maximally-entangled states for which the converse is true."
  },
  {
    "date": "2025-12-29",
    "title": "Beyond Correctness: Exposing LLM-generated Logical Flaws in Reasoning via Multi-step Automated Theorem Proving",
    "authors": "Xinyi Zheng, Ningke Li, Xiaokun Luan, Kailong Wang, Ling Shi, Meng Sun, Haoyu Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23511v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive reasoning capabilities, leading to their adoption in high-stakes domains such as healthcare, law, and scientific research. However, their reasoning often contains subtle logical errors masked by fluent language, posing significant risks for critical applications. While existing approaches like fact-checking, self-consistency methods, and rule-based validation provide partial solutions, they fail to detect complex logical flaws in multi-step reasoning. To overcome these challenges, we present MATP, an evaluation framework for systematically verifying LLM reasoning via Multi-step Automatic Theorem Proving. MATP translates natural language reasoning into First-Order Logic (FOL) and applies automated theorem provers to assess step-by-step logical validity. This approach identifies hidden logical errors and provides fine-grained classifications of reasoning correctness. Evaluations on a benchmark comprising 10,830 reasoning instances generated by 10 LLMs across tasks from PrOntoQA-OOD, ProofWriter, and FOLIO show that MATP surpasses prompting-based baselines by over 42 percentage points in reasoning step verification. It further reveals model-level disparities, with reasoning models generating more logically coherent outputs than general models. These results demonstrate MATP's potential to enhance the trustworthiness of LLM-generated reasoning."
  },
  {
    "date": "2025-12-29",
    "title": "Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation",
    "authors": "Toqeer Ali Syed, Mohammad Riyaz Belgaum, Salman Jan, Asadullah Abdullah Khan, Saad Said Alqahtani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23480v1",
    "source": "arXiv",
    "abstract": "The software supply chain attacks are becoming more and more focused on trusted development and delivery procedures, so the conventional post-build integrity mechanisms cannot be used anymore. The available frameworks like SLSA, SBOM and in toto are majorly used to offer provenance and traceability but do not have the capabilities of actively identifying and removing vulnerabilities in software production. The current paper includes an example of agentic artificial intelligence (AI) based on autonomous software supply chain security that combines large language model (LLM)-based reasoning, reinforcement learning (RL), and multi-agent coordination. The suggested system utilizes specialized security agents coordinated with the help of LangChain and LangGraph, communicates with actual CI/CD environments with the Model Context Protocol (MCP), and documents all the observations and actions in a blockchain security ledger to ensure integrity and auditing. Reinforcement learning can be used to achieve adaptive mitigation strategies that consider the balance between security effectiveness and the operational overhead, and LLMs can be used to achieve semantic vulnerability analysis, as well as explainable decisions. This framework is tested based on simulated pipelines, as well as, actual world CI/CD integrations on GitHub Actions and Jenkins, including injection attacks, insecure deserialization, access control violations, and configuration errors. Experimental outcomes indicate better detection accuracy, shorter mitigation latency and reasonable build-time overhead than rule-based, provenance only and RL only baselines. These results show that agentic AI can facilitate the transition to self defending, proactive software supply chains rather than reactive verification ones."
  },
  {
    "date": "2025-12-29",
    "title": "Fuzzilicon: A Post-Silicon Microcode-Guided x86 CPU Fuzzer",
    "authors": "Johannes Lenzen, Mohamadreza Rostami, Lichao Wu, Ahmad-Reza Sadeghi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23438v1",
    "source": "arXiv",
    "abstract": "Modern CPUs are black boxes, proprietary, and increasingly characterized by sophisticated microarchitectural flaws that evade traditional analysis. While some of these critical vulnerabilities have been uncovered through cumbersome manual effort, building an automated and systematic vulnerability detection framework for real-world post-silicon processors remains a challenge. In this paper, we present Fuzzilicon, the first post-silicon fuzzing framework for real-world x86 CPUs that brings deep introspection into the microcode and microarchitectural layers. Fuzzilicon automates the discovery of vulnerabilities that were previously only detectable through extensive manual reverse engineering, and bridges the visibility gap by introducing microcode-level instrumentation. At the core of Fuzzilicon is a novel technique for extracting feedback directly from the processor's microarchitecture, enabled by reverse-engineering Intel's proprietary microcode update interface. We develop a minimally intrusive instrumentation method and integrate it with a hypervisor-based fuzzing harness to enable precise, feedback-guided input generation, without access to Register Transfer Level (RTL). Applied to Intel's Goldmont microarchitecture, Fuzzilicon introduces 5 significant findings, including two previously unknown microcode-level speculative-execution vulnerabilities. Besides, the Fuzzilicon framework automatically rediscover the $μ$Spectre class of vulnerabilities, which were detected manually in the previous work. Fuzzilicon reduces coverage collection overhead by up to 31$\\times$ compared to baseline techniques and achieves 16.27% unique microcode coverage of hookable locations, the first empirical baseline of its kind. As a practical, coverage-guided, and scalable approach to post-silicon fuzzing, Fuzzilicon establishes a new foundation to automate the discovery of complex CPU vulnerabilities."
  },
  {
    "date": "2025-12-29",
    "title": "interID -- An Ecosystem-agnostic Verifier Application for Self-sovereign Identity",
    "authors": "Hakan Yildiz, Axel Küpper",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23383v1",
    "source": "arXiv",
    "abstract": "Self-Sovereign Identity is a transformative paradigm in digital identity management, empowering individuals with full control over their credentials. However, the coexistence of diverse SSI ecosystems, such as the European Digital Identity and the European Blockchain Services Infrastructure, poses significant challenges for cross-ecosystem interoperability due to technological and trust framework differences. This paper introduces \\textit{interID}, a modular credential verification application that addresses this fragmentation by orchestrating ecosystem-specific verifier services. Our key contributions include: (1) an ecosystem-agnostic orchestration layer that interfaces with multiple SSI verification services, (2) a unified API that abstracts underlying protocol complexities for service providers, and (3) a practical implementation that bridges three major SSI ecosystems: Hyperledger Indy/Aries, EBSI, and EUDI. Evaluation results demonstrate that interID successfully verifies credentials across all tested wallets with minimal performance overhead, while maintaining a flexible architecture that can be extended to accept credentials from additional SSI ecosystems. This work offers both a technical solution and architectural pattern for achieving interoperability in SSI verifier implementations."
  },
  {
    "date": "2025-12-29",
    "title": "AGRO-SQL: Agentic Group-Relative Optimization with High-Fidelity Data Synthesis",
    "authors": "Cehua Yang, Dongyu Xiao, Junming Lin, Yuyang Song, Hanxu Yan, Shawn Guo, Wei Zhang, Jian Yang, Mingjie Tang, Bryan Dai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23366v1",
    "source": "arXiv",
    "abstract": "The advancement of Text-to-SQL systems is currently hindered by the scarcity of high-quality training data and the limited reasoning capabilities of models in complex scenarios. In this paper, we propose a holistic framework that addresses these issues through a dual-centric approach. From a Data-Centric perspective, we construct an iterative data factory that synthesizes RL-ready data characterized by high correctness and precise semantic-logic alignment, ensured by strict verification. From a Model-Centric perspective, we introduce a novel Agentic Reinforcement Learning framework. This framework employs a Diversity-Aware Cold Start stage to initialize a robust policy, followed by Group Relative Policy Optimization (GRPO) to refine the agent's reasoning via environmental feedback. Extensive experiments on BIRD and Spider benchmarks demonstrate that our synergistic approach achieves state-of-the-art performance among single-model methods."
  },
  {
    "date": "2025-12-29",
    "title": "A space-time extension of a conservative two-fluid cut-cell diffusion method for moving geometries",
    "authors": "Louis Libat, Can Selçuk, Eric Chénier, Vincent Le Chenadec",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23358v1",
    "source": "arXiv",
    "abstract": "We present a space-time extension of a conservative Cartesian cut-cell finite-volume method for two-phase diffusion in prescribed-motion geometries. The formulation follows a two-fluid approach: one scalar field is solved in each phase with discontinuous material properties, coupled by sharp interface conditions enforcing flux continuity and jump laws. To handle moving boundaries on a fixed Cartesian grid, the discrete balance is written over phase-restricted space-time control volumes, whose geometric moments (swept volumes and apertures) are used as weights in the finite-volume operators. This construction naturally accounts for the creation and destruction of cut cells (fresh/dead-cell events) and yields strict discrete conservation. The resulting scheme retains the algebraic structure of the static cut-cell formulation while incorporating motion through local geometric weights and interface coupling operators. A series of verification and validation tests in two and three dimensions demonstrate super-linear accuracy in space, robust behavior under repeated topology changes and conservation across strong coefficient jumps and moving interfaces. The proposed space-time cut-cell framework provides a conservative building block for multiphase transport in evolving geometries and a foundation for future free-boundary extensions such as Stefan-type phase change."
  },
  {
    "date": "2025-12-29",
    "title": "Verifying Asynchronous Hyperproperties in Reactive Systems",
    "authors": "Raven Beutner, Bernd Finkbeiner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23344v1",
    "source": "arXiv",
    "abstract": "Hyperproperties are system properties that relate multiple execution traces and commonly occur when specifying information-flow and security policies. Logics like HyperLTL utilize explicit quantification over execution traces to express temporal hyperproperties in reactive systems, i.e., hyperproperties that reason about the temporal behavior along infinite executions. An often unwanted side-effect of such logics is that they compare the quantified traces synchronously. This prohibits the logics from expressing properties that compare multiple traces asynchronously, such as Zdancewic and Myers's observational determinism, McLean's non-inference, or stuttering refinement. We study the model-checking problem for a variant of asynchronous HyperLTL (A-HLTL), a temporal logic that can express hyperproperties where multiple traces are compared across timesteps. In addition to quantifying over system traces, A-HLTL features secondary quantification over stutterings of these traces. Consequently, A-HLTL allows for a succinct specification of many widely used asynchronous hyperproperties. Model-checking A-HLTL requires finding suitable stutterings, which, thus far, has been only possible for very restricted fragments or terminating systems. In this paper, we propose a novel game-based approach for the verification of arbitrary $\\forall^*\\exists^*$ A-HLTL formulas in reactive systems. In our method, we consider the verification as a game played between a verifier and a refuter, who challenge each other by controlling parts of the underlying traces and stutterings. A winning strategy for the verifier then corresponds to concrete witnesses for existentially quantified traces and asynchronous alignments for existentially quantified stutterings. We identify fragments for which our game-based interpretation is complete and thus constitutes a finite-state decision procedure."
  },
  {
    "date": "2025-12-29",
    "title": "An Empirical Study of Generative AI Adoption in Software Engineering",
    "authors": "Görkem Giray, Onur Demirörs, Marcos Kalinowski, Daniel Mendez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23327v1",
    "source": "arXiv",
    "abstract": "Context. GenAI tools are being increasingly adopted by practitioners in SE, promising support for several SE activities. Despite increasing adoption, we still lack empirical evidence on how GenAI is used in practice, the benefits it provides, the challenges it introduces, and its broader organizational and societal implications. Objective. This study aims to provide an overview of the status of GenAI adoption in SE. It investigates the status of GenAI adoption, associated benefits and challenges, institutionalization of tools and techniques, and anticipated long term impacts on SE professionals and the community. Results. The results indicate a wide adoption of GenAI tools and how they are deeply integrated into daily SE work, particularly for implementation, verification and validation, personal assistance, and maintenance-related tasks. Practitioners report substantial benefits, most notably reduction in cycle time, quality improvements, enhanced support in knowledge work, and productivity gains. However, objective measurement of productivity and quality remains limited in practice. Significant challenges persist, including incorrect or unreliable outputs, prompt engineering difficulties, validation overhead, security and privacy concerns, and risks of overreliance. Institutionalization of tools and techniques seems to be common, but it varies considerably, with a strong focus on tool access and less emphasis on training and governance. Practitioners expect GenAI to redefine rather than replace their roles, while expressing moderate concern about job market contraction and skill shifts."
  },
  {
    "date": "2025-12-29",
    "title": "On Conformant Planning and Model-Checking of $\\exists^*\\forall^*$ Hyperproperties",
    "authors": "Raven Beutner, Bernd Finkbeiner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23324v1",
    "source": "arXiv",
    "abstract": "We study the connection of two problems within the planning and verification community: Conformant planning and model-checking of hyperproperties. Conformant planning is the task of finding a sequential plan that achieves a given objective independent of non-deterministic action effects during the plan's execution. Hyperproperties are system properties that relate multiple execution traces of a system and, e.g., capture information-flow and fairness policies. In this paper, we show that model-checking of $\\exists^*\\forall^*$ hyperproperties is closely related to the problem of computing a conformant plan. Firstly, we show that we can efficiently reduce a hyperproperty model-checking instance to a conformant planning instance, and prove that our encoding is sound and complete. Secondly, we establish the converse direction: Every conformant planning problem is, itself, a hyperproperty model-checking task."
  },
  {
    "date": "2025-12-29",
    "title": "BRkNN-light: Batch Processing of Reverse k-Nearest Neighbor Queries for Moving Objects on Road Networks",
    "authors": "Anbang Song, Ziqiang Yu, Wei Liu, Yating Xu, Mingjin Tao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23298v1",
    "source": "arXiv",
    "abstract": "The Reverse $k$-Nearest Neighbor (R$k$NN) query over moving objects on road networks seeks to find all moving objects that consider the specified query point as one of their $k$ nearest neighbors. In location based services, many users probably submit R$k$NN queries simultaneously. However, existing methods largely overlook how to efficiently process multiple such queries together, missing opportunities to share redundant computations and thus reduce overall processing costs. To address this, this work is the first to explore batch processing of multiple R$k$NN queries, aiming to minimize total computation by sharing duplicate calculations across queries. To tackle this issue, we propose the BR$k$NN-Light algorithm, which uses rapid verification and pruning strategies based on geometric constraints, along with an optimized range search technique, to speed up the process of identifying the R$k$NNs for each query. Furthermore, it proposes a dynamic distance caching mechanism to enable computation reuse when handling multiple queries, thereby significantly reducing unnecessary computations. Experiments on multiple real-world road networks demonstrate the superiority of the BR$k$NN-Light algorithm on the processing of batch queries."
  },
  {
    "date": "2025-12-29",
    "title": "The Dawn of Agentic EDA: A Survey of Autonomous Digital Chip Design",
    "authors": "Zelin Zang, Yuhang Song, Bingo Wing-Kuen Ling, Aili Wang, Fuji Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23189v1",
    "source": "arXiv",
    "abstract": "This survey provides a comprehensive overview of the integration of Generative AI and Agentic AI within the field of Digital Electronic Design Automation (EDA). The paper first reviews the paradigmatic evolution from traditional Computer-Aided Design (CAD) to AI-assisted EDA (AI4EDA), and finally to the emerging AI-Native and Agentic design paradigms. We detail the application of these paradigms across the digital chip design flow, including the construction of agentic cognitive architectures based on multimodal foundation models, frontend RTL code generation and intelligent verification, and backend physical design featuring algorithmic innovations and tool orchestration. We validate these methodologies through integrated case studies, demonstrating practical viability from microarchitecture definition to GDSII. Special emphasis is placed on the potential for cross-stage feedback loops where agents utilize backend PPA metrics to autonomously refine frontend logic. Furthermore, this survey delves into the dual-faceted impact on security, covering novel adversarial risks, automated vulnerability repair, and privacy-preserving infrastructure. Finally, the paper critically summarizes current challenges related to hallucinations, data scarcity, and black-box tools, and outlines future trends towards L4 autonomous chip design. Ultimately, this work aims to define the emerging field of Agentic EDA and provide a strategic roadmap for the transition from AI-assisted tools to fully autonomous design engineers."
  },
  {
    "date": "2025-12-28",
    "title": "Multimodal Fact-Checking: An Agent-based Approach",
    "authors": "Danni Xu, Shaojing Fan, Xuanang Cheng, Mohan Kankanhalli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22933v1",
    "source": "arXiv",
    "abstract": "The rapid spread of multimodal misinformation poses a growing challenge for automated fact-checking systems. Existing approaches, including large vision language models (LVLMs) and deep multimodal fusion methods, often fall short due to limited reasoning and shallow evidence utilization. A key bottleneck is the lack of dedicated datasets that provide complete real-world multimodal misinformation instances accompanied by annotated reasoning processes and verifiable evidence. To address this limitation, we introduce RW-Post, a high-quality and explainable dataset for real-world multimodal fact-checking. RW-Post aligns real-world multimodal claims with their original social media posts, preserving the rich contextual information in which the claims are made. In addition, the dataset includes detailed reasoning and explicitly linked evidence, which are derived from human written fact-checking articles via a large language model assisted extraction pipeline, enabling comprehensive verification and explanation. Building upon RW-Post, we propose AgentFact, an agent-based multimodal fact-checking framework designed to emulate the human verification workflow. AgentFact consists of five specialized agents that collaboratively handle key fact-checking subtasks, including strategy planning, high-quality evidence retrieval, visual analysis, reasoning, and explanation generation. These agents are orchestrated through an iterative workflow that alternates between evidence searching and task-aware evidence filtering and reasoning, facilitating strategic decision-making and systematic evidence analysis. Extensive experimental results demonstrate that the synergy between RW-Post and AgentFact substantially improves both the accuracy and interpretability of multimodal fact-checking."
  },
  {
    "date": "2025-12-28",
    "title": "Optimal Threshold for Fracton Codes and Nearly Saturated Code Capacity in Three Dimensions",
    "authors": "Giovanni Canossa, Lode Pollet, Miguel A. Martin-Delgado, Hao Song, Ke Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22888v1",
    "source": "arXiv",
    "abstract": "Fracton codes have been intensively studied as novel topological states of matter, yet their fault-tolerant properties remain largely unexplored. Here, we investigate the optimal thresholds of self-dual fracton codes, in particular the checkerboard code, against stochastic Pauli noise. By utilizing a statistical-mechanical mapping combined with large-scale parallel tempering Monte Carlo simulations, we calculate the optimal code capacity of the checkerboard code to be $p_{th} \\simeq 0.108(2)$. This value is the highest among known three-dimensional codes and nearly saturates the theoretical limit for topological codes. Our results further validate the generalized entropy relation for two mutually dual models, $H(p_{th}) + H(\\tilde{p}_{th}) \\approx 1$, and extend its applicability beyond standard topological codes. This verification indicates the Haah's code also possesses a code capacity near the theoretical limit $p_{th} \\approx 0.11$. These findings highlight fracton codes as highly resilient quantum memory and demonstrate the utility of duality techniques in analyzing intricate quantum error-correcting codes."
  },
  {
    "date": "2025-12-27",
    "title": "Raven: Mining Defensive Patterns in Ethereum via Semantic Transaction Revert Invariants Categories",
    "authors": "Mojtaba Eshghie, Melissa Mazura, Alexandre Bartel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22616v1",
    "source": "arXiv",
    "abstract": "We frame Ethereum transactions reverted by invariants-require(<invariant>)/ assert(<invariant>)/if (<invariant>) revert statements in the contract implementation-as a positive signal of active on-chain defenses. Despite their value, the defensive patterns in these transactions remain undiscovered and underutilized in security research. We present Raven, a framework that aligns reverted transactions to the invariant causing the reversion in the smart contract source code, embeds these invariants using our BERT-based fine-tuned model, and clusters them by semantic intent to mine defensive invariant categories on Ethereum. Evaluated on a sample of 20,000 reverted transactions, Raven achieves cohesive and meaningful clusters of transaction-reverting invariants. Manual expert review of the mined 19 semantic clusters uncovers six new invariant categories absent from existing invariant catalogs, including feature toggles, replay prevention, proof/signature verification, counters, caller-provided slippage thresholds, and allow/ban/bot lists. To demonstrate the practical utility of this invariant catalog mining pipeline, we conduct a case study using one of the newly discovered invariant categories as a fuzzing oracle to detect vulnerabilities in a real-world attack. Raven thus can map Ethereum's successful defenses. These invariant categories enable security researchers to develop analysis tools based on data-driven security oracles extracted from the smart contracts' working defenses."
  },
  {
    "date": "2025-12-27",
    "title": "Nightjar: Dynamic Adaptive Speculative Decoding for Large Language Models Serving",
    "authors": "Rui Li, Zhaoning Zhang, Libo Zhang, Huaimin Wang, Xiang Fu, Zhiquan Lai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22420v1",
    "source": "arXiv",
    "abstract": "Speculative decoding (SD) accelerates LLM inference by verifying draft tokens in parallel. However, this method presents a critical trade-off: it improves throughput in low-load, memory-bound systems but degrades performance in high-load, compute-bound environments due to verification overhead. Current SD implementations use a fixed speculative length, failing to adapt to dynamic request rates and creating a significant performance bottleneck in real-world serving scenarios. To overcome this, we propose Nightjar, a novel learning-based algorithm for adaptive speculative inference that adjusts to request load by dynamically selecting the optimal speculative length for different batch sizes and even disabling speculative decoding when it provides no benefit. Experiments show that Nightjar achieves up to 14.8% higher throughput and 20.2% lower latency compared to standard speculative decoding, demonstrating robust efficiency for real-time serving."
  },
  {
    "date": "2025-12-27",
    "title": "Hallucination Detection and Evaluation of Large Language Model",
    "authors": "Chenggong Zhang, Haopeng Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22416v1",
    "source": "arXiv",
    "abstract": "Hallucinations in Large Language Models (LLMs) pose a significant challenge, generating misleading or unverifiable content that undermines trust and reliability. Existing evaluation methods, such as KnowHalu, employ multi-stage verification but suffer from high computational costs. To address this, we integrate the Hughes Hallucination Evaluation Model (HHEM), a lightweight classification-based framework that operates independently of LLM-based judgments, significantly improving efficiency while maintaining high detection accuracy. We conduct a comparative analysis of hallucination detection methods across various LLMs, evaluating True Positive Rate (TPR), True Negative Rate (TNR), and Accuracy on question-answering (QA) and summarization tasks. Our results show that HHEM reduces evaluation time from 8 hours to 10 minutes, while HHEM with non-fabrication checking achieves the highest accuracy \\(82.2\\%\\) and TPR \\(78.9\\%\\). However, HHEM struggles with localized hallucinations in summarization tasks. To address this, we introduce segment-based retrieval, improving detection by verifying smaller text components. Additionally, our cumulative distribution function (CDF) analysis indicates that larger models (7B-9B parameters) generally exhibit fewer hallucinations, while intermediate-sized models show higher instability. These findings highlight the need for structured evaluation frameworks that balance computational efficiency with robust factual validation, enhancing the reliability of LLM-generated content."
  },
  {
    "date": "2025-12-26",
    "title": "HalluMat: Detecting Hallucinations in LLM-Generated Materials Science Content Through Multi-Stage Verification",
    "authors": "Bhanu Prakash Vangala, Sajid Mahmud, Pawan Neupane, Joel Selvaraj, Jianlin Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22396v1",
    "source": "arXiv",
    "abstract": "Artificial Intelligence (AI), particularly Large Language Models (LLMs), is transforming scientific discovery, enabling rapid knowledge generation and hypothesis formulation. However, a critical challenge is hallucination, where LLMs generate factually incorrect or misleading information, compromising research integrity. To address this, we introduce HalluMatData, a benchmark dataset for evaluating hallucination detection methods, factual consistency, and response robustness in AI-generated materials science content. Alongside this, we propose HalluMatDetector, a multi-stage hallucination detection framework that integrates intrinsic verification, multi-source retrieval, contradiction graph analysis, and metric-based assessment to detect and mitigate LLM hallucinations. Our findings reveal that hallucination levels vary significantly across materials science subdomains, with high-entropy queries exhibiting greater factual inconsistencies. By utilizing HalluMatDetector verification pipeline, we reduce hallucination rates by 30% compared to standard LLM outputs. Furthermore, we introduce the Paraphrased Hallucination Consistency Score (PHCS) to quantify inconsistencies in LLM responses across semantically equivalent queries, offering deeper insights into model reliability."
  },
  {
    "date": "2025-12-26",
    "title": "Symbolic Specification and Reasoning for Quantum Data and Operations",
    "authors": "Mingsheng Ying",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22383v1",
    "source": "arXiv",
    "abstract": "In quantum information and computation research, symbolic methods have been widely used for human specification and reasoning about quantum states and operations. At the same time, they are essential for ensuring the scalability and efficiency of automated reasoning and verification tools for quantum algorithms and programs. However, a formal theory for symbolic specification and reasoning about quantum data and operations is still lacking, which significantly limits the practical applicability of automated verification techniques in quantum computing. In this paper, we present a general logical framework, called Symbolic Operator Logic $\\mathbf{SOL}$, which enables symbolic specification and reasoning about quantum data and operations. Within this framework, a classical first-order logical language is embedded into a language of formal operators used to specify quantum data and operations, including their recursive definitions. This embedding allows reasoning about their properties modulo a chosen theory of the underlying classical data (e.g., Boolean algebra or group theory), thereby leveraging existing automated verification tools developed for classical computing. It should be emphasised that this embedding of classical first-order logic into $\\mathbf{SOL}$ is precisely what makes the symbolic method possible. We envision that this framework can provide a conceptual foundation for the formal verification and automated theorem proving of quantum computation and information in proof assistants such as Lean, Coq, and related systems."
  },
  {
    "date": "2025-12-30",
    "title": "Tracing the Logic: Evaluating LLM Reasoning Paths in RTL Generation",
    "authors": "Matthew DeLorenzo, Kevin Tieu, Jeyavijayan Rajendran",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00115",
    "source": "IEEE",
    "abstract": "Large reasoning models (LRMs) have recently demonstrated strong improvements in complex problem-solving by leveraging inference-time reasoning strategies. In hardware design, these approaches have been applied to Verilog generation, enabling models to produce more functional designs compared to conventional LLMs. However, while the effectiveness of reasoning-augmented models has been established, the intermediate reasoning traces themselves remain underexplored. This work presents the first systematic framework for evaluating reasoning traces in Verilog generation. We analyze state-of-the-art reasoning-trained models using a suite of text-based, semantic, and structural metrics that quantify redundancy, coherence, and alignment between reasoning tokens and final Verilog outputs. Our evaluation highlights both the advantages and inefficiencies of current reasoning approaches: while extended reasoning can support functional correctness, it often introduces significant redundancy and inference overhead. These findings point toward the need for more concise, purposeful reasoning strategies. By characterizing the quality of reasoning traces, this work provides new insights and directions for optimizing reasoning structures in LLM-assisted hardware design."
  },
  {
    "date": "2025-12-30",
    "title": "CircuitGuard: Mitigating LLM Memorization in RTL Code Generation Against IP Leakage",
    "authors": "Nowfel Mashnoor, Mohammad Akyash, Hadi Kamali, Kimia Azar",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00117",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in generative tasks, including register-transfer level (RTL) hardware synthesis. However, their tendency to memorize training data poses critical risks when proprietary or security-sensitive designs are unintentionally exposed during inference. While prior work has examined memorization in natural language, RTL introduces unique challenges: In RTL, structurally different implementations (e.g., behavioral vs. gatelevel descriptions) can realize the same hardware, leading to intellectual property (IP) leakage (full or partial) even without verbatim overlap. Conversely, even small syntactic variations (e.g., operator precedence or blocking vs. non-blocking assignments) can drastically alter circuit behavior, making correctness preservation especially challenging. In this work, we systematically study memorization in RTL code generation and propose CircuitGuard, a defense strategy that balances leakage reduction with correctness preservation. CircuitGuard (i) introduces a novel RTL-aware similarity metric that captures both structural and functional equivalence beyond surface-level overlap, and (ii) develops an activation-level steering method that identifies and attenuates transformer components most responsible for memorization. Our empirical evaluation demonstrates that CircuitGuard identifies (and isolates) 275 memorization-critical features across layers 18-28 of Llama 3.1-8B model, achieving up to 80% reduction in semantic similarity to proprietary patterns while maintaining generation quality. CircuitGuard further shows 78-85% crossdomain transfer effectiveness, enabling robust memorization mitigation across circuit categories without retraining. <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup><sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>Code is available at https://github.com/mashnoor/circuitguard."
  },
  {
    "date": "2025-12-30",
    "title": "RTLBench: A Multi-Dimensional Benchmark Suite for Evaluating LLM-Generated RTL Code",
    "authors": "Zhigang Fang, Renzhi Chen, Yang Guo, Huadong Dai, Lei Wang",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00087",
    "source": "IEEE",
    "abstract": "The rapid advancement of large language models (LLMs) has enabled automated Register Transfer Level (RTL) code generation, accelerating chip design workflows. However, existing benchmarks focus mainly on syntax and functionality, overlooking critical engineering aspects such as lint compliance, readability, and coding style. To address this gap, we propose RTLBench, a benchmark suite of 160 copyright-free RTL cases sourced from textbooks and open-source projects. RTLBench features a multi-dimensional evaluation framework covering syntax, functionality, lint compliance, readability, and style consistency. To assess subjective code quality metrics, it also incorporates an LLM-as-a-judge mechanism. We evaluated 24 state-of-the-art LLMs using RTLBench, finding that while several models perform well in syntax and functionality, most fall short on engineering quality. To address this, we propose Log2BetterRTL, a log-driven feedback system that transforms EDA tool diagnostics into iterative improvement prompts. It improves syntax correctness by up to 18.13 %, boosts functional correctness by 14.38 %, reduces lint violations by up to 229, and raises clarity scores by 0.51. These results demonstrate RTLBench's effectiveness in evaluating and enhancing LLMgenerated RTL, bridging the gap between generative AI and industrial-grade hardware design. The suite and scripts are available at: https://fangzhigang32.github.io/RTLBench."
  },
  {
    "date": "2025-12-30",
    "title": "FV-PAL: Scalable Formal Verification through Partitioning and LLM-Guided Property Generation",
    "authors": "Sudipta Paria, Aritra Dasgupta, Dinesh Reddy Ankireddy, Prabuddha Chakraborty, Swarup Bhunia",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00114",
    "source": "IEEE",
    "abstract": "The growing complexity of modern system-on-chip (SoC) designs, coupled with the integration of untrusted thirdparty Intellectual Property (IP) blocks, presents significant challenges for security verification to ensure the trust and integrity of the fabricated silicon. Traditional verification methods, such as functional simulation and Formal Property Verification (FPV), suffer from limited scalability, substantial manual effort, and often incomplete coverage. To address these issues, we propose an automated formal verification framework FV-PAL that can vastly enhance security verification at both module and submodule levels. Our approach introduces judicious design partitioning to identify submodules using structural analysis and enables targeted verification of gate-level netlists, reducing computational overhead. Leveraging Large Language Models (LLMs) and retrieval-augmented generation (RAG), the framework automatically generates non-vacuous security properties translated into SystemVerilog Assertions (SVAs) using design specifications and related documentation. FV-PAL can be integrated with the commercial EDA toolflow to perform FPV and generate coverage metrics with iterative refinement via a feedback loop if coverage falls below specified threshold. FV-PAL demonstrates significant improvements in verification efficiency and coverage based on our evaluation on open-source benchmarks, offering a scalable and efficient formal verification approach for hardware designs."
  },
  {
    "date": "2025-12-30",
    "title": "I Know Which LLM Wrote Your Code Last Summer: LLM generated Code Stylometry for Authorship Attribution",
    "authors": "Tamas Bisztray, Bilel Cherif, Richard A. Dubniczky, Nils Gruschka, Bertalan Borsos, Mohamed Amine Ferrag, Attila Kovacs, Vasileios Mavroeidis, Norbert Tihanyi",
    "publish": "Proceedings of the 18th ACM Workshop on Artificial Intelligence and Security",
    "url": "https://doi.org/10.1145/3733799.3762964",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2025-12-30",
    "title": "Optimizing LLM with FP8",
    "authors": "Vinh Pham Xuan, Khoi Nguyen Le, Vinh Nguyen Van",
    "publish": "2025 17th International Conference on Knowledge and System Engineering (KSE)",
    "url": "https://doi.org/10.1109/kse68178.2025.11309551",
    "source": "IEEE",
    "abstract": "抓取摘要失败: Unterminated string starting at: line 1 column 2421 (char 2420)"
  },
  {
    "date": "2025-12-30",
    "title": "Challenges &amp; Opportunities with LLM-Assisted Visualization Retargeting",
    "authors": "Luke S. Snyder, Chenglong Wang, Steven M. Drucker",
    "publish": "2025 IEEE Visualization and Visual Analytics (VIS)",
    "url": "https://doi.org/10.1109/vis60296.2025.00034",
    "source": "IEEE",
    "abstract": "Despite the ubiquity of visualization examples published on the web, retargeting existing custom chart implementations to new datasets remains difficult, time-intensive, and tedious. The adaptation process assumes author familiarity with both the implementation of the example as well as how the new dataset might need to be transformed to fit into the example code. With recent advances in Large Language Models (LLMs), automatic adaptation of code can be achieved from high-level user prompts, reducing the barrier for visualization retargeting. To better understand how LLMs can assist retargeting and its potential limitations, we characterize and evaluate the performance of LLM assistance across multiple datasets and charts of varying complexity, categorizing failures according to type and severity. In our evaluation, we compare two approaches: (1) directly instructing the LLM model to fully generate and adapt code by treating code as text inputs and (2) a more constrained program synthesis pipeline where the LLM guides the code construction process by providing structural information (e.g., visual encodings) based on properties of the example code and data. We find that both approaches struggle when new data has not been appropriately transformed, and discuss important design recommendations for future retargeting systems."
  },
  {
    "date": "2025-12-30",
    "title": "Hot-FV: A Semi-Formal Test Generation Framework for RTL Functional Coverage Using Warm Starting States",
    "authors": "Ziyue Zheng, Zhiyuan Yan, Xiangchen Meng, Guangyu Hu, Hongce Zhang, Yangdi Lyu",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00049",
    "source": "IEEE",
    "abstract": "Functional verification is critical in ensuring the correctness of register transfer level (RTL) models. Formal methods, such as model checkers, are powerful tools that help achieve high coverage in functional validation by transforming the coverage problem into property verification tasks. However, these methods typically demand significant memory usage and long verification times. One major issue is that the satisfiability problem for each unsolved property always starts from the reset state of a design, leading to repeated solving of the same subset of clauses across different properties. In this paper, we propose an open-source semi-formal framework based on model checkers that accelerates test stimulus generation through two techniques: assertion ordering and strategic selection of starting states. These techniques enable model checkers to intelligently select starting states that are much closer to the final state, thereby reducing unnecessary computations. Through comprehensive experiments on ITC'99 benchmarks and modern complex processor designs, including OpenCores 1200 and Rocket-Chip, we demonstrate that our proposed techniques can achieve higher coverage with less than half of the test generation time."
  },
  {
    "date": "2025-12-30",
    "title": "Human-LLM Collaboration Framework for Translating Health Instruments",
    "authors": "Hind Bitar, Omaima Almatrafi, Amal Babour, Ohoud Alzamzami, Mayada Alrige, Sarah Alismail",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2025.3649657",
    "source": "IEEE",
    "abstract": "Large language models have revolutionized various sectors, including education and healthcare, by demonstrating significant advancements in producing human-like text and enhancing translation accuracy. Despite these advancements, the conventional process of cross-cultural instrument translation remains labor-intensive, expensive, and heavily dependent on the expertise of human professionals, including translators and healthcare specialists. The objective of this study is to address the translation challenges in health-related instruments. This study introduces a Human and Large Language Models Collaboration Framework, called H-LLMCF, designed to automate the key steps of instrument translation while maintaining linguistic precision and cultural appropriateness. The proposed framework integrates human expertise and LLM capabilities across two phases: AI-guided translation and human-guided evaluation and refinement. When applied to the translation of two validated instruments in the health sector from English to Arabic, the framework demonstrated promising outcomes. The proposed framework achieved BLEU scores of ~0.54 and ~66 for the two instruments. SBERT-based cosine similarity exceeded 0.85 for 80% of items, with a mean of ~0.92 and ~0.96, indicating strong semantic alignment with human translations. Human evaluation of the 35-item HPV Knowledge Assessment instrument yielded an average I-CVI of 1.00, with 91.42% of items rated as fully acceptable by both reviewers. For the KIDMED instrument, out of 16 items, 15 (93.75%) received a rating of 3 from both reviewers, resulting in an I-CVI of 1.00 for those items. Most discrepancies were linked to translation and fluency adaptation. This highlights the potential of LLMs to enhance cross-cultural translation processes while maintaining translation quality."
  },
  {
    "date": "2025-12-30",
    "title": "An Integrated Workforce Planning with LLM Support for Blood Bank Operations Optimization",
    "authors": "Le Tuong Nguyen, Nguyen Van-Hop",
    "publish": "2025 17th International Conference on Knowledge and System Engineering (KSE)",
    "url": "https://doi.org/10.1109/kse68178.2025.11309567",
    "source": "IEEE",
    "abstract": "Efficient staff rostering in blood banks is critical to ensuring continuous, high-quality service and dynamic operational constraints. This study proposes an intelligent scheduling framework that integrates Genetic Algorithms (GA) with adaptive penalty weighting guided by a Large Language Model (LLM). Three variants including plain GA, GA with fixed weights, and weighted GA with LLM support, are evaluated across five realistic scenarios. Experimental results from 20 independent runs per method demonstrate that the proposed approach significantly reduces soft constraint violations, improves fairness, and minimizes average overtime. Paired t-tests confirm the statistical significance of these improvements (<tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathrm{p}&lt;0.05$</tex>). The findings highlight the potential of integrating LLM-driven reasoning into evolutionary optimization for robust, context-aware workforce scheduling in healthcare environments."
  },
  {
    "date": "2025-12-30",
    "title": "The Agentopia Times: Understanding and Mitigating Hallucinations in Multi-Agent LLM Systems via Data Journalism Gameplay",
    "authors": "Yilin Harry Lu, Shurui Du, Qianwen Wang",
    "publish": "2025 IEEE Visualization and Visual Analytics (VIS)",
    "url": "https://doi.org/10.1109/vis60296.2025.00037",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) are increasingly used to support data analysis and visualization tasks, but remain prone to hallucinations. Recent work suggests that multi-agent systems (MAS) can mitigate hallucinations by enabling internal validation and cross-verification. However, learning effective MAS coordination strategies to mitigate hallucination remains challenging, particularly for newcomers, due to the wide range of coordination strategies and the lack of interactive, hands-on learning tools. To address this, we present The Agentopia Times, an educational game that teaches hallucination mitigation through active experimentation with MAS coordination strategies. The Agentopia Times simulates a newsroom where LLM agents collaborate to create data-driven narratives, with users tasked with adjusting communication protocols to manage hallucinated content. The game features a structured mapping between MAS coordination and familiar gameplay mechanics, providing immediate feedback on hallucination outcomes. Through use cases and preliminary user feedback, we demonstrate how The Agentopia Times enables users to explore and mitigate hallucination in MAS."
  },
  {
    "date": "2025-12-30",
    "title": "Intelligent Report Generation for Medical Imaging Enhanced by LLM",
    "authors": "Naveen Kumar S, Rajakumar K, Samesh Enathe VP, Venu Kishore SB",
    "publish": "2025 International Conference on Sustainable Communication Networks and Application (ICSCN)",
    "url": "https://doi.org/10.1109/icscn67106.2025.11308249",
    "source": "IEEE",
    "abstract": "This project focuses on developing an Intelligent Report Generation system for medical imaging, harnessing the power of deep learning through an ensemble model approach. In order to efficiently analyze medical images and extract essential information for precise abnormality diagnosis, we integrate cutting-edge architectures such as Vision Transformer and U-Net. Following feature extraction, a multi-modal transformer ensemble is used to process the data and produce initial text summaries of the results. Using Flamingo, a specialized vision language model trained on image data, we update this content to improve the medical correctness and relevancy of the generated reports. To further enhance the reports with descriptive information and produce thorough narratives that support radiologists in clinical decision-making. This integrated approach aims to streamline the reporting process, improve diagnostic accuracy, and ultimately enhance patient outcomes in medical imaging practices."
  },
  {
    "date": "2025-12-30",
    "title": "SLB:A Bridge Module of Local SLM and Online LLM for Smart Home Device Control",
    "authors": "Peizhe Dong, Vu Tran",
    "publish": "2025 17th International Conference on Knowledge and System Engineering (KSE)",
    "url": "https://doi.org/10.1109/kse68178.2025.11309441",
    "source": "IEEE",
    "abstract": "With the increasing popularity of smart home devices, users have a growing need to communicate with smarter assistants to control smart home devices. However, on the one hand, using online large language models(LLMs) to recognize user commands poses a certain threat to the personal privacy and data security of the user. On the other hand, local small language models(SLMs) cannot always perform well because of the limited computing power of local devices. We propose a method that can better interact with smart home assistants: developing a bridge module that can efficiently connect local SLM and online LLM in a smart home assistant. It first analyzes user intent on the local SLM, and then hands it off to the online LLM for further command generations to specified smart home devices. Our experimental results suggest that this approach can provide users with high-quality services while reducing the risk of privacy leakage. This helps reduce the reliance on large hardware devices when implementing home automation while better protecting user data security and personal privacy."
  },
  {
    "date": "2025-12-30",
    "title": "LLM-Driven Code Generation for Neural Networks on FPGAs: Bridging Python and HLS",
    "authors": "Rupesh Raj Karn, Johann Knechtel, Ramesh Karri, Ozgur Sinanoglu",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00090",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) have transformed code generation across various fields. Here, we study the specific opportunities and challenges that LLMs present in generating hardware designs for neural networks (NNs) on fieldprogrammable gate arrays (FPGAs). We illustrate how LLMs can be utilized to achieve code optimizations essential for this task, such as parallelism, memory management, and latency reduction. Additionally, we compare the proposed specialized approach for NN code generation with others for more generalized hardware. Through a series of case studies and performance evaluations, we also contrast our results with prior state of the art."
  },
  {
    "date": "2025-12-30",
    "title": "SecNPU: Securing LLM Inference on NPU",
    "authors": "Xuanyao Peng, Yinghao Yang, Shangjie Pan, Junjie Huang, Yujun Liang, Hang Lu, Fengwei Zhang, Xiaowei Li",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00011",
    "source": "IEEE",
    "abstract": "In the era of prevalent large language models (LLMs), efficient LLM inference systems deployed on the neural processing units (NPUs) have gained widespread adoption. During NPUbased LLM inference, both user privacy inputs and proprietary model parameters require stringent protection. While traditional trusted execution environments (TEEs) can be applied to NPU inference processes, we identify that they introduce challenging security-related overheads, including communication for security metadata management and secure startup costs. This paper proposes SecNPU, a CPU-decoupled and LLM-inference-optimized NPU TEE. SecNPU effectively eliminates communication overhead caused by coupled security metadata and leverages the characteristics of LLM inference to conceal security initialization latency. Experimental evaluations demonstrate that our design achieves <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$1.51 \\times$</tex> overall secure inference speedup and <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$1.61 \\times$</tex> secure boot performance improvement, requiring merely 1.63 % additional area and 6.6 % more power."
  },
  {
    "date": "2025-12-30",
    "title": "Algorithm for Constructing Educational Dynamic Knowledge Graph and Predicting Intervention Nodes Based on LLM-GNN Fusion",
    "authors": "Yixuan Song, Ling Fu",
    "publish": "2025 IEEE 8th International Conference on Information Systems and Computer Aided Education (ICISCAE)",
    "url": "https://doi.org/10.1109/iciscae66104.2025.11307255",
    "source": "IEEE",
    "abstract": "Students encounter multi-dimensional dynamic challenges in the learning process, while traditional student performance analysis, which relies on static data, fails to capture the complex relationships in learning behaviors, resulting in delayed interventions. To address this issue, this paper proposes an algorithm for constructing educational dynamic knowledge graphs and predicting intervention nodes by integrating Large Language Models (LLMs) and Graph Neural Networks (GNNs). The semantic understanding capability of LLMs (such as parsing homework errors and classroom needs) assists GNNs in building a dynamic heterogeneous knowledge graph of “students-knowledge points-teaching resources-interactive behaviors”, breaking the limitations of static data. To make up for the deficiency of GNNs in deep semantic mining, a knowledge-based semantic structure mining module (combined with Qwen2) is designed to improve the accuracy of node representation. In addition, an Integrated One Graph (IOG) module is adopted to unify individual and group classification into the prediction of “key intervention nodes”, enhancing the generalization ability across educational scenarios. Experimental results show that the IOG-CIQAN model achieves an accuracy of over 87 % in tasks such as performance early warning and personalized path recommendation, outperforming traditional machine learning baselines. This study provides an effective technical framework for precise educational intervention."
  },
  {
    "date": "2025-12-30",
    "title": "Trustworthiness of an LLM in the Classroom Through a Role-Playing Game: The Case of ChatGPT",
    "authors": "Panagiota Ismini Matthe, Maria Virvou",
    "publish": "2025 16th International Conference on Information, Intelligence, Systems &amp;amp; Applications (IISA)",
    "url": "https://doi.org/10.1109/iisa66859.2025.11311301",
    "source": "IEEE",
    "abstract": "This paper presents the research design and results of an appropriately designed role-playing game for students, involving large language models (LLMs) in the context of classrooms in a public model high school. The activity included structured, guided tasks in which students worked in pairs to interact with the AI tool. The study investigated students' interactions and experiences with ChatGPT as a representative case of an LLM, focusing on their perceptions of the learning process and the development of trust in AI systems. Data were collected through post-activity questionnaires and classroom observations, enabling both qualitative and quantitative analysis. Findings suggest that integrating ChatGPT into a role-playing pedagogical framework can enhance student engagement and positively influence perceived learning outcomes. A modest increase in students' trust in LLMs was observed. However, a considerable number of AI-generated responses were accepted without critical evaluation on the part of students, indicating gaps in their evaluative reasoning. The results underscore the necessity of embedding AI literacy and critical thinking into secondary education. Although the activity did not explicitly focus on the limitations of LLMs, the study highlights the essential role of educational institutions in preparing students for responsible and informed engagement with AI technologies. A larger-scale subsequent study is planned to validate and expand these findings."
  },
  {
    "date": "2025-12-30",
    "title": "EEsizer: LLM-Based AI Agent for Sizing of Analog and Mixed Signal Circuit",
    "authors": "Chang Liu, Danial Chitnis",
    "publish": "IEEE Transactions on Circuits and Systems I: Regular Papers",
    "url": "https://doi.org/10.1109/tcsi.2025.3646359",
    "source": "IEEE",
    "abstract": "The design of Analog and Mixed-Signal (AMS) integrated circuits (ICs) often involves significant manual effort, especially during the transistor sizing process. While Machine Learning techniques in Electronic Design Automation (EDA) have shown promise in reducing complexity and minimizing human intervention, they still face challenges such as numerous iterations and a lack of knowledge about AMS circuit design. Recently, Large Language Models (LLMs) have demonstrated significant potential across various fields, showing a certain level of knowledge in circuit design and indicating their potential to automate the transistor sizing process. In this work, we propose EEsizer, an LLM-based AI agent that integrates large language models with circuit simulators and custom data analysis functions, enabling fully automated, closed-loop transistor sizing without relying on external knowledge. By employing prompt engineering and Chain-of-Thought reasoning, the agent iteratively explores design directions, evaluates performance, and refines solutions with minimal human intervention. We first benchmarked 8 LLMs on six basic circuits and selected three high-performing models to optimize a 20-transistor CMOS operational amplifier, targeting multiple performance metrics, including rail-to-rail operation from 180 nm to 90 nm technology nodes. Notably, OpenAI o3 successfully achieved the user-intended target at 90 nm across three different test groups, with a maximum of 20 iterations, demonstrating adaptability and robustness at advanced nodes. To assess design robustness, we manually designed a bias circuit and performed a variation analysis using Gaussian-distributed variations on transistor dimensions and threshold voltages. Overall, the results demonstrate the potential of LLMs to accelerate AMS circuit design by reducing manual effort while maintaining efficiency and adaptability across circuits, models, and technology nodes."
  },
  {
    "date": "2025-12-30",
    "title": "SAGE-HLS: Syntax-Aware AST-Guided LLM for High-Level Synthesis Code Generation",
    "authors": "M Zafir Sadik Khan, Nowfel Mashnoor, Mohammad Akyash, Kimia Azar, Hadi Kamali",
    "publish": "2025 IEEE 43rd International Conference on Computer Design (ICCD)",
    "url": "https://doi.org/10.1109/iccd65941.2025.00088",
    "source": "IEEE",
    "abstract": "In today's rapidly evolving field of electronic design automation (EDA), the complexity of hardware designs is increasing, necessitating more sophisticated automation solutions. High-level synthesis (HLS), as a pivotal solution, automates hardware designs from high-level abstractions (e.g., C/C++). However, it faces significant challenges, particularly in design space exploration and optimization. While large language models (LLMs) have shown notable capabilities in code generation, their application to HLS has been limited due to the scarcity of (publicly) available HLS code datasets. Hence, research in this domain has primarily focused on techniques such as prompt engineering and retrieval-augmented generation (RAG). To overcome this limitation, this paper introduces SAGE-HLS, the first-of-its-kind fine-tuned LLM specifically for HLS code generation. Our method includes three key advancements: (i) We implement Verilog-to-C/C++ porting, converting verified and synthesizable Verilog codes into corresponding C, creating a dataset of 16.7 K HLS codes; (ii) We implement a fine-tuning strategy, which is based on instruction prompting to code generation guided by abstract syntax tree (AST); (iii) We develop a semi-automated evaluation framework using VerilogEval to assess the functionality of the generated HLS code. Our experiments show that SAGE-HLS, fined-tuned on the QwenCoder (2.5) 7B model, achieves a near 100 % success rate in code synthesizability and a 75% success rate in functional correctness <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup><sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup> The code and resources related to this work are publicly available at: https://github.com/zfsadik/SAGEHLS."
  },
  {
    "date": "2025-12-30",
    "title": "Retrieval-Augmented Multi-LLM Ensemble for Industrial Part Specification Extraction",
    "authors": "Muzakkiruddin A. Mohammed, John R. Talburt, Leon Claasssens, Adriaan Marais",
    "publish": "2025 17th International Conference on Knowledge and System Engineering (KSE)",
    "url": "https://doi.org/10.1109/kse68178.2025.11309590",
    "source": "IEEE",
    "abstract": "Industrial part specification extraction from unstructured text remains a persistent challenge in manufacturing, procurement, and maintenance, where manual processing is both time-consuming and error-prone. This paper introduces RAGsemble, a retrieval-augmented multi-LLM ensemble framework that orchestrates nine state-of-the-art Large Language Models (LLMs) within a structured three-phase pipeline. RAGsemble addresses key limitations of single-model systems by combining the complementary strengths of model families including Gemini (2.0, 2.5, 1.5), OpenAI (GPT-4o, o4-mini), Mistral Large, and Gemma (1B, 4B, 3n-e4b), while grounding outputs in factual data using FAISS-based semantic retrieval. The system architecture consists of three stages: (1) parallel extraction by diverse LLMs, (2) targeted research augmentation leveraging high-performing models, and (3) intelligent synthesis with conflict resolution and confidence-aware scoring. RAG integration provides real-time access to structured part databases, enabling the system to validate, refine, and enrich outputs through similarity-based reference retrieval. Experimental results using real industrial datasets demonstrate significant gains in extraction accuracy, technical completeness, and structured output quality compared to leading single-LLM baselines. Key contributions include a scalable ensemble architecture for industrial domains, seamless RAG integration throughout the pipeline, comprehensive quality assessment mechanisms, and a production-ready solution suitable for deployment in knowledgeintensive manufacturing environments."
  }
]