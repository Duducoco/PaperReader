[
  {
    "date": "2025-12-29",
    "title": "Analysis of kinetic-diffusion Monte Carlo simulation and source term estimation scheme in nuclear fusion applications",
    "authors": "Zhirui Tang, Julian Koellermeier, Emil Løvbak, Giovanni Samaey",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23580v1",
    "source": "arXiv",
    "abstract": "In plasma edge simulations, the behavior of neutral particles is often described by a Boltzmann--BGK equation. Solving this kinetic equation and estimating the moments of its solution are essential tasks, typically carried out using Monte Carlo (MC) methods. However, for large-sized reactors, like ITER and DEMO, high collision rates lead to a substantial computational cost. To accelerate the calculation, an asymptotic-preserving kinetic-diffusion Monte Carlo (KDMC) simulation method (Mortier et al., SIAM J. Sci. Comput., 2022) and a corresponding fluid estimation technique (Mortier et al., Contrib. Plasma Phys., 2022) have recently been proposed. In this work, we present a comprehensive analysis of the convergence of KDMC combined with the associated fluid estimation. The analysis consists of proving theoretical upper bounds for both KDMC and the fluid estimation, and numerical verifications of these bounds. In addition, we compare the analyzed algorithm with a purely fluid-based method using the fully kinetic MC method as a reference. The algorithm consistently achieves lower error than the fluid-based method, and even one order of magnitude lower in a fusion-relevant test case. Moreover, the algorithm exhibits a significant speedup compared to the reference kinetic MC method. Overall, our analysis confirms the effectiveness of KDMC with the associated fluid estimation in nuclear fusion applications."
  },
  {
    "date": "2025-12-29",
    "title": "Clauser-Horne-Shimony-Holt Bell-inequality Violability with the Full Poincaré-Bloch Sphere",
    "authors": "Carlos Cardoso-Isidoro, Enrique J. Galvez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23550v1",
    "source": "arXiv",
    "abstract": "Linearly polarized projections are the tacit means for performing Clauser-Horne-Shimony-Holt (CHSH) Bell-inequality tests using polarization-entangled photon pairs. The inequality is valid for all states on the Poincaré-Bloch sphere, but few laboratory studies have investigated violations with the full sphere. In this article, we explore the experimental verifications of the predicted violations of the CHSH inequality with Bell and non-Bell states with same and different linear and elliptically polarized basis states for each photon. We find that Bell states violate CHSH when using the same basis for both photons, regardless of their ellipticity, whereas they show no violations for photon projections in different bases. We found non-Bell maximally-entangled states for which the converse is true."
  },
  {
    "date": "2025-12-29",
    "title": "Beyond Correctness: Exposing LLM-generated Logical Flaws in Reasoning via Multi-step Automated Theorem Proving",
    "authors": "Xinyi Zheng, Ningke Li, Xiaokun Luan, Kailong Wang, Ling Shi, Meng Sun, Haoyu Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23511v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive reasoning capabilities, leading to their adoption in high-stakes domains such as healthcare, law, and scientific research. However, their reasoning often contains subtle logical errors masked by fluent language, posing significant risks for critical applications. While existing approaches like fact-checking, self-consistency methods, and rule-based validation provide partial solutions, they fail to detect complex logical flaws in multi-step reasoning. To overcome these challenges, we present MATP, an evaluation framework for systematically verifying LLM reasoning via Multi-step Automatic Theorem Proving. MATP translates natural language reasoning into First-Order Logic (FOL) and applies automated theorem provers to assess step-by-step logical validity. This approach identifies hidden logical errors and provides fine-grained classifications of reasoning correctness. Evaluations on a benchmark comprising 10,830 reasoning instances generated by 10 LLMs across tasks from PrOntoQA-OOD, ProofWriter, and FOLIO show that MATP surpasses prompting-based baselines by over 42 percentage points in reasoning step verification. It further reveals model-level disparities, with reasoning models generating more logically coherent outputs than general models. These results demonstrate MATP's potential to enhance the trustworthiness of LLM-generated reasoning."
  },
  {
    "date": "2025-12-29",
    "title": "Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation",
    "authors": "Toqeer Ali Syed, Mohammad Riyaz Belgaum, Salman Jan, Asadullah Abdullah Khan, Saad Said Alqahtani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23480v1",
    "source": "arXiv",
    "abstract": "The software supply chain attacks are becoming more and more focused on trusted development and delivery procedures, so the conventional post-build integrity mechanisms cannot be used anymore. The available frameworks like SLSA, SBOM and in toto are majorly used to offer provenance and traceability but do not have the capabilities of actively identifying and removing vulnerabilities in software production. The current paper includes an example of agentic artificial intelligence (AI) based on autonomous software supply chain security that combines large language model (LLM)-based reasoning, reinforcement learning (RL), and multi-agent coordination. The suggested system utilizes specialized security agents coordinated with the help of LangChain and LangGraph, communicates with actual CI/CD environments with the Model Context Protocol (MCP), and documents all the observations and actions in a blockchain security ledger to ensure integrity and auditing. Reinforcement learning can be used to achieve adaptive mitigation strategies that consider the balance between security effectiveness and the operational overhead, and LLMs can be used to achieve semantic vulnerability analysis, as well as explainable decisions. This framework is tested based on simulated pipelines, as well as, actual world CI/CD integrations on GitHub Actions and Jenkins, including injection attacks, insecure deserialization, access control violations, and configuration errors. Experimental outcomes indicate better detection accuracy, shorter mitigation latency and reasonable build-time overhead than rule-based, provenance only and RL only baselines. These results show that agentic AI can facilitate the transition to self defending, proactive software supply chains rather than reactive verification ones."
  },
  {
    "date": "2025-12-29",
    "title": "Fuzzilicon: A Post-Silicon Microcode-Guided x86 CPU Fuzzer",
    "authors": "Johannes Lenzen, Mohamadreza Rostami, Lichao Wu, Ahmad-Reza Sadeghi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23438v1",
    "source": "arXiv",
    "abstract": "Modern CPUs are black boxes, proprietary, and increasingly characterized by sophisticated microarchitectural flaws that evade traditional analysis. While some of these critical vulnerabilities have been uncovered through cumbersome manual effort, building an automated and systematic vulnerability detection framework for real-world post-silicon processors remains a challenge. In this paper, we present Fuzzilicon, the first post-silicon fuzzing framework for real-world x86 CPUs that brings deep introspection into the microcode and microarchitectural layers. Fuzzilicon automates the discovery of vulnerabilities that were previously only detectable through extensive manual reverse engineering, and bridges the visibility gap by introducing microcode-level instrumentation. At the core of Fuzzilicon is a novel technique for extracting feedback directly from the processor's microarchitecture, enabled by reverse-engineering Intel's proprietary microcode update interface. We develop a minimally intrusive instrumentation method and integrate it with a hypervisor-based fuzzing harness to enable precise, feedback-guided input generation, without access to Register Transfer Level (RTL). Applied to Intel's Goldmont microarchitecture, Fuzzilicon introduces 5 significant findings, including two previously unknown microcode-level speculative-execution vulnerabilities. Besides, the Fuzzilicon framework automatically rediscover the $μ$Spectre class of vulnerabilities, which were detected manually in the previous work. Fuzzilicon reduces coverage collection overhead by up to 31$\\times$ compared to baseline techniques and achieves 16.27% unique microcode coverage of hookable locations, the first empirical baseline of its kind. As a practical, coverage-guided, and scalable approach to post-silicon fuzzing, Fuzzilicon establishes a new foundation to automate the discovery of complex CPU vulnerabilities."
  },
  {
    "date": "2025-12-29",
    "title": "interID -- An Ecosystem-agnostic Verifier Application for Self-sovereign Identity",
    "authors": "Hakan Yildiz, Axel Küpper",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23383v1",
    "source": "arXiv",
    "abstract": "Self-Sovereign Identity is a transformative paradigm in digital identity management, empowering individuals with full control over their credentials. However, the coexistence of diverse SSI ecosystems, such as the European Digital Identity and the European Blockchain Services Infrastructure, poses significant challenges for cross-ecosystem interoperability due to technological and trust framework differences. This paper introduces \\textit{interID}, a modular credential verification application that addresses this fragmentation by orchestrating ecosystem-specific verifier services. Our key contributions include: (1) an ecosystem-agnostic orchestration layer that interfaces with multiple SSI verification services, (2) a unified API that abstracts underlying protocol complexities for service providers, and (3) a practical implementation that bridges three major SSI ecosystems: Hyperledger Indy/Aries, EBSI, and EUDI. Evaluation results demonstrate that interID successfully verifies credentials across all tested wallets with minimal performance overhead, while maintaining a flexible architecture that can be extended to accept credentials from additional SSI ecosystems. This work offers both a technical solution and architectural pattern for achieving interoperability in SSI verifier implementations."
  },
  {
    "date": "2025-12-29",
    "title": "AGRO-SQL: Agentic Group-Relative Optimization with High-Fidelity Data Synthesis",
    "authors": "Cehua Yang, Dongyu Xiao, Junming Lin, Yuyang Song, Hanxu Yan, Shawn Guo, Wei Zhang, Jian Yang, Mingjie Tang, Bryan Dai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23366v1",
    "source": "arXiv",
    "abstract": "The advancement of Text-to-SQL systems is currently hindered by the scarcity of high-quality training data and the limited reasoning capabilities of models in complex scenarios. In this paper, we propose a holistic framework that addresses these issues through a dual-centric approach. From a Data-Centric perspective, we construct an iterative data factory that synthesizes RL-ready data characterized by high correctness and precise semantic-logic alignment, ensured by strict verification. From a Model-Centric perspective, we introduce a novel Agentic Reinforcement Learning framework. This framework employs a Diversity-Aware Cold Start stage to initialize a robust policy, followed by Group Relative Policy Optimization (GRPO) to refine the agent's reasoning via environmental feedback. Extensive experiments on BIRD and Spider benchmarks demonstrate that our synergistic approach achieves state-of-the-art performance among single-model methods."
  },
  {
    "date": "2025-12-29",
    "title": "A space-time extension of a conservative two-fluid cut-cell diffusion method for moving geometries",
    "authors": "Louis Libat, Can Selçuk, Eric Chénier, Vincent Le Chenadec",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23358v1",
    "source": "arXiv",
    "abstract": "We present a space-time extension of a conservative Cartesian cut-cell finite-volume method for two-phase diffusion in prescribed-motion geometries. The formulation follows a two-fluid approach: one scalar field is solved in each phase with discontinuous material properties, coupled by sharp interface conditions enforcing flux continuity and jump laws. To handle moving boundaries on a fixed Cartesian grid, the discrete balance is written over phase-restricted space-time control volumes, whose geometric moments (swept volumes and apertures) are used as weights in the finite-volume operators. This construction naturally accounts for the creation and destruction of cut cells (fresh/dead-cell events) and yields strict discrete conservation. The resulting scheme retains the algebraic structure of the static cut-cell formulation while incorporating motion through local geometric weights and interface coupling operators. A series of verification and validation tests in two and three dimensions demonstrate super-linear accuracy in space, robust behavior under repeated topology changes and conservation across strong coefficient jumps and moving interfaces. The proposed space-time cut-cell framework provides a conservative building block for multiphase transport in evolving geometries and a foundation for future free-boundary extensions such as Stefan-type phase change."
  },
  {
    "date": "2025-12-29",
    "title": "Verifying Asynchronous Hyperproperties in Reactive Systems",
    "authors": "Raven Beutner, Bernd Finkbeiner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23344v1",
    "source": "arXiv",
    "abstract": "Hyperproperties are system properties that relate multiple execution traces and commonly occur when specifying information-flow and security policies. Logics like HyperLTL utilize explicit quantification over execution traces to express temporal hyperproperties in reactive systems, i.e., hyperproperties that reason about the temporal behavior along infinite executions. An often unwanted side-effect of such logics is that they compare the quantified traces synchronously. This prohibits the logics from expressing properties that compare multiple traces asynchronously, such as Zdancewic and Myers's observational determinism, McLean's non-inference, or stuttering refinement. We study the model-checking problem for a variant of asynchronous HyperLTL (A-HLTL), a temporal logic that can express hyperproperties where multiple traces are compared across timesteps. In addition to quantifying over system traces, A-HLTL features secondary quantification over stutterings of these traces. Consequently, A-HLTL allows for a succinct specification of many widely used asynchronous hyperproperties. Model-checking A-HLTL requires finding suitable stutterings, which, thus far, has been only possible for very restricted fragments or terminating systems. In this paper, we propose a novel game-based approach for the verification of arbitrary $\\forall^*\\exists^*$ A-HLTL formulas in reactive systems. In our method, we consider the verification as a game played between a verifier and a refuter, who challenge each other by controlling parts of the underlying traces and stutterings. A winning strategy for the verifier then corresponds to concrete witnesses for existentially quantified traces and asynchronous alignments for existentially quantified stutterings. We identify fragments for which our game-based interpretation is complete and thus constitutes a finite-state decision procedure."
  },
  {
    "date": "2025-12-29",
    "title": "An Empirical Study of Generative AI Adoption in Software Engineering",
    "authors": "Görkem Giray, Onur Demirörs, Marcos Kalinowski, Daniel Mendez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23327v1",
    "source": "arXiv",
    "abstract": "Context. GenAI tools are being increasingly adopted by practitioners in SE, promising support for several SE activities. Despite increasing adoption, we still lack empirical evidence on how GenAI is used in practice, the benefits it provides, the challenges it introduces, and its broader organizational and societal implications. Objective. This study aims to provide an overview of the status of GenAI adoption in SE. It investigates the status of GenAI adoption, associated benefits and challenges, institutionalization of tools and techniques, and anticipated long term impacts on SE professionals and the community. Results. The results indicate a wide adoption of GenAI tools and how they are deeply integrated into daily SE work, particularly for implementation, verification and validation, personal assistance, and maintenance-related tasks. Practitioners report substantial benefits, most notably reduction in cycle time, quality improvements, enhanced support in knowledge work, and productivity gains. However, objective measurement of productivity and quality remains limited in practice. Significant challenges persist, including incorrect or unreliable outputs, prompt engineering difficulties, validation overhead, security and privacy concerns, and risks of overreliance. Institutionalization of tools and techniques seems to be common, but it varies considerably, with a strong focus on tool access and less emphasis on training and governance. Practitioners expect GenAI to redefine rather than replace their roles, while expressing moderate concern about job market contraction and skill shifts."
  },
  {
    "date": "2025-12-29",
    "title": "On Conformant Planning and Model-Checking of $\\exists^*\\forall^*$ Hyperproperties",
    "authors": "Raven Beutner, Bernd Finkbeiner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23324v1",
    "source": "arXiv",
    "abstract": "We study the connection of two problems within the planning and verification community: Conformant planning and model-checking of hyperproperties. Conformant planning is the task of finding a sequential plan that achieves a given objective independent of non-deterministic action effects during the plan's execution. Hyperproperties are system properties that relate multiple execution traces of a system and, e.g., capture information-flow and fairness policies. In this paper, we show that model-checking of $\\exists^*\\forall^*$ hyperproperties is closely related to the problem of computing a conformant plan. Firstly, we show that we can efficiently reduce a hyperproperty model-checking instance to a conformant planning instance, and prove that our encoding is sound and complete. Secondly, we establish the converse direction: Every conformant planning problem is, itself, a hyperproperty model-checking task."
  },
  {
    "date": "2025-12-29",
    "title": "BRkNN-light: Batch Processing of Reverse k-Nearest Neighbor Queries for Moving Objects on Road Networks",
    "authors": "Anbang Song, Ziqiang Yu, Wei Liu, Yating Xu, Mingjin Tao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23298v1",
    "source": "arXiv",
    "abstract": "The Reverse $k$-Nearest Neighbor (R$k$NN) query over moving objects on road networks seeks to find all moving objects that consider the specified query point as one of their $k$ nearest neighbors. In location based services, many users probably submit R$k$NN queries simultaneously. However, existing methods largely overlook how to efficiently process multiple such queries together, missing opportunities to share redundant computations and thus reduce overall processing costs. To address this, this work is the first to explore batch processing of multiple R$k$NN queries, aiming to minimize total computation by sharing duplicate calculations across queries. To tackle this issue, we propose the BR$k$NN-Light algorithm, which uses rapid verification and pruning strategies based on geometric constraints, along with an optimized range search technique, to speed up the process of identifying the R$k$NNs for each query. Furthermore, it proposes a dynamic distance caching mechanism to enable computation reuse when handling multiple queries, thereby significantly reducing unnecessary computations. Experiments on multiple real-world road networks demonstrate the superiority of the BR$k$NN-Light algorithm on the processing of batch queries."
  },
  {
    "date": "2025-12-29",
    "title": "The Dawn of Agentic EDA: A Survey of Autonomous Digital Chip Design",
    "authors": "Zelin Zang, Yuhang Song, Bingo Wing-Kuen Ling, Aili Wang, Fuji Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.23189v1",
    "source": "arXiv",
    "abstract": "This survey provides a comprehensive overview of the integration of Generative AI and Agentic AI within the field of Digital Electronic Design Automation (EDA). The paper first reviews the paradigmatic evolution from traditional Computer-Aided Design (CAD) to AI-assisted EDA (AI4EDA), and finally to the emerging AI-Native and Agentic design paradigms. We detail the application of these paradigms across the digital chip design flow, including the construction of agentic cognitive architectures based on multimodal foundation models, frontend RTL code generation and intelligent verification, and backend physical design featuring algorithmic innovations and tool orchestration. We validate these methodologies through integrated case studies, demonstrating practical viability from microarchitecture definition to GDSII. Special emphasis is placed on the potential for cross-stage feedback loops where agents utilize backend PPA metrics to autonomously refine frontend logic. Furthermore, this survey delves into the dual-faceted impact on security, covering novel adversarial risks, automated vulnerability repair, and privacy-preserving infrastructure. Finally, the paper critically summarizes current challenges related to hallucinations, data scarcity, and black-box tools, and outlines future trends towards L4 autonomous chip design. Ultimately, this work aims to define the emerging field of Agentic EDA and provide a strategic roadmap for the transition from AI-assisted tools to fully autonomous design engineers."
  },
  {
    "date": "2025-12-28",
    "title": "Multimodal Fact-Checking: An Agent-based Approach",
    "authors": "Danni Xu, Shaojing Fan, Xuanang Cheng, Mohan Kankanhalli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22933v1",
    "source": "arXiv",
    "abstract": "The rapid spread of multimodal misinformation poses a growing challenge for automated fact-checking systems. Existing approaches, including large vision language models (LVLMs) and deep multimodal fusion methods, often fall short due to limited reasoning and shallow evidence utilization. A key bottleneck is the lack of dedicated datasets that provide complete real-world multimodal misinformation instances accompanied by annotated reasoning processes and verifiable evidence. To address this limitation, we introduce RW-Post, a high-quality and explainable dataset for real-world multimodal fact-checking. RW-Post aligns real-world multimodal claims with their original social media posts, preserving the rich contextual information in which the claims are made. In addition, the dataset includes detailed reasoning and explicitly linked evidence, which are derived from human written fact-checking articles via a large language model assisted extraction pipeline, enabling comprehensive verification and explanation. Building upon RW-Post, we propose AgentFact, an agent-based multimodal fact-checking framework designed to emulate the human verification workflow. AgentFact consists of five specialized agents that collaboratively handle key fact-checking subtasks, including strategy planning, high-quality evidence retrieval, visual analysis, reasoning, and explanation generation. These agents are orchestrated through an iterative workflow that alternates between evidence searching and task-aware evidence filtering and reasoning, facilitating strategic decision-making and systematic evidence analysis. Extensive experimental results demonstrate that the synergy between RW-Post and AgentFact substantially improves both the accuracy and interpretability of multimodal fact-checking."
  },
  {
    "date": "2025-12-28",
    "title": "Optimal Threshold for Fracton Codes and Nearly Saturated Code Capacity in Three Dimensions",
    "authors": "Giovanni Canossa, Lode Pollet, Miguel A. Martin-Delgado, Hao Song, Ke Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22888v1",
    "source": "arXiv",
    "abstract": "Fracton codes have been intensively studied as novel topological states of matter, yet their fault-tolerant properties remain largely unexplored. Here, we investigate the optimal thresholds of self-dual fracton codes, in particular the checkerboard code, against stochastic Pauli noise. By utilizing a statistical-mechanical mapping combined with large-scale parallel tempering Monte Carlo simulations, we calculate the optimal code capacity of the checkerboard code to be $p_{th} \\simeq 0.108(2)$. This value is the highest among known three-dimensional codes and nearly saturates the theoretical limit for topological codes. Our results further validate the generalized entropy relation for two mutually dual models, $H(p_{th}) + H(\\tilde{p}_{th}) \\approx 1$, and extend its applicability beyond standard topological codes. This verification indicates the Haah's code also possesses a code capacity near the theoretical limit $p_{th} \\approx 0.11$. These findings highlight fracton codes as highly resilient quantum memory and demonstrate the utility of duality techniques in analyzing intricate quantum error-correcting codes."
  },
  {
    "date": "2025-12-27",
    "title": "Raven: Mining Defensive Patterns in Ethereum via Semantic Transaction Revert Invariants Categories",
    "authors": "Mojtaba Eshghie, Melissa Mazura, Alexandre Bartel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22616v1",
    "source": "arXiv",
    "abstract": "We frame Ethereum transactions reverted by invariants-require(<invariant>)/ assert(<invariant>)/if (<invariant>) revert statements in the contract implementation-as a positive signal of active on-chain defenses. Despite their value, the defensive patterns in these transactions remain undiscovered and underutilized in security research. We present Raven, a framework that aligns reverted transactions to the invariant causing the reversion in the smart contract source code, embeds these invariants using our BERT-based fine-tuned model, and clusters them by semantic intent to mine defensive invariant categories on Ethereum. Evaluated on a sample of 20,000 reverted transactions, Raven achieves cohesive and meaningful clusters of transaction-reverting invariants. Manual expert review of the mined 19 semantic clusters uncovers six new invariant categories absent from existing invariant catalogs, including feature toggles, replay prevention, proof/signature verification, counters, caller-provided slippage thresholds, and allow/ban/bot lists. To demonstrate the practical utility of this invariant catalog mining pipeline, we conduct a case study using one of the newly discovered invariant categories as a fuzzing oracle to detect vulnerabilities in a real-world attack. Raven thus can map Ethereum's successful defenses. These invariant categories enable security researchers to develop analysis tools based on data-driven security oracles extracted from the smart contracts' working defenses."
  },
  {
    "date": "2025-12-27",
    "title": "Nightjar: Dynamic Adaptive Speculative Decoding for Large Language Models Serving",
    "authors": "Rui Li, Zhaoning Zhang, Libo Zhang, Huaimin Wang, Xiang Fu, Zhiquan Lai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22420v1",
    "source": "arXiv",
    "abstract": "Speculative decoding (SD) accelerates LLM inference by verifying draft tokens in parallel. However, this method presents a critical trade-off: it improves throughput in low-load, memory-bound systems but degrades performance in high-load, compute-bound environments due to verification overhead. Current SD implementations use a fixed speculative length, failing to adapt to dynamic request rates and creating a significant performance bottleneck in real-world serving scenarios. To overcome this, we propose Nightjar, a novel learning-based algorithm for adaptive speculative inference that adjusts to request load by dynamically selecting the optimal speculative length for different batch sizes and even disabling speculative decoding when it provides no benefit. Experiments show that Nightjar achieves up to 14.8% higher throughput and 20.2% lower latency compared to standard speculative decoding, demonstrating robust efficiency for real-time serving."
  },
  {
    "date": "2025-12-27",
    "title": "Hallucination Detection and Evaluation of Large Language Model",
    "authors": "Chenggong Zhang, Haopeng Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22416v1",
    "source": "arXiv",
    "abstract": "Hallucinations in Large Language Models (LLMs) pose a significant challenge, generating misleading or unverifiable content that undermines trust and reliability. Existing evaluation methods, such as KnowHalu, employ multi-stage verification but suffer from high computational costs. To address this, we integrate the Hughes Hallucination Evaluation Model (HHEM), a lightweight classification-based framework that operates independently of LLM-based judgments, significantly improving efficiency while maintaining high detection accuracy. We conduct a comparative analysis of hallucination detection methods across various LLMs, evaluating True Positive Rate (TPR), True Negative Rate (TNR), and Accuracy on question-answering (QA) and summarization tasks. Our results show that HHEM reduces evaluation time from 8 hours to 10 minutes, while HHEM with non-fabrication checking achieves the highest accuracy \\(82.2\\%\\) and TPR \\(78.9\\%\\). However, HHEM struggles with localized hallucinations in summarization tasks. To address this, we introduce segment-based retrieval, improving detection by verifying smaller text components. Additionally, our cumulative distribution function (CDF) analysis indicates that larger models (7B-9B parameters) generally exhibit fewer hallucinations, while intermediate-sized models show higher instability. These findings highlight the need for structured evaluation frameworks that balance computational efficiency with robust factual validation, enhancing the reliability of LLM-generated content."
  },
  {
    "date": "2025-12-26",
    "title": "HalluMat: Detecting Hallucinations in LLM-Generated Materials Science Content Through Multi-Stage Verification",
    "authors": "Bhanu Prakash Vangala, Sajid Mahmud, Pawan Neupane, Joel Selvaraj, Jianlin Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22396v1",
    "source": "arXiv",
    "abstract": "Artificial Intelligence (AI), particularly Large Language Models (LLMs), is transforming scientific discovery, enabling rapid knowledge generation and hypothesis formulation. However, a critical challenge is hallucination, where LLMs generate factually incorrect or misleading information, compromising research integrity. To address this, we introduce HalluMatData, a benchmark dataset for evaluating hallucination detection methods, factual consistency, and response robustness in AI-generated materials science content. Alongside this, we propose HalluMatDetector, a multi-stage hallucination detection framework that integrates intrinsic verification, multi-source retrieval, contradiction graph analysis, and metric-based assessment to detect and mitigate LLM hallucinations. Our findings reveal that hallucination levels vary significantly across materials science subdomains, with high-entropy queries exhibiting greater factual inconsistencies. By utilizing HalluMatDetector verification pipeline, we reduce hallucination rates by 30% compared to standard LLM outputs. Furthermore, we introduce the Paraphrased Hallucination Consistency Score (PHCS) to quantify inconsistencies in LLM responses across semantically equivalent queries, offering deeper insights into model reliability."
  },
  {
    "date": "2025-12-26",
    "title": "Symbolic Specification and Reasoning for Quantum Data and Operations",
    "authors": "Mingsheng Ying",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.22383v1",
    "source": "arXiv",
    "abstract": "In quantum information and computation research, symbolic methods have been widely used for human specification and reasoning about quantum states and operations. At the same time, they are essential for ensuring the scalability and efficiency of automated reasoning and verification tools for quantum algorithms and programs. However, a formal theory for symbolic specification and reasoning about quantum data and operations is still lacking, which significantly limits the practical applicability of automated verification techniques in quantum computing. In this paper, we present a general logical framework, called Symbolic Operator Logic $\\mathbf{SOL}$, which enables symbolic specification and reasoning about quantum data and operations. Within this framework, a classical first-order logical language is embedded into a language of formal operators used to specify quantum data and operations, including their recursive definitions. This embedding allows reasoning about their properties modulo a chosen theory of the underlying classical data (e.g., Boolean algebra or group theory), thereby leveraging existing automated verification tools developed for classical computing. It should be emphasised that this embedding of classical first-order logic into $\\mathbf{SOL}$ is precisely what makes the symbolic method possible. We envision that this framework can provide a conceptual foundation for the formal verification and automated theorem proving of quantum computation and information in proof assistants such as Lean, Coq, and related systems."
  },
  {
    "date": "2025-12-29",
    "title": "Gate-Breaker: An LLM-Powered Netlist-to-RTL Reverse Engineering Tool",
    "authors": "Md Omar Faruque, Peter Jamieson, Ahmad Patooghy, Abdel-Hameed A. Badawy",
    "publish": "2025 IEEE International Performance, Computing, and Communications Conference (IPCCC)",
    "url": "https://doi.org/10.1109/ipccc66453.2025.11304682",
    "source": "IEEE",
    "abstract": "The escalating sophistication of hardware intellectual property (IP) theft, a multi-billion dollar problem for the semiconductor industry, demands novel approaches to both understanding attack vectors and fortifying defenses. This paper evaluates the potential of Large Language Models (LLMs) to reverse engineer Register Transfer Level (RTL) designs from gate-level netlists. We introduce a framework for netlist-to-RTL conversion, leveraging pattern recognition and code generation capabilities of modern LLMs. Our evaluation of four available LLM models across 156 circuit benchmarks reveals that LLMs can indeed recover functional RTL with reasonable accuracy until the RTL benchmarks become our classified 4th quartile of code complexity. We also provide a similarity metrics-based methodology to evaluate and ascertain the quality of reverse engineering. Among the evaluated models, OpenAI's O3-Mini emerged as the best performer with 75.1 % overall success rate. While performance degrades significantly on the most complex 4th quartile (53.4 % success rate), when O3-Mini does succeed on these challenging designs, it maintains a high Abstract Syntax Tree (AST) similarity of 0.924 and achieves a moderate 0.871 Control Flow Graph (CFG) similarity."
  },
  {
    "date": "2025-12-29",
    "title": "Design &amp; Implementation of Karatsuba Multiplier: A complete RTL to GDS II Flow",
    "authors": "Peketi Reshma, A S Surabhi, Sujatha Hiremath",
    "publish": "2025 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)",
    "url": "https://doi.org/10.1109/conecct65861.2025.11306762",
    "source": "IEEE",
    "abstract": "Efficient multiplier design is critical for DSP, cryptography, and high-performance computing. The Karatsuba multiplication algorithm reduces computation but is significantly reliant on the adder used for partial product accumulation. The Brent-Kung adder, which has an area of $408 \\mu \\mathrm{~m} 2$, a power consumption of $45.78 \\mu \\mathrm{~W}$, and a timing slack of 1 ns, is the most efficient option for this design, based on a comparative analysis of adders, including the Brent-Kung, Carry Select, and Ripple Carry Adders. This paper introduces a 32-bit Karatsuba multiplier based on a Brent-Kung (BK) adder that is optimised for power, area, and performance. In addition, scan flip-flops are used to improve testing and reliability throughout manufacturing testing. The Karatsuba algorithm is designed and implemented with the Brent-Kung adder’s parallel prefix structure, which reduces carry propagation time and increases total computational performance. Cadence EDA tools were used to implement the RTL to GDSII pipeline. The Brent-Kung adderbased design resulted in a 27.8% reduction in area compared to the conventional design employing square root carry select adder. The existing design has a slack of 0.068 ns, indicating improved timing closure. Post-layout simulations show that the BrentKung adder-based Karatsuba multiplier outperforms traditional architectures, making it an excellent choice for high-performance, energy-efficient computing applications."
  },
  {
    "date": "2025-12-29",
    "title": "ML-Driven Methodology for Converting Hand-Drawn FSM Diagrams in Specification Documents into RTL",
    "authors": "Almonzer Alaaeldin, Ibrahim Amr, Bassem Osama, Ahmed Hussein, Khaled Salah",
    "publish": "2025 IEEE East-West Design &amp;amp; Test Symposium (EWDTS)",
    "url": "https://doi.org/10.1109/ewdts67441.2025.11303682",
    "source": "IEEE",
    "abstract": "This work proposes an algorithm for converting Finite State Machine diagrams from specification documents into Verilog HDL code. The design utilizes multiple YOLOv3 models for object detection, the Hough Transform for straight arrow detection, and k-nearest neighbours for number detection. The proposed methodology uses object recognition techniques to identify states/circles, state names, edges (arrows - straight and curved, arrowheads), source and destination states of an edge, input/output numbers on edges, etc. The validation test sets are machine printed images. Validation results show 98% accuracy and runtime under 30 seconds. The final accuracy represents the quality of the generated RTL."
  },
  {
    "date": "2025-12-29",
    "title": "Machine Learning Based Power Prediction for RTL-Level MIPS Processor Design",
    "authors": "Roopa G Desai, Basavaraj M Goudappanavar, Maneek Poojari, Kaushik Mallibhat",
    "publish": "2025 International Conference on Intelligent Systems and Pioneering Innovations in Robotics and Electric Mobility (INSPIRE)",
    "url": "https://doi.org/10.1109/inspire67328.2025.11300551",
    "source": "IEEE",
    "abstract": "Power prediction and optimization are critical in digital design, especially at the Register Transfer Level (RTL), since it is the initial phase where architectural choices have a significant influence on the eventual power consumption of a circuit. Power estimation early and accurately enables designers to make effective trade-offs among performance, area, and power. The proposed work aims to address the challenge of an accurate prediction of power and optimization at the Register Transfer Level(RTL) in digital design. The proposed work focuses on the identification of the power loss source in digital design using switching activity at RTL in a Microprocessor without Interlocked Pipeline Stages(MIPS) processor. The Value Change Dump(VCD) file generated using the Xilinx ISE Design Suite simulates various input conditions in circuit design to produce switching activities in the circuit that describes signal transitions.The proposed work uses an ensemble model of Gradient Boosting and Ridge Regression, towards improving the predictive power, and obtained Mean Squared Error(MSE) is 2.13%."
  },
  {
    "date": "2025-12-29",
    "title": "Predictive Wellness Analytics Through Hybrid Sensor-LLM Integration",
    "authors": "Roopam Dhanraj Choudhari, Gaurav Khodwe",
    "publish": "2025 International Conference on Big Data, Knowledge and Control Systems Engineering (BdKCSE)",
    "url": "https://doi.org/10.1109/bdkcse67969.2025.11300494",
    "source": "IEEE",
    "abstract": "This paper presents a novel predictive wellness analytics framework that integrates human activity recognition (HAR) sensor data with large language model (LLM) extracted behavioral context for personalized health interventions. Our hybrid pipeline combines the WISDM accelerometer dataset with contextual features derived from natural language wellness logs, enabling both accurate activity classification and personalized recommendation generation. The proposed late-fusion architecture achieves 98.2% accuracy for core activity recognition (Walking, Jogging, Sitting, Standing) while simultaneously providing contextually aware wellness recommendations. Through controlled experimental validation using synthetic wellness narratives, we demonstrate that incorporating LLM-extracted behavioral features (sleep patterns, fatigue levels, activity goals) significantly enhances the personalization capabilities of traditional sensor-based wellness systems. This work establishes a technical foundation for intelligent digital health assistants that bridges the gap between objective sensor measurements and subjective wellness experiences, while identifying critical research directions for real-world deployment."
  },
  {
    "date": "2025-12-29",
    "title": "LLM-Enhanced Multi-Channel Recommendation with Adaptive Ensemble Ranking",
    "authors": "Aijia Sun",
    "publish": "Proceedings of the 4th International Conference on Artificial Intelligence and Intelligent Information Processing",
    "url": "https://doi.org/10.1145/3778534.3778591",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2025-12-29",
    "title": "Verification of the Methodology for Verification of Pressure Gauges Used in Pressure Equipment and Railway Transport",
    "authors": "Zlatka Chavdarova, Desislava Koleva, Hristiana Nikolova",
    "publish": "2025 XXXV International Scientific Symposium Metrology and Metrology Assurance (MMA)",
    "url": "https://doi.org/10.1109/mma67107.2025.11311221",
    "source": "IEEE",
    "abstract": "Bulgarian Institute of Metrology (BIM) carries out metrological control of measuring instruments according to methodologies approved by the president of the Institute. The methodologies for verification of measuring instruments are developed on the basis of standardized methods. This paper presents the results of the verification of the Methodology for verification of pressure gauges used in pressure equipment and railway transport."
  },
  {
    "date": "2025-12-29",
    "title": "Using LLM to Design Reward Function for Bipedal Walker-v3",
    "authors": "Shuangyi Dong",
    "publish": "Proceedings of the 4th International Conference on Artificial Intelligence and Intelligent Information Processing",
    "url": "https://doi.org/10.1145/3778534.3778593",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2025-12-29",
    "title": "LLM Powered Memory Consolidation for Ubiquitous Computing",
    "authors": "Parampuneet Kaur Thind, Vaibhav Kumar Katturu",
    "publish": "Companion of the 2025 ACM International Joint Conference on Pervasive and Ubiquitous Computing",
    "url": "https://doi.org/10.1145/3714394.3750599",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2025-12-29",
    "title": "Towards DevOps of Zero-Knowledge Proofs on Blockchain: LLM-Enhanced Proof Generation and Contract Deployment",
    "authors": "Goshgar Can Ismayilov",
    "publish": "2025 International Conference on Big Data, Knowledge and Control Systems Engineering (BdKCSE)",
    "url": "https://doi.org/10.1109/bdkcse67969.2025.11300538",
    "source": "IEEE",
    "abstract": "Zero-knowledge proof is one of the most promising privacy-preserving approaches in the current literature. However, its complex nature leads its development and deployment to be time-consuming and error-prone. Furthermore, despite the increasing adoption of zero-knowledge proof in the blockchain applications, there is still no systematic framework that streamlines the end-to-end life-cycle of proof development. This paper introduces the first LLM-enhanced zero-knowledge proof DevOps framework for blockchain (i.e. zkOps) to the literature. To evaluate the performance of the framework on different real-life scenarios, a small benchmarking suite is constructed with the increasing computational complexity with respect to the size of circuit constraints. The experimental study identifies the effects of the model temperature on the code compilation rate, and the complexity of prompts on the service latencies. The findings show that the framework efficiently handles the varying-complexity of prompts with a maximum successful compilation rate of 70% (i.e., up to 200,000 proof constraints)."
  },
  {
    "date": "2025-12-29",
    "title": "Adaptive LLM Routing for Scientific Workflows: Predicting Query Complexity to Optimize Cost",
    "authors": "Jonas Thierfeldt, Dominik Scheinert, Thorsten Wittkopp, Odej Kao",
    "publish": "2025 IEEE International Performance, Computing, and Communications Conference (IPCCC)",
    "url": "https://doi.org/10.1109/ipccc66453.2025.11304643",
    "source": "IEEE",
    "abstract": "Scientific workflows increasingly incorporate large-language-model (LLM) services for tasks such as metadata curation, code generation, and interactive analysis. However, inference cost in terms of resource usage varies widely with query complexity, both for service-based or self-hosted setups. Current “always-XL” deployments tend to over-provision: they safeguard response quality but squander compute usage. We introduce a routing framework based on query complexity estimations that trains a lightweight classifier on past multi-model performance data to predict the smallest model likely to satisfy a target quality threshold and then routes queries accordingly. Evaluated on <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\text{4 0, 0 0 4}$</tex> Mix-Instruct prompts, our method matches an XL-only baseline (<tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$+0.27 \\%$</tex> quality) while reducing floating-point operations by 12.9 %, achieving competitive performance at a fraction of the cost. The method thus enables scalable, complexity-aware routing for LLM services within data- and compute-intensive scientific workflows."
  },
  {
    "date": "2025-12-29",
    "title": "BitRL-Light: 1-Bit LLM Agents with Deep Reinforcement Learning for Energy-Efficient Smart Home Lighting Optimization",
    "authors": "Ravi Gupta, Shabista Haider",
    "publish": "2025 IEEE International Performance, Computing, and Communications Conference (IPCCC)",
    "url": "https://doi.org/10.1109/ipccc66453.2025.11304691",
    "source": "IEEE",
    "abstract": "Smart home lighting systems consume 15−20% of residential energy but lack adaptive intelligence to optimize for user comfort and energy efficiency simultaneously. We present BitRL-Light, a novel framework combining 1-bit quantized Large Language Models (LLMs) with Deep Q-Network (DQN) reinforcement learning for real-time smart home lighting control on edge devices. Our approach deploys a 1-bit quantized Llama-3.21B model on Raspberry Pi hardware, achieving 71.4 times energy reduction compared to full-precision models while maintaining intelligent control capabilities. Through multi-objective reinforcement learning, BitRL-Light learns optimal lighting policies from user feedback, balancing energy consumption, comfort, and circadian alignment. Experimental results demonstrate 32% energy savings compared to rule-based systems, with inference latency under 200 ms on Raspberry Pi 4 and 95% user satisfaction. The system processes natural language commands via Google Home/IFTTT integration and learns from implicit feedback through manual overrides. Our comparative analysis shows 1bit models achieve 5.07 times speedup over 2-bit alternatives on ARM processors while maintaining 92% task accuracy. This work establishes a practical framework for deploying adaptive AI on resource-constrained IoT devices, enabling intelligent home automation without cloud dependencies."
  },
  {
    "date": "2025-12-29",
    "title": "Mitigating Syntax and Logic Errors in LLM Based Code Generation via XML-Structured Prompts",
    "authors": "Saket Sambaraju, Jeffrey Boman, Howell Wu, Ziliang Zong",
    "publish": "2025 IEEE International Performance, Computing, and Communications Conference (IPCCC)",
    "url": "https://doi.org/10.1109/ipccc66453.2025.11304661",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) have become powerful tools for automated code generation. Yet, they remain prone to both syntax and logic errors that limit their effectiveness in real-world software development. This paper comprehensively evaluates LLM-generated code utilizing the Codeforces Benchmark, and proposes XML-Structured Prompts (XSP) to improve code quality. Specifically, we present three creative strategies: XSP for improving problem comprehension, Syntax-Aware XSP (SA-XSP) for mitigating syntax errors, and Testcase-Driven Logic Error Debugging (TDLED) for resolving logic errors through test case feedback. Our experiments on 30 LLMs, ranging from <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$0.5 ~\\mathrm{B}, 70 ~\\mathrm{B}$</tex>, to 671 B parameters and including 5 reasoning models, demonstrate that the proposed methods improve accuracy by up to 27.5 %, especially in smaller models, with syntax error reductions of up to 60 % and logic error corrections by up to 30%."
  },
  {
    "date": "2025-12-29",
    "title": "From Randomness to Predictability - Fine Tuning the Key Parameters of LLM for Better Detection of Hallucination",
    "authors": "Deeksha Athreya, Animesh Giri",
    "publish": "2025 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)",
    "url": "https://doi.org/10.1109/conecct65861.2025.11306887",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) are revolutionizing various fields but remain vulnerable to hallucinations, undermining trust and reliability. In this paper, we have introduced a novel mathematical model that can predict the level of hallucination in various architectures of LLMs. This new model takes into account the key parameters and architectural factors of different models of LLMs to arrive at its prediction. The obtained solution is proven to be positive and can predict hallucination within the range of 10% error margin in various LLM models. To validate the theoretical results, we conducted numerous experiments which provided insights into the behavior of the model and under different set ups. This new finding aims to be a stepping stone to predict hallucination in LLM very effectively."
  },
  {
    "date": "2025-12-29",
    "title": "$NieNie:$ Adaptive Rhythmic System for Stress Relief with LLM-Based Guidance",
    "authors": "Yichen Yu, Qiaoran Wang",
    "publish": "Companion of the 2025 ACM International Joint Conference on Pervasive and Ubiquitous Computing",
    "url": "https://doi.org/10.1145/3714394.3750586",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2025-12-29",
    "title": "Agent2Tool: MCP-Enhanced Reliable Integration of LLM Agents and Legacy Optimization Solvers",
    "authors": "Tong Qiu, Jingwei Ge, Wenhan Wu, Fei-Yue Wang",
    "publish": "2025 IEEE 25th International Symposium on Computational Intelligence and Informatics (CINTI)",
    "url": "https://doi.org/10.1109/cinti67731.2025.11311789",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) are increasingly applied as intelligent agents in scientific computing. However, their integration with optimization solvers remains hindered by semantic-syntactic mismatches and protocol-level interference. In this work, we propose Agent2Tool, a robust framework that extends the Model Context Protocol (MCP) to support reliable agent-to-solver communication. The framework introduces a non-invasive output suppression mechanism, semantic parsing modules, and multi-layered error handling to ensure structured control over solvers such as Gurobi. We test five optimization problems under simple and complex task conditions. The results show that Agent2Tool consistently improves task-solving accuracy by achieving up to $21.5 \\%$ average gain in complex scenarios and preserves solver generality and agent autonomy. These results demonstrate that protocol-aware encapsulation is essential for enabling a dependable, tool-augmented LLM agent in optimization applications."
  },
  {
    "date": "2025-12-29",
    "title": "X-Flow: Explanation-Augmented prompting for LLM-Based Intrusion Detection",
    "authors": "Iván Pizarro, Ricardo Ñanculef, Carlos Valle",
    "publish": "2025 15th IEEE International Conference on Pattern Recognition Systems (ICPRS)",
    "url": "https://doi.org/10.1109/icprs66293.2025.11302848",
    "source": "IEEE",
    "abstract": "The increasing complexity of cyberattacks demands more intelligent Intrusion Detection Systems (IDS) to identify or mitigate the effects of malicious activities in networks. While Large Language Models (LLMs) have shown promise in many tasks, current approaches using zero-shot and few-shot classification have shown limited results for flow-based intrusion detection, with zero-shot yielding poor performance for the more complex attack types and few-shot exhibiting high variance. This paper introduces X-Flow, a two-stage explanation-guided approach that leverages LLM-generated explanations to enhance LLM-based network intrusion detection. X-Flow generates class-level natural language explanations from labeled data, which are then injected into the classification prompt of another LLM for real-time detection. Evaluated on the CIDDS-001 dataset across five LLMs, X-Flow improves macro F1-score over zero-shot classification, with substantial improvements across all the models, with gains of 12.9 to 39.2 points in the more competitive models GPT-4.1 and Gemma 27B. X-Flow also improves over few-shot classification in competitive models, achieving better F1-score, precision, and reduced variance, though gains are more modest. We find that smaller models with poor baseline performance show limited benefit from enriched prompts, suggesting they may require stronger interventions to acquire domain-specific knowledge from tabular IDS datasets. X-Flow also outperforms a recently proposed deep learning method explicitly trained on CIDDS-001 by up to 17.6 F1-score points. Our findings show that providing human-readable context in the prompt can effectively transfer knowledge from labeled IDS datasets, increasing the effectiveness and interpretability of LLMs in flow-based intrusion detection with a computational cost similar to that of few-shot prompting. We also release the generated explanations as a dataset to facilitate broader cybersecurity applications."
  },
  {
    "date": "2025-12-29",
    "title": "Reducing traffic accidents through real-time detection and alerting of hazardous driving behaviors using multimodal LLM",
    "authors": "Naoudouwel Fulbert, S J Rexline",
    "publish": "2025 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)",
    "url": "https://doi.org/10.1109/conecct65861.2025.11306651",
    "source": "IEEE",
    "abstract": "This Road accidents remain a leading cause of death worldwide, with driver distraction, fatigue, and drowsiness identified as major contributing factors. Recent advancements in artificial intelligence, particularly multimodal large language models (LLMs), offer promising solutions for addressing these critical safety issues. This paper presents the development of a lightweight embedded system designed to detect hazardous driving behaviors such as subtle drowsiness or mobile phone usage by drivers. The system leverages the Gemini API, an advanced multimodal LLM capable of realtime image analysis, enabling efficient and accurate detection of accident-prone behaviors without extensive local computing resources. Our proposed solution comprises three modules: continuous image capture of the driver, image analysis via Gemini API, and real-time auditory alerts triggered upon detection of risky behaviors. Initial evaluations demonstrate high accuracy, minimal latency, and robust performance under realistic conditions, validating our hypothesis that utilizing cloud-based multimodal LLMs significantly enhances the detection of driver distraction and fatigue. Future work includes adapting the system to mobile devices, utilizing smartphone front cameras, and exploring open-source models for cost-effective deployment."
  },
  {
    "date": "2025-12-29",
    "title": "LLM-Based Decision Support for the Planning of Personalized Chemotherapy",
    "authors": "Ákos Pálosi, Csaba István Dézsi, Martin Ferenc Dömény, Dániel András Drexler",
    "publish": "2025 IEEE 25th International Symposium on Computational Intelligence and Informatics (CINTI)",
    "url": "https://doi.org/10.1109/cinti67731.2025.11311826",
    "source": "IEEE",
    "abstract": "A key difficulty in solving multi-objective optimization problems is that multiple solutions may be considered optimal, without a clear criterion for selecting among them. Traditionally, this issue is resolved by involving a decision maker, a domain expert familiar with the task at hand. Their involvement results in an interactive optimization process, but one that cannot be automated efficiently. In order to overcome this limitation, we propose replacing the decision maker with a Large Language Model (LLM), which would be responsible for guiding the optimization in the appropriate direction. The goal of our work is thus to develop an LLM-based decision support system capable of assisting and directing a multiobjective Epsilon-constraint optimization procedure to identify the most suitable solution. Large language models represent a promising alternative to human expertise, as they possess a level of generalizable knowledge and human-like reasoning skills. In addition, they are capable of generating creative ideas, which can be particularly useful for tasks requiring the identification of connections between data points."
  },
  {
    "date": "2025-12-29",
    "title": "Supporting Self-Awareness of Smartphone Use with Passive Sensing and LLM-Driven Feedback",
    "authors": "Nigel Sjölin Grech, Gabriella Trasciatti",
    "publish": "Companion of the 2025 ACM International Joint Conference on Pervasive and Ubiquitous Computing",
    "url": "https://doi.org/10.1145/3714394.3756242",
    "source": "ACM",
    "abstract": "None"
  }
]