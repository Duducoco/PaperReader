[
  {
    "date": "2026-01-05",
    "title": "Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching",
    "authors": "Roja Sahoo, Anoop Namboodiri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.02318v1",
    "source": "arXiv",
    "abstract": "Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint)."
  },
  {
    "date": "2026-01-05",
    "title": "Automatic Assertion Mining in Assertion-Based Verification: Techniques, Challenges, and Future Directions",
    "authors": "Mohammad Reza Heidari Iman, Giorgio Di Natale, Katell Morin-Allory",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.02248v1",
    "source": "arXiv",
    "abstract": "Functional verification increasingly relies on Assertion-Based Verification (ABV), which has become a key approach for verifying hardware designs due to its efficiency and effectiveness. Central to ABV are automatic assertion miners, which apply different techniques to generate assertions automatically. This paper reviews the most recent, advanced, and widely adopted assertion miners, offering a comparative analysis of their methodologies. The goal is to provide researchers and verification practitioners with insights into the capabilities and limitations of existing miners. By identifying their shortcomings, this work also points toward directions for developing more powerful and advanced assertion miners in the future."
  },
  {
    "date": "2026-01-05",
    "title": "Density-based topology optimization for turbulent fluid flow using the standard k-epsilon RANS model with wall-functions imposed through an implicit wall penalty formulation",
    "authors": "Amirhossein Bayat, Hao Li, Joe Alexandersen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.02202v1",
    "source": "arXiv",
    "abstract": "Turbulent flows have high requirements for very fine meshes near the boundary to ensure accuracy. In the context of topology optimization (TO), such fine meshes become unrealistic and common approaches are hampered by low accuracy and overestimation of boundary layer thickness. Wall-functions are a natural way to ease the computational requirements, but they are not naturally imposed in density-based TO due to the diffuse design parametrization. We propose an implicit wall-function formulation for the Reynolds-Averaged Navier-Stokes (RANS), standard k-epsilon model that extracts wall-normal information directly from the gradient of the design variable and enables a penalty-based formulation for imposing wall-functions to the RANS equations, without the need for body-fitted meshes. The method provides a reliable route to high Reynolds number turbulent topology optimization, delivering boundary layer accuracy comparable to explicit-wall body-fitted analyses, while retaining the flexibility of density-based TO. Furthermore, because wall effects are modeled using wall-functions, accurate solutions are obtained on substantially coarser meshes, leading to significant reductions in computational cost. The approach is validated on three canonical benchmarks over Reynolds numbers up to Re = 2e5: a pipe-bend; a U-bend; and a Tesla-valve. Across all cases, the proposed method accurately recovers near-wall velocity profiles, closely matching verification simulations on body-fitted meshes with explicit wall-functions. In contrast, a conventional turbulent TO formulation, without the proposed wall-function treatment, mispredicts boundary-layer development and yields sub-optimal results."
  },
  {
    "date": "2026-01-05",
    "title": "The extended phase space thermodynamics and Ehrenfest scheme for the Kerr-Sen AdS black holes",
    "authors": "Md Sabir Ali, Arindam Mondal, Sushant G. Ghosh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01814v1",
    "source": "arXiv",
    "abstract": "In the present work, we numerically investigate the horizon structure of the Kerr-Sen black holes in anti-de Sitter (AdS) spacetime. Further, we investigate the phase transitions and critical phenomena in Kerr-Sen-AdS black holes at the critical points. Such black holes are characterized by its mass ($M$), the dilaton charge ($Q$), and the negative cosmological constant, $Λ(<0)$. We define a dimensionless parameter $ε=\\bar{J}/{\\bar{Q}^2}$ and express the mass, temperature, volume, and Gibbs free energy in terms of $ε$ and its polynomials. Moreover, we numerically fit the data for the critical points and find that in the appropriate limit, the expressions for critical points would correspond to the respective critical points of the Kerr-AdS black hole thermodynamics. Such a study involves a systematic analysis of temperature, Gibbs free energy, and volume in the extended phase space. We provide an analytical verification of the nature of the phase transitions at the critical points by introducing the Ehrenfest equations. We also check that all three quantities, e.g., the specific heat at constant pressure, $C_P$, the volume expansion coefficient, $α$, and the isothermal compressibility, $κ_T$, diverge at the critical points. We find the $Prigogine$-$Defay$ ratio using the expressions of $C_P$, $α$, and $κ_T$, and find that it identically equals unity. Hence, the phase transition behavior of the Kerr-Sen-AdS black holes at their critical points is of second order. In addition, we propose investigating the energy extraction process via the Penrose process. Later, we calculate the speed of sound and adiabatic compressibility for the rotating Kerr-Sen-AdS black holes. Finally, on a specific note, we calculate the thermodynamic quantities of the boundary conformal field theory (CFT) dual to the extended phase space."
  },
  {
    "date": "2026-01-05",
    "title": "Physically natural metric-measure Lindbladian ensembles and their learning hardness",
    "authors": "Caisheng Cheng, Ruicheng Bao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01806v1",
    "source": "arXiv",
    "abstract": "In open quantum systems, a basic question at the interface of quantum information, statistical physics, and many-body dynamics is how well can one infer the structure of noise and dissipation generators from finite-time measurement statistics alone. Motivated by this question, we study the learnability and cryptographic applications of random open-system dynamics generated by Lindblad-Gorini-Kossakowski-Sudarshan (GKSL) master equations. Working in the affine hull of the GKSL cone, we introduce physically motivated ensembles of random local Lindbladians via a linear parametrisation around a reference generator. On top of this geometric structure, we extend statistical query (SQ) and quantum-process statistical query (QPStat) frameworks to the open-system setting and prove exponential (in the parameter dimension $M$) lower bounds on the number of queries required to learn random Lindbladian dynamics. In particular, we establish average-case SQ-hardness for learning output distributions in total variation distance and average-case QPStat-hardness for learning Lindbladian channels in diamond norm. To support these results physically, we derive a linear-response expression for the ensemble-averaged total variation distance and verify the required nonvanishing scaling in a random local amplitude-damping chain. Finally, we design two Lindbladian physically unclonable function (Lindbladian-PUF) protocols based on random Lindbladian ensembles with distribution-level and tomography-based verification, thereby providing open-system examples where learning hardness can be translated into cryptographic security guarantees."
  },
  {
    "date": "2026-01-05",
    "title": "VerLM: Explaining Face Verification Using Natural Language",
    "authors": "Syed Abdul Hannan, Hazim Bukhari, Thomas Cantalapiedra, Eman Ansar, Massa Baali, Rita Singh, Bhiksha Raj",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01798v1",
    "source": "arXiv",
    "abstract": "Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems."
  },
  {
    "date": "2026-01-05",
    "title": "A New Benchmark for the Appropriate Evaluation of RTL Code Optimization",
    "authors": "Yao Lu, Shang Liu, Hangan Zhou, Wenji Fang, Qijun Zhang, Zhiyao Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01765v1",
    "source": "arXiv",
    "abstract": "The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization."
  },
  {
    "date": "2026-01-05",
    "title": "AI Agent Systems: Architectures, Applications, and Evaluation",
    "authors": "Bin Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01743v1",
    "source": "arXiv",
    "abstract": "AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\\ multi-agent; centralized vs.\\ decentralized coordination), and deployment settings (offline analysis vs.\\ online interactive assistance; safety-critical vs.\\ open-ended tasks). We discuss key design trade-offs -- latency vs.\\ accuracy, autonomy vs.\\ controllability, and capability vs.\\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads."
  },
  {
    "date": "2026-01-05",
    "title": "Explicit World Models for Reliable Human-Robot Collaboration",
    "authors": "Kenneth Kwok, Basura Fernando, Qianli Xu, Vigneshwaran Subbaraju, Dongkyu Choi, Boon Kiat Quek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01705v1",
    "source": "arXiv",
    "abstract": "This paper addresses the topic of robustness under sensing noise, ambiguous instructions, and human-robot interaction. We take a radically different tack to the issue of reliable embodied AI: instead of focusing on formal verification methods aimed at achieving model predictability and robustness, we emphasise the dynamic, ambiguous and subjective nature of human-robot interactions that requires embodied AI systems to perceive, interpret, and respond to human intentions in a manner that is consistent, comprehensible and aligned with human expectations. We argue that when embodied agents operate in human environments that are inherently social, multimodal, and fluid, reliability is contextually determined and only has meaning in relation to the goals and expectations of humans involved in the interaction. This calls for a fundamentally different approach to achieving reliable embodied AI that is centred on building and updating an accessible \"explicit world model\" representing the common ground between human and AI, that is used to align robot behaviours with human expectations."
  },
  {
    "date": "2026-01-04",
    "title": "Mitigating Longitudinal Performance Degradation in Child Face Recognition Using Synthetic Data",
    "authors": "Afzal Hossain, Stephanie Schuckers",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01689v1",
    "source": "arXiv",
    "abstract": "Longitudinal face recognition in children remains challenging due to rapid and nonlinear facial growth, which causes template drift and increasing verification errors over time. This work investigates whether synthetic face data can act as a longitudinal stabilizer by improving temporal robustness of child face recognition models. Using an identity disjoint protocol on the Young Face Aging (YFA) dataset, we evaluate three settings: (i) pretrained MagFace embeddings without dataset specific fine-tuning, (ii) MagFace fine-tuned using authentic training faces only, and (iii) MagFace fine-tuned using a combination of authentic and synthetically generated training faces. Synthetic data is generated using StyleGAN2 ADA and incorporated exclusively within the training identities; a post generation filtering step is applied to mitigate identity leakage and remove artifact affected samples. Experimental results across enrollment verification gaps from 6 to 36 months show that synthetic-augmented fine tuning substantially reduces error rates relative to both the pretrained baseline and real only fine tuning. These findings provide a risk aware assessment of synthetic augmentation for improving identity persistence in pediatric face recognition."
  },
  {
    "date": "2026-01-04",
    "title": "Evaluating Deep Learning-Based Face Recognition for Infants and Toddlers: Impact of Age Across Developmental Stages",
    "authors": "Afzal Hossain, Mst Rumana Sumi, Stephanie Schuckers",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01680v1",
    "source": "arXiv",
    "abstract": "Face recognition for infants and toddlers presents unique challenges due to rapid facial morphology changes, high inter-class similarity, and limited dataset availability. This study evaluates the performance of four deep learning-based face recognition models FaceNet, ArcFace, MagFace, and CosFace on a newly developed longitudinal dataset collected over a 24 month period in seven sessions involving children aged 0 to 3 years. Our analysis examines recognition accuracy across developmental stages, showing that the True Accept Rate (TAR) is only 30.7% at 0.1% False Accept Rate (FAR) for infants aged 0 to 6 months, due to unstable facial features. Performance improves significantly in older children, reaching 64.7% TAR at 0.1% FAR in the 2.5 to 3 year age group. We also evaluate verification performance over different time intervals, revealing that shorter time gaps result in higher accuracy due to reduced embedding drift. To mitigate this drift, we apply a Domain Adversarial Neural Network (DANN) approach that improves TAR by over 12%, yielding features that are more temporally stable and generalizable. These findings are critical for building biometric systems that function reliably over time in smart city applications such as public healthcare, child safety, and digital identity services. The challenges observed in early age groups highlight the importance of future research on privacy preserving biometric authentication systems that can address temporal variability, particularly in secure and regulated urban environments where child verification is essential."
  },
  {
    "date": "2026-01-04",
    "title": "Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration",
    "authors": "Albert Sadowski, Jarosław A. Chudziak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01609v1",
    "source": "arXiv",
    "abstract": "Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express."
  },
  {
    "date": "2026-01-04",
    "title": "The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs",
    "authors": "Zibo Zhao, Yuanting Zha, Haipeng Zhang, Xingcheng Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01580v1",
    "source": "arXiv",
    "abstract": "Self-reflection capabilities emerge in Large Language Models after RL post-training, with multi-turn RL achieving substantial gains over SFT counterparts. Yet the mechanism of how a unified optimization objective gives rise to functionally distinct capabilities of generating solutions and evaluating when to revise them remains opaque. To address this question, we introduce the Gradient Attribution Property to characterize how reward gradients distribute across policy components, formalized through the Two-Stage Decision-Sampling (DS) Hypothesis, which decomposes the policy into sampling ($π_{sample}$) for generation and decision ($π_{d}$) for verification. We prove that surrogate rewards exhibit Balanced Gradient Attribution, while SFT and KL penalties exhibit Unbalanced Gradient Attribution, with length-weighting creating asymmetric regularization that constrains $π_{sample}$ while leaving $π_{d}$ under-optimized, providing an theoretical explanation of why RL succeeds where SFT fails. We also empirically validate our theoretical predictions on arithmetic reasoning demonstrates that RL's superior generalization stems primarily from improved decision-making ($π_{d}$) rather than sampling capabilities, providing a first-principles mechanistic explanation for self-correction in thinking models."
  },
  {
    "date": "2026-01-04",
    "title": "Distortion Instead of Hallucination: The Effect of Reasoning Under Strict Constraints",
    "authors": "Junichiro Niimi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01490v1",
    "source": "arXiv",
    "abstract": "With the widespread adoption of large language models (LLMs), hallucinations, which are non-factual fabrications in model outputs, have become serious concerns. Reasoning capabilities have received attention as a self-verification process to improve output reliability. However, the effect of reasoning within a closed system where LLMs cannot rely on external tools or knowledge has yet to be clarified. We therefore conduct experiments under strict constraints (recommending peer-reviewed journal articles in computer science) to examine the effect of reasoning across multiple models (GPT-5.2 and Gemini 3 Flash). Our results reveal a problematic trade-off between constraint compliance and factual accuracy. Non-reasoning models exhibit high constraint violation rates (66-75%) but maintain factual accuracy, while reasoning models reduce violations (13-26%) but systematically distort known facts to satisfy constraints and increase complete fabrication. This trade-off pattern is consistent across both models despite different architectures, indicating a fundamental limitation of reasoning. Furthermore, reasoning does not uniformly improve output authenticity: effects diverge by model, reflecting different allocations of the compliance-truthfulness trade-off. These findings challenge the assumption that reasoning universally improves reliability: reasoning models trade honest constraint violations for detection-resistant distortions."
  },
  {
    "date": "2026-01-04",
    "title": "Unified Generation and Self-Verification for Vision-Language Models via Advantage Decoupled Preference Optimization",
    "authors": "Xinyu Qiu, Heng Jia, Zhengwen Zeng, Shuheng Shen, Changhua Meng, Yi Yang, Linchao Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01483v1",
    "source": "arXiv",
    "abstract": "Parallel test-time scaling typically trains separate generation and verification models, incurring high training and inference costs. We propose Advantage Decoupled Preference Optimization (ADPO), a unified reinforcement learning framework that jointly learns answer generation and self-verification within a single policy. ADPO introduces two innovations: a preference verification reward improving verification capability and a decoupled optimization mechanism enabling synergistic optimization of generation and verification. Specifically, the preference verification reward computes mean verification scores from positive and negative samples as decision thresholds, providing positive feedback when prediction correctness aligns with answer correctness. Meanwhile, the advantage decoupled optimization computes separate advantages for generation and verification, applies token masks to isolate gradients, and combines masked GRPO objectives, preserving generation quality while calibrating verification scores. ADPO achieves up to +34.1% higher verification AUC and -53.5% lower inference time, with significant gains of +2.8%/+1.4% accuracy on MathVista/MMMU, +1.9 cIoU on ReasonSeg, and +1.7%/+1.0% step success rate on AndroidControl/GUI Odyssey."
  },
  {
    "date": "2026-01-04",
    "title": "Bithoven: Formal Safety for Expressive Bitcoin Smart Contracts",
    "authors": "Hyunhum Cho, Ik Rae Jeong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01436v1",
    "source": "arXiv",
    "abstract": "The rigorous security model of Bitcoin's UTXO architecture often comes at the cost of developer usability, forcing a reliance on manual stack manipulation that leads to critical financial vulnerabilities like signature malleability, unspendable states and unconstrained execution paths. Industry standards such as Miniscript provide necessary abstractions for policy verification but do not model the full imperative logic required for complex contracts, leaving gaps in state management and resource liveness. This paper introduces Bithoven, a high-level language designed to bridge the gap between expressiveness and formal safety. By integrating a strict type checker and a resource liveness analyzer with a semantic control-flow analyzer, Bithoven eliminates major categories of consensus and logic defects defined in our fault model prior to deployment. Our results indicate that this safety comes at modest cost: Bithoven compiles to Bitcoin Script with efficiency comparable to hand-optimized code, demonstrating that type-safe, developer-friendly abstractions are viable even within the strict byte-size constraints of the Bitcoin blockchain."
  },
  {
    "date": "2026-01-04",
    "title": "EternalMath: A Living Benchmark of Frontier Mathematics that Evolves with Human Discovery",
    "authors": "Jicheng Ma, Guohua Wang, Xinhua Feng, Yiming Liu, Zhichao Hu, Yuhong Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01400v1",
    "source": "arXiv",
    "abstract": "Current evaluations of mathematical reasoning in large language models (LLMs) are dominated by static benchmarks, either derived from competition-style problems or curated through costly expert effort, resulting in limited coverage of research-level mathematics and rapid performance saturation. We propose a fully automated, theorem-grounded pipeline for evaluating frontier mathematical reasoning, which directly transforms recent peer-reviewed mathematical literature into executable and verifiable reasoning tasks. The pipeline identifies constructive or quantitative results, instantiates them into parameterized problem templates, and generates deterministic solutions through execution-based verification, enabling scalable, reproducible, and continuously updatable evaluation without reliance on large-scale expert authoring. By design, this approach supports temporal extensibility, intrinsic correctness checking, and domain-specific customization across mathematical subfields. Applying this pipeline yields \\textbf{EternalMath}, an evolving evaluation suite derived from contemporary research papers. Experiments with state-of-the-art LLMs reveal substantial performance gaps, indicating that mathematical reasoning at the research frontier remains far from saturated and underscoring the need for evaluation methodologies that evolve in step with human mathematical discovery."
  },
  {
    "date": "2026-01-04",
    "title": "Probabilistic verification algorithm for linear codes",
    "authors": "Mingchao Li, Jiyou Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01372v1",
    "source": "arXiv",
    "abstract": "In this paper, we propose a probabilistic algorithm suitable for any linear code $C$ to determine whether a given vector $\\mathbf{x}$ belongs to $ C$. The algorithm achieves $O(n\\log n)$ time complexity, $ O(n^2)$ space complexity and with an error probability less than $1/\\mathrm{poly}(n)$ in the asymptotic sense."
  },
  {
    "date": "2026-01-03",
    "title": "dataRLsec: Safety, Security, and Reliability With Robust Offline Reinforcement Learning for DPAs",
    "authors": "Shriram KS Pandian, Naresh Kshetri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01289v1",
    "source": "arXiv",
    "abstract": "Data poisoning attacks (DPAs) are becoming popular as artificial intelligence (AI) algorithms, machine learning (ML) algorithms, and deep learning (DL) algorithms in this artificial intelligence (AI) era. Hackers and penetration testers are excessively injecting malicious contents in the training data (and in testing data too) that leads to false results that are very hard to inspect and predict. We have analyzed several recent technologies used (from deep reinforcement learning to federated learning) for the DPAs and their safety, security, & countermeasures. The problem setup along with the problem estimation is shown in the MuJoCo environment with performance of HalfCheetah before the dataset is poisoned and after the dataset is poisoned. We have analyzed several risks associated with the DPAs and falsification in medical data from popular poisoning data attacks to some popular data defenses. We have proposed robust offline reinforcement learning (Offline RL) for the safety and reliability with weighted hash verification along with density-ratio weighted behavioral cloning (DWBC) algorithm. The four stages of the proposed algorithm (as the Stage 0, the Stage 1, the Stage 2, and the Stage 3) are described with respect to offline RL, safety, and security for DPAs. The conclusion and future scope are provided with the intent to combine DWBC with other data defense strategies to counter and protect future contamination cyberattacks."
  },
  {
    "date": "2026-01-03",
    "title": "Stylometry Analysis of Human and Machine Text for Academic Integrity",
    "authors": "Hezam Albaqami, Muhammad Asif Ayub, Nasir Ahmad, Yaseen Ahmad, Mohammed M. Alqahtani, Abdullah M. Algamdi, Almoaid A. Owaidah, Kashif Ahmad",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.01225v1",
    "source": "arXiv",
    "abstract": "This work addresses critical challenges to academic integrity, including plagiarism, fabrication, and verification of authorship of educational content, by proposing a Natural Language Processing (NLP)-based framework for authenticating students' content through author attribution and style change detection. Despite some initial efforts, several aspects of the topic are yet to be explored. In contrast to existing solutions, the paper provides a comprehensive analysis of the topic by targeting four relevant tasks, including (i) classification of human and machine text, (ii) differentiating in single and multi-authored documents, (iii) author change detection within multi-authored documents, and (iv) author recognition in collaboratively produced documents. The solutions proposed for the tasks are evaluated on two datasets generated with Gemini using two different prompts, including a normal and a strict set of instructions. During experiments, some reduction in the performance of the proposed solutions is observed on the dataset generated through the strict prompt, demonstrating the complexities involved in detecting machine-generated text with cleverly crafted prompts. The generated datasets, code, and other relevant materials are made publicly available on GitHub, which are expected to provide a baseline for future research in the domain."
  },
  {
    "date": "2026-1-5",
    "title": "LLM-Ops and Ensemble Intelligence for Robust LLM Performance: Integrating Fine-Tuning and Majority Voting",
    "authors": "Osama Hosam Abdellatif, Ahmed Ayman, Abdelrahman Nader, Ali Hamdi, Khaled Shaban",
    "publish": "2025 IEEE/ACS 22nd International Conference on Computer Systems and Applications (AICCSA)",
    "url": "https://doi.org/10.1109/aiccsa66935.2025.11315209",
    "source": "IEEE",
    "abstract": "This paper presents a novel approach that combines LLM-Ops with ensemble intelligence to enhance document processing accuracy. We introduce a multi-OCR pipeline that leverages four distinct OCR engines and four fine-tuned lightweight LLMs in a two-tier majority voting framework. Through automated fine-tuning after every 500 processed records, our system demonstrates that lightweight (7B parameter) models can achieve performance comparable to much larger (27B parameter) alternatives. Experimental results show field accuracy improvements from $85.6 \\%$ to $94.5 \\%$ after three fine-tuning cycles, with processing speeds twice as fast as larger models. The continuous improvement loop enabled by our LLM-Ops framework ensures the system evolves with minimal human intervention, making advanced document intelligence more accessible and deployable for real-world applications."
  },
  {
    "date": "2026-1-5",
    "title": "Door-to-Floor: LLM-Driven Floorplan Reconstruction from 3D LiDAR Scans_supp1-3650441.pdf",
    "authors": "Wenyuan Wang",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/lsp.2025.3650441/mm1",
    "source": "IEEE",
    "abstract": "Floorplan reconstruction captures the structure and layout of a three-dimensional space, which is essential for numerous applications such as robot localization, indoor navigation, and path planning. In recent years, with the continuous development of large language models, some models have been trained to reconstruct indoor environment structures. However, a major limitation of these models is their capability to address only small-scale, room-level scenes, making it challenging to cope with large-scale scenes at the floor level. To address this challenge, we introduce a hierarchical spatial segmentation method based on door frame recognition. By identifying door frames, large-scale floor scenes are divided into multiple small and regular rooms. Subsequently, semantic inference is applied to each subspace using a large language model, thereby achieving an accurate floorplan reconstruction. This approach overcomes the limitation of current large language models, which are restricted to handling small, room-level scenarios. We conducted an experiment on door frame recognition within a complex, large-scale environment containing nine door frames. The method successfully detected all the door frames, which allowed the precise division of the entire space into nine distinct rooms. Additionally, our floorplan reconstruction method is tested on both public and self-collected datasets, showing a 56.3% improvement over state-of-the-art (SOTA) methods."
  },
  {
    "date": "2026-1-5",
    "title": "Enhancing Transparency in Android Privacy Policies via LLM-Based Permission Mapping",
    "authors": "Ali Al Kinoon, David Mohaisen",
    "publish": "2025 IEEE/ACS 22nd International Conference on Computer Systems and Applications (AICCSA)",
    "url": "https://doi.org/10.1109/aiccsa66935.2025.11315465",
    "source": "IEEE",
    "abstract": "Privacy policies play a vital role in informing users about how mobile apps collect, use, and share their data, but their length and complexity often obscure transparency. This is especially concerning for Android apps, which frequently request sensitive permissions, e.g., location, contacts, and storage. To tackle this issue, we developed an NLP-based system that classifies privacy policy segments according to the permissions they describe. Using a dataset of over 5,000 Android apps from AndroZoo, we scraped privacy policies and extracted permissions to form a diverse dataset. The extracted permissions include those from the vanilla Android OS, as well as a small subset from third-party tools and custom Android distributions, ensuring a comprehensive analysis. After data cleaning and preprocessing, we employed both keyword-based and manual labeling, assisted by ChatGPT, to categorize policy segments. We trained NLP models like BERT, RoBERTa, and DistilBERT, comparing their performance based on accuracy, precision, recall, and F1 score. Our results showed that an ensemble learning approach, combining predictions from multiple models, outperformed individual models. This study advances efforts to enhance privacy policy transparency, improve user awareness, and strengthen privacy protection within diverse Android systems."
  },
  {
    "date": "2026-1-5",
    "title": "MediCERN: An LLM-Powered Platform for Quality Evaluation of Medical Videos",
    "authors": "Yaser Alesh, Fatma Mohamed, Abdulhadi Shoufan",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3650815",
    "source": "IEEE",
    "abstract": "YouTube has become a vital platform for disseminating medical information and guiding health decision-making. However, the literature confirms the prevalence of inaccurate, biased, or misleading content on this platform and underscores the need for robust quality assessment. This paper presents MediCERN, a platform that leverages a large language model (LLM) to evaluate the quality of medical videos using DISCERN, a widely accepted instrument for assessing health information reliability. Users can access MediCERN through a web interface to search for medical videos. The platform forwards each search query to YouTube and retrieves a list of relevant videos. MediCERN then checks whether any of these videos have been previously evaluated. Evaluated videos are presented to users ranked by their quality scores, while unevaluated videos are displayed without a score; however, users can request on-demand evaluation. The system processes these requests and provides scores within a few seconds. Sample analyses demonstrate substantial agreement between the model’s and experts’ ratings, with a Brennan–Prediger Kappa of 0.87. We further demonstrate the platform’s utility by analyzing over 5,000 videos. The results indicate that quality scores followed a Gaussian-like distribution, with most videos exhibiting medium quality. We also assessed the platform’s efficiency in terms of cost, time, and storage. For instance, the current prototype can evaluate one hour of video content in approximately 0.6 minutes at a cost of $0.0026 USD. These findings demonstrate that MediCERN offers a scalable and efficient solution for promoting access to high-quality medical content on YouTube."
  },
  {
    "date": "2026-1-5",
    "title": "Agentic AI in Healthcare &amp; Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents",
    "authors": "Shubham Vatsal, Harsh Dubey, Aditi Singh",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3651218",
    "source": "IEEE",
    "abstract": "Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Fully Implemented</i> ✓, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Partially Implemented</i> Δ, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Not Implemented</i> ✗), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (∼76% ✓) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (∼92% ✗) and Drift Detection & Mitigation sub-dimension under Adaptation & Learning is rare (∼98% ✗). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (∼82% ✓) while orchestration layers remain mostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question Answering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas such as Treatment Planning & Prescription still show substantial gaps (∼59% ✗). Together, these findings provide an empirical baseline indicating that current agents excel at retrieval-grounded advising but require stronger adaptation and compliance platforms to move from early-stage systems to dependable systems."
  },
  {
    "date": "2026-1-5",
    "title": "MSLEF: Multi-Segment LLM Ensemble Finetuning in Recruitment",
    "authors": "Omar Walid, Mohamed T. Younes, Khaled Shaban, Mai Hassan, Ali Hamdi",
    "publish": "2025 IEEE/ACS 22nd International Conference on Computer Systems and Applications (AICCSA)",
    "url": "https://doi.org/10.1109/aiccsa66935.2025.11315289",
    "source": "IEEE",
    "abstract": "This paper presents MSLEF, a multi-segment ensemble framework that employs LLM fine-tuning to enhance resume parsing in recruitment automation. It integrates finetuned Large Language Models (LLMs) using weighted voting, with each model specializing in a specific resume segment to boost accuracy. Building on MLAR [1], MSLEF introduces a segmentaware architecture that leverages field-specific weighting tailored to each resume part, effectively overcoming the limitations of single-model systems by adapting to diverse formats and structures. The framework incorporates Gemini-2.5-Flash LLM as a high-level aggregator for complex sections and utilizes Gemma 9B, LLaMA 3.1 8B, and Phi-4 14B. MSLEF achieves significant improvements in Exact Match (EM), F1 score, BLEU, ROUGE, and Recruitment Similarity (RS) metrics, outperforming the best single model by up to +7 % in RS. Its segment-aware design enhances generalization across varied resume layouts, making it highly adaptable to real-world hiring scenarios while ensuring precise and reliable candidate representation."
  },
  {
    "date": "2026-1-5",
    "title": "A Novel Competency Tagging Method Through Semantic Search Using Fine-Tuned LLM",
    "authors": "Imene Jemal, Naoussi Sijou Wilfried Armand, Belkacem Chikhaoui",
    "publish": "2025 IEEE/ACS 22nd International Conference on Computer Systems and Applications (AICCSA)",
    "url": "https://doi.org/10.1109/aiccsa66935.2025.11315432",
    "source": "IEEE",
    "abstract": "Competency tagging plays an essential role in both academic and industrial settings, enabling the alignment of learning content, job postings, and resumes with specific skill sets. However, traditional manual tagging is costly, time-intensive, and prone to inconsistencies. In this work, we propose an automated competency tagging method leveraging semantic search with fine-tuned Large Language Model (LLM). Our approach encodes textual data from learning materials and competency descriptions into a shared embedding space, enabling efficient retrieval of relevant competency tags via similarity search. We systematically evaluate semantic matching at different levels of granularity-document, paragraph, and sentence-to optimize retrieval performance. Furthermore, we fine-tune the LLM using Low-Rank Adaptation (LoRA) to improve competency tagging while maintaining efficiency. Experiments on a dataset of 164 pages of learning content and 96 competencies demonstrate the effectiveness of our method, achieving a recall@10 of $80.29 \\%$. Notably, fine-tuning with LoRA led to a $6 \\%$ improvement in recall@10, highlighting its impact on enhancing retrieval performance. Our findings underscore the potential of fine-tuned LLMs for high-precision competency tagging."
  },
  {
    "date": "2026-1-5",
    "title": "Context-Aware Prompt Engineering and Time-Aware LLM Architecture for Radiology Report Generation",
    "authors": "Medini Mariem, Bouslimi Riadh, Kaouther Nouira Ferchichi",
    "publish": "2025 IEEE/ACS 22nd International Conference on Computer Systems and Applications (AICCSA)",
    "url": "https://doi.org/10.1109/aiccsa66935.2025.11315213",
    "source": "IEEE",
    "abstract": "Recent advances in large language models (LLMs) have enabled new possibilities for automated radiology reporting, yet key challenges remain, including lack of contextualization, absence of longitudinal reasoning, and risk of clinically inaccurate content. We propose a lightweight, modular architecture that combines a pre-trained LLM with a context-aware Prompt Constructor and a temporal reasoning engine. Prompts are dynamically adapted based on imaging modality, clinical indication, and prior reports, supported by a fuzzy logic-driven rule base and a temporal summarizer to ensure clinical nuance and continuity. Our system is evaluated through realistic case scenarios across multiple imaging types and externally validated on 250 cases from the MIMIC-CXR dataset. Results demonstrate significant gains in BLEU, ROUGE, and BERTScore over baseline prompting, with expert review confirming improved structure, diagnostic alignment, and reduced hallucinations. These findings support the practical integration of explainable and configurable LLMbased systems into real-world radiology workflows."
  },
  {
    "date": "2026-1-5",
    "title": "Beyond Stars: Bridging the Gap Between Ratings and Review Sentiment with LLM",
    "authors": "Najla Zuhir, Amna Mohammad Salim, Parvathy Premkumar, Md Moshiur Farazi",
    "publish": "2025 IEEE/ACS 22nd International Conference on Computer Systems and Applications (AICCSA)",
    "url": "https://doi.org/10.1109/aiccsa66935.2025.11315331",
    "source": "IEEE",
    "abstract": "We present an advanced approach to mobile app review analysis aimed at addressing limitations inherent in traditional star-rating systems. Star ratings, although intuitive and popular among users, often fail to capture the nuanced feedback present in detailed review texts. Traditional NLP tech-niques-such as lexicon-based methods and classical machine learning classifiers-struggle to interpret contextual nuances, domain-specific terminology, and subtle linguistic features like sarcasm. To overcome these limitations, we propose a modular framework leveraging large language models (LLMs) enhanced by structured prompting techniques. Our method quantifies discrepancies between numerical ratings and textual sentiment, extracts detailed, feature-level insights, and supports interactive exploration of reviews through retrieval-augmented conversational question answering (RAG-QA). Comprehensive experiments conducted on three diverse datasets (AWARE, Google Play, and Spotify) demonstrate that our LLM-driven approach significantly surpasses baseline methods, yielding improved accuracy, robustness, and actionable insights in challenging and context-rich review scenarios."
  },
  {
    "date": "2026-1-5",
    "title": "GeoTree: A Dynamic Tree-based Geometry Problem Solver through LLM-Symbolic Reasoning",
    "authors": "Yaxian Wang, Bifan Wei, Yinghong Ma, Lingling Zhang, Xudong Jiang, Henghui Ding, Jun Liu",
    "publish": "IEEE Transactions on Multimedia",
    "url": "https://doi.org/10.1109/tmm.2026.3651076",
    "source": "IEEE",
    "abstract": "Geometry problem solving (GPS) requires high-level symbolic and logical reasoning based on geometry theorem knowledge to arrive at the answer. Despite the remarkable advances achieved by Large Language Models (LLMs) in various problem-solving tasks, they still struggle to perform rigorous multi-step geometry reasoning, which is essential for GPS. In this paper, we propose a dynamic tree-based geometry problem solver named GeoTree, which combines a knowledgeable LLM with a rigorous symbolic solver to perform geometry reasoning cooperatively. Specifically, an iterative multi-step geometry reasoning process is performed dynamically based on a tree-like structure, thereby emulating divergent and deliberate human problem-solving thinking. Each geometry reasoning step is completed collaboratively through four components, consisting of <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Theorem Seeker</i>, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Symbolic Solver</i>, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Evaluator</i>, and <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Controller</i>. First, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Theorem Seeker</i> prompts LLMs to seek out candidate theorems with their inherent geometry theorem knowledge. Subsequently, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Symbolic Solver</i> applies the theorems on the known conditions to obtain new additional conditions. Then, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Evaluator</i> assesses the availability of the theorems and prompts LLMs to judge the usefulness of these new conditions for the problem target, which serves as the heuristic guidance for subsequent reasoning. Finally, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Controller</i> determines the termination state, which decides whether to continue invoking the other three components for further attempts. Extensive experiments on Geometry3K demonstrate the superiority of GeoTree in accuracy, efficiency, and explainability."
  },
  {
    "date": "2026-1-5",
    "title": "Autonomous QA Data Augmentation via Open-Source LLM Agents for Metaverse Applications",
    "authors": "Faiza Belbachir, Rémy Chen, Lucas Lorang, Arthur Delfose, Nasredine Semmar, Samia Bouzefrane, Assia Soukane",
    "publish": "2025 IEEE/ACS 22nd International Conference on Computer Systems and Applications (AICCSA)",
    "url": "https://doi.org/10.1109/aiccsa66935.2025.11315489",
    "source": "IEEE",
    "abstract": "The Metaverse requires intelligent QA services for applications like digital twins and avatar assistants, yet assembling high-quality domain-specific data is challenging. We introduce a novel agent-oriented augmentation pipeline using open-source LLMs (LLaMA and DeepSeek) to autonomously generate and refine synthetic QA pairs. Agents leverage chain-of-thought prompts and feedback loops to iteratively validate and improve responses. By augmenting a limited Stack Overflow R-tag dataset (2,000 examples) with 4,500 synthetic items, our method boosts BERTScore by 11.2% and F1 by 8.0% over static zero-shot baselines. This transparent, cost-effective workflow lays groundwork for scalable QA augmentation in virtual environments."
  },
  {
    "date": "2026-1-5",
    "title": "LAMPAS: LLM-driven Adaptive Multi-factor Personalised learning System",
    "authors": "Reda Bendraou, Fatima Gul Zeb, Aziza Mohammed, Warda Ifran, Kalysha Utama, Fatima Anwar Safir, Ali Ahmad, Oussama Djedidi",
    "publish": "2025 IEEE/ACS 22nd International Conference on Computer Systems and Applications (AICCSA)",
    "url": "https://doi.org/10.1109/aiccsa66935.2025.11315491",
    "source": "IEEE",
    "abstract": "This research presents a personalized adaptive learning system, LAMPAS. Leveraging Large Language Models and a modular learner profiling mechanism, we developed a web-based system that dynamically adapts educational content based on cognitive factors, such as learning styles, cognitive styles, knowledge levels, and skill levels. We introduce a Generate-Review-Refine pipeline to enhance content relevance and completeness and evaluate our system through prompt engineering experiments and LLM benchmarking."
  },
  {
    "date": "2026-1-5",
    "title": "Detecting Misinformation by Uncovering Commonsense Conflicts with LLM Workflows",
    "authors": "Bing Wang, Ximing Li, Changchun Li, Bingrui Zhao, Renchu Guan, Lin Yuanbo Wu, Jungong Han",
    "publish": "IEEE Transactions on Knowledge and Data Engineering",
    "url": "https://doi.org/10.1109/tkde.2025.3650588",
    "source": "IEEE",
    "abstract": "The advancement of Internet technology has spurred a rise in the dissemination of misinformation, which has had profoundly negative impacts across a wide array of fields. To address this issue, the field of Misinformation Detection (MD), which focuses on the automated identification of online misinformation, has gained significant traction among researchers. In our study, we introduce an innovative plugand- play augmentation technique for MD, termed DEtecting Misinformation by Uncovering Commonsense Conflict (DEMUC). Our approach is grounded in previous psychological research that suggests that fake content often contains commonsense. Accordingly, we develop commonsense expressions for articles to highlight potential conflicts between the inferred commonsense triplets and the established ones derived from reliable commonsense reasoning tools. According to the used tools, we induce two variants DEMUC-KLM using the knowledge language model COMET and DEMUC-LLM using the large language models. These generated expressions are then applied as augmentations to each article, enabling any MD method to be trained on these augmented datasets. Additionally, we have manually compiled a new dataset CoMis, which consists exclusively of fake articles characterized by commonsense conflicts. By integrating DEMUC with various existing MD frameworks and evaluating them on four public benchmark datasets and CoMis, our empirical findings show that both DEMUC-KLM and DEMUC-LLM consistently and significantly outperform current MD baselines, while also generating precise commonsense expressions."
  },
  {
    "date": "2026-1-5",
    "title": "ClaimVerAgents: A Multi-Agent Retrieval-Augmented Claim Verification Framework",
    "authors": "Dorsaf Sallami, Sabrine Amri, Esma Aïmeur",
    "publish": "2025 IEEE/ACS 22nd International Conference on Computer Systems and Applications (AICCSA)",
    "url": "https://doi.org/10.1109/aiccsa66935.2025.11315316",
    "source": "IEEE",
    "abstract": "The spread of fake news has had major impact on public discourse and trust. Detection methods rely heavily on evidence quality and verdict accuracy. Traditional approaches, often based on static sources, struggle with outdated or incomplete information, especially for new or obscure claims. Large Language Models (LLMs) offer promising reasoning and generation capabilities but face similar challenges, including outdated knowledge and limited coverage. To address these challenges, we present ClaimVerAgents<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>, a novel, retrieval-augmented, modular, and interpretable multi-agent system that leverages LLMs for real-time fake news verification. Each autonomous agent fulfills a specialized sub-task: claim extraction, query generation, evidence evaluation, verdict decision, and explanation generation, all within a transparent, confidenceaware pipeline. Extensive experiments on the PolitiFact dataset show that ClaimVerAgents outperforms both classical and LLM-based baselines in accuracy and robustness. Importantly, the system generates structured, humanreadable explanations alongside its verdicts, enhancing trust and interpretability.<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>Code and data are available at https://anonymous.4open.science/r/ ClaimVerAgents-832E"
  },
  {
    "date": "2026-1-5",
    "title": "LLM-Driven Adversarial Example Synthesis for Emerging Topic Rumor Detection on Social Media",
    "authors": "Menglong Lu, Zejiang He, Yaohui Guo, Shanshan Liu, Jingyuan Huang, Yunxiang Zhao, Zhiliang Tian, Xiaoran Zhao, Chengcheng Shao, Lin Deng, Dongsheng Li, Zhen Huang",
    "publish": "IEEE Transactions on Knowledge and Data Engineering",
    "url": "https://doi.org/10.1109/tkde.2026.3650830",
    "source": "IEEE",
    "abstract": "Rumor detection is essential for building a responsible web and internet ecosystem, which has attracted significant attention from the research community. However, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">emerging topic rumor detection</i>, i.e., identify rumors at the early stages of a topic's emergence where only limited discussions can be observed, still remains a challenge. Technically, this scenario is accompanied by the issues of <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">data scarcity</i> on emerging topics and the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">data distribution discrepancy</i> between old topics and emerging new topic. In this paper, we propose a new framework termed <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">L</b>LM-driven <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">AD</b>versarial <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">E</b>xample <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">S</b>ynthesis (<bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">LADES</b>) for emerging topic rumor detection. LADES utilizes Large Language Models (LLMs) for generating readable and contextually coherent adversarial examples. The generated adversarial examples not only expand the training set to tackle the data scarcity issue, but also act as a bridge to connect the data distribution of old and new topics. To overcome training instability in adversarial example generation, LADES introduces a gradient-free Markov Chain Monte Carlo (MCMC) sampling method. This method ensures adversarial examples are readable and contextually coherent by harnessing LLMs, while promoting effective attacks through entropy-based sampling that targets model uncertainty. To mitigate the impact of potential mislabeling in synthetic data, LADES implements a meta-mixed-learning mechanism. This mechanism dynamically adjusts the weights of synthetic adversarial examples, guided by limited labeled data from emerging topics, thereby alleviating the data noise."
  },
  {
    "date": "2026-1-5",
    "title": "EaaS/PIN Synergy: Advances and Challenges Secure Path Verification",
    "authors": "Amir Javadpour, Forough Ja’fari, Tarik Taleb, Chafika Benzaïd",
    "publish": "IEEE Internet of Things Journal",
    "url": "https://doi.org/10.1109/jiot.2025.3650640",
    "source": "IEEE",
    "abstract": "The proliferation of resource-constrained devices in Internet of Things (IoT) environments has amplified the demand for scalable, secure, and efficient cryptographic services. While Encryption-as-a-Service (EaaS) models enable offloading cryptographic tasks to trusted infrastructure, critical challenges remain regarding path integrity, trust management, and resilience to adversarial threats in multi-domain networks. This paper introduces EaaS/PIN, a unified framework that combines cryptographically verifiable path integrity, user-centric trust scoring, collaborative threat intelligence, and machine learning-driven path selection across distributed Autonomous Systems (ASs). The framework integrates: (i) a novel anonymity protocol to conceal complete routes from intermediary ASs, (ii) lightweight, customizable encryption suitable for IoT and edge environments, (iii) real-time, AI-based path recommendation leveraging dynamic trust and performance metrics, and (iv) a blockchain-inspired audit mechanism for tamper-evident reporting and accountability. Comprehensive mathematical modeling, algorithms, and a detailed case study focused on secure data transmission in a multi-AS smart city network demonstrate that EaaS/PIN significantly enhances routing security, reduces latency, and ensures transparent and verifiable operations even under adversarial conditions. Experimental results confirm robust detection of path manipulation and compromised ASs, as well as measurable performance gains over baseline solutions. The proposed framework paves the way for scalable, user-aware, and resilient cryptographic services in next-generation heterogeneous network infrastructures."
  },
  {
    "date": "2026-1-6",
    "title": "Construction and Verification of an Intelligent Connected Vehicle Training Platform Based on Mixed Reality and Artificial Intelligence",
    "authors": "Zeting An, Peng Shao, Qianlin Xv, Xialin Sun, Yuhang Zuo, Lin Cheng",
    "publish": "Proceedings of the 2025 International Conference on Computer Technology, Digital Media and Communication",
    "url": "https://doi.org/10.1145/3783669.3783724",
    "source": "ACM",
    "abstract": "None"
  }
]